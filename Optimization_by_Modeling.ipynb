{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week Number</th>\n",
       "      <th>Corridor</th>\n",
       "      <th>Workday</th>\n",
       "      <th>Station</th>\n",
       "      <th>Period</th>\n",
       "      <th>Ridership</th>\n",
       "      <th>N_trains</th>\n",
       "      <th>Covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34103</th>\n",
       "      <td>2021</td>\n",
       "      <td>February</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Corridor_1</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_1</td>\n",
       "      <td>Midday</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31471</th>\n",
       "      <td>2020</td>\n",
       "      <td>November</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>Corridor_2</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_5</td>\n",
       "      <td>PM Peak</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>2019</td>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Corridor_2</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_3</td>\n",
       "      <td>Midday</td>\n",
       "      <td>1102</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57280</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>Corridor_2</td>\n",
       "      <td>n</td>\n",
       "      <td>Station_5</td>\n",
       "      <td>Weekend/Holiday</td>\n",
       "      <td>10361</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36645</th>\n",
       "      <td>2021</td>\n",
       "      <td>April</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Corridor_4</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_3</td>\n",
       "      <td>Midday</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year     Month  Day  Week Number    Corridor Workday    Station  \\\n",
       "34103  2021  February    3            5  Corridor_1       y  Station_1   \n",
       "31471  2020  November   30           49  Corridor_2       y  Station_5   \n",
       "6139   2019       May    2           18  Corridor_2       y  Station_3   \n",
       "57280  2022      July   30           30  Corridor_2       n  Station_5   \n",
       "36645  2021     April   14           15  Corridor_4       y  Station_3   \n",
       "\n",
       "                Period  Ridership  N_trains  Covid19  \n",
       "34103           Midday         32         1        1  \n",
       "31471          PM Peak        144         6        1  \n",
       "6139            Midday       1102        24        0  \n",
       "57280  Weekend/Holiday      10361        37        0  \n",
       "36645           Midday         92         6        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridership_df= pd.read_csv('data/Ridership.csv')\n",
    "df= Ridership_df.copy()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64369 entries, 0 to 64368\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Year         64369 non-null  int64 \n",
      " 1   Month        64369 non-null  object\n",
      " 2   Day          64369 non-null  int64 \n",
      " 3   Week Number  64369 non-null  int64 \n",
      " 4   Corridor     64369 non-null  object\n",
      " 5   Workday      64369 non-null  object\n",
      " 6   Station      64369 non-null  object\n",
      " 7   Period       64369 non-null  object\n",
      " 8   Ridership    64369 non-null  int64 \n",
      " 9   N_trains     64369 non-null  int64 \n",
      " 10  Covid19      64369 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Month          0\n",
       "Day            0\n",
       "Week Number    0\n",
       "Corridor       0\n",
       "Workday        0\n",
       "Station        0\n",
       "Period         0\n",
       "Ridership      0\n",
       "N_trains       0\n",
       "Covid19        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Month mapping\n",
    "    month_mapping = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "        'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    df['Month_Num'] = df['Month'].map(month_mapping)\n",
    "\n",
    "    # Cyclical Day conversion\n",
    "    def convert_day_to_circle(day):\n",
    "        angle = 2 * np.pi * (day - 1) / 31\n",
    "        x = np.cos(angle)\n",
    "        y = np.sin(angle)\n",
    "        return x, y\n",
    "\n",
    "    df['day_x'], df['day_y'] = zip(*df['Day'].map(convert_day_to_circle))\n",
    "\n",
    "    # Cyclical Week conversion\n",
    "    def convert_week_to_circle(week):\n",
    "        angle = 2 * np.pi * (week - 1) / 53\n",
    "        x = np.cos(angle)\n",
    "        y = np.sin(angle)\n",
    "        return x, y\n",
    "\n",
    "    df['week_x'], df['week_y'] = zip(*df['Week Number'].map(convert_week_to_circle))\n",
    "\n",
    "    # Categorical features for OneHotEncoder\n",
    "    categorical_features = ['Month', 'Corridor', 'Workday', 'Station', 'Period']\n",
    "\n",
    "    # Column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('', OneHotEncoder(), categorical_features),\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Fit and transform the DataFrame\n",
    "    df_transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Convert the encoded features to a dense matrix\n",
    "    df_transformed = df_transformed.toarray()\n",
    "\n",
    "    # Convert to DataFrame and get feature names\n",
    "    feature_names_out = list(preprocessor.get_feature_names_out())\n",
    "    \n",
    "    # Convert the dense matrix to a DataFrame\n",
    "    df_transformed = pd.DataFrame(df_transformed, columns=[item.split('__')[1] for item in feature_names_out])\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COVID_Workday'] = df['Covid19'] * df['Workday_y']\n",
    "\n",
    "columns_to_convert = [\n",
    "    'Month_April', 'Month_August', 'Month_December', 'Month_February', \n",
    "    'Month_January', 'Month_July', 'Month_June', 'Month_March', \n",
    "    'Month_May', 'Month_November', 'Month_October', 'Month_September',\n",
    "    'Corridor_Corridor_1', 'Corridor_Corridor_2', 'Corridor_Corridor_3', \n",
    "    'Corridor_Corridor_4', 'Corridor_Corridor_5', 'Corridor_Corridor_6', 'Corridor_Corridor_7',\n",
    "    'Station_Station_1', 'Station_Station_10', 'Station_Station_11', 'Station_Station_12', \n",
    "    'Station_Station_13', 'Station_Station_14', 'Station_Station_15', 'Station_Station_16', \n",
    "    'Station_Station_17', 'Station_Station_18', 'Station_Station_19', 'Station_Station_2', \n",
    "    'Station_Station_20', 'Station_Station_21', 'Station_Station_22', 'Station_Station_23', \n",
    "    'Station_Station_24', 'Station_Station_25', 'Station_Station_26', 'Station_Station_27', \n",
    "    'Station_Station_28', 'Station_Station_29', 'Station_Station_3', 'Station_Station_30', \n",
    "    'Station_Station_31', 'Station_Station_32', 'Station_Station_33', 'Station_Station_34', \n",
    "    'Station_Station_35', 'Station_Station_36', 'Station_Station_37', 'Station_Station_38', \n",
    "    'Station_Station_39', 'Station_Station_4', 'Station_Station_40', 'Station_Station_41', \n",
    "    'Station_Station_42', 'Station_Station_43', 'Station_Station_44', 'Station_Station_45', \n",
    "    'Station_Station_5', 'Station_Station_6', 'Station_Station_7', 'Station_Station_8', 'Station_Station_9',\n",
    "    'Period_AM Peak', 'Period_Evening', 'Period_Midday', 'Period_PM Peak', 'Period_Weekend/Holiday',\n",
    "    'Day',\n",
    "    'Week Number',\n",
    "    'Workday_n', 'Workday_y',\n",
    "    'Covid19','COVID_Workday',\n",
    "    'Month_Num']\n",
    "\n",
    "columns_to_convert_02=['Year', 'Ridership', 'N_trains']\n",
    "\n",
    "\n",
    "df[columns_to_convert] = df[columns_to_convert].astype('uint8')\n",
    "df[columns_to_convert_02] = df[columns_to_convert_02].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64369 entries, 0 to 64368\n",
      "Data columns (total 83 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Month_April             64369 non-null  uint8  \n",
      " 1   Month_August            64369 non-null  uint8  \n",
      " 2   Month_December          64369 non-null  uint8  \n",
      " 3   Month_February          64369 non-null  uint8  \n",
      " 4   Month_January           64369 non-null  uint8  \n",
      " 5   Month_July              64369 non-null  uint8  \n",
      " 6   Month_June              64369 non-null  uint8  \n",
      " 7   Month_March             64369 non-null  uint8  \n",
      " 8   Month_May               64369 non-null  uint8  \n",
      " 9   Month_November          64369 non-null  uint8  \n",
      " 10  Month_October           64369 non-null  uint8  \n",
      " 11  Month_September         64369 non-null  uint8  \n",
      " 12  Corridor_Corridor_1     64369 non-null  uint8  \n",
      " 13  Corridor_Corridor_2     64369 non-null  uint8  \n",
      " 14  Corridor_Corridor_3     64369 non-null  uint8  \n",
      " 15  Corridor_Corridor_4     64369 non-null  uint8  \n",
      " 16  Corridor_Corridor_5     64369 non-null  uint8  \n",
      " 17  Corridor_Corridor_6     64369 non-null  uint8  \n",
      " 18  Corridor_Corridor_7     64369 non-null  uint8  \n",
      " 19  Workday_n               64369 non-null  uint8  \n",
      " 20  Workday_y               64369 non-null  uint8  \n",
      " 21  Station_Station_1       64369 non-null  uint8  \n",
      " 22  Station_Station_10      64369 non-null  uint8  \n",
      " 23  Station_Station_11      64369 non-null  uint8  \n",
      " 24  Station_Station_12      64369 non-null  uint8  \n",
      " 25  Station_Station_13      64369 non-null  uint8  \n",
      " 26  Station_Station_14      64369 non-null  uint8  \n",
      " 27  Station_Station_15      64369 non-null  uint8  \n",
      " 28  Station_Station_16      64369 non-null  uint8  \n",
      " 29  Station_Station_17      64369 non-null  uint8  \n",
      " 30  Station_Station_18      64369 non-null  uint8  \n",
      " 31  Station_Station_19      64369 non-null  uint8  \n",
      " 32  Station_Station_2       64369 non-null  uint8  \n",
      " 33  Station_Station_20      64369 non-null  uint8  \n",
      " 34  Station_Station_21      64369 non-null  uint8  \n",
      " 35  Station_Station_22      64369 non-null  uint8  \n",
      " 36  Station_Station_23      64369 non-null  uint8  \n",
      " 37  Station_Station_24      64369 non-null  uint8  \n",
      " 38  Station_Station_25      64369 non-null  uint8  \n",
      " 39  Station_Station_26      64369 non-null  uint8  \n",
      " 40  Station_Station_27      64369 non-null  uint8  \n",
      " 41  Station_Station_28      64369 non-null  uint8  \n",
      " 42  Station_Station_29      64369 non-null  uint8  \n",
      " 43  Station_Station_3       64369 non-null  uint8  \n",
      " 44  Station_Station_30      64369 non-null  uint8  \n",
      " 45  Station_Station_31      64369 non-null  uint8  \n",
      " 46  Station_Station_32      64369 non-null  uint8  \n",
      " 47  Station_Station_33      64369 non-null  uint8  \n",
      " 48  Station_Station_34      64369 non-null  uint8  \n",
      " 49  Station_Station_35      64369 non-null  uint8  \n",
      " 50  Station_Station_36      64369 non-null  uint8  \n",
      " 51  Station_Station_37      64369 non-null  uint8  \n",
      " 52  Station_Station_38      64369 non-null  uint8  \n",
      " 53  Station_Station_39      64369 non-null  uint8  \n",
      " 54  Station_Station_4       64369 non-null  uint8  \n",
      " 55  Station_Station_40      64369 non-null  uint8  \n",
      " 56  Station_Station_41      64369 non-null  uint8  \n",
      " 57  Station_Station_42      64369 non-null  uint8  \n",
      " 58  Station_Station_43      64369 non-null  uint8  \n",
      " 59  Station_Station_44      64369 non-null  uint8  \n",
      " 60  Station_Station_45      64369 non-null  uint8  \n",
      " 61  Station_Station_5       64369 non-null  uint8  \n",
      " 62  Station_Station_6       64369 non-null  uint8  \n",
      " 63  Station_Station_7       64369 non-null  uint8  \n",
      " 64  Station_Station_8       64369 non-null  uint8  \n",
      " 65  Station_Station_9       64369 non-null  uint8  \n",
      " 66  Period_AM Peak          64369 non-null  uint8  \n",
      " 67  Period_Evening          64369 non-null  uint8  \n",
      " 68  Period_Midday           64369 non-null  uint8  \n",
      " 69  Period_PM Peak          64369 non-null  uint8  \n",
      " 70  Period_Weekend/Holiday  64369 non-null  uint8  \n",
      " 71  Year                    64369 non-null  uint16 \n",
      " 72  Day                     64369 non-null  uint8  \n",
      " 73  Week Number             64369 non-null  uint8  \n",
      " 74  Ridership               64369 non-null  uint16 \n",
      " 75  N_trains                64369 non-null  uint16 \n",
      " 76  Covid19                 64369 non-null  uint8  \n",
      " 77  Month_Num               64369 non-null  uint8  \n",
      " 78  day_x                   64369 non-null  float64\n",
      " 79  day_y                   64369 non-null  float64\n",
      " 80  week_x                  64369 non-null  float64\n",
      " 81  week_y                  64369 non-null  float64\n",
      " 82  COVID_Workday           64369 non-null  uint8  \n",
      "dtypes: float64(4), uint16(3), uint8(76)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One: \n",
    "Assume we want to find a general model for the number of passengers without looking at the number of passengers on previous days and only using the recorded information in the table for the same time period (except for the year and number of trains) to predict the number of required trains based on the number of passengers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_p01 = df.drop(['Ridership', 'Year', 'N_trains'], axis=1)  \n",
    "# y_p01 = pd.DataFrame(df['Ridership'])\n",
    "\n",
    "# df_for_stratify_p01 = Ridership_df.copy()\n",
    "# stratify_key_p01 = df_for_stratify_p01['Covid19'].astype(str) + '_' + \\\n",
    "#                    df_for_stratify_p01['Workday'] + '_' + \\\n",
    "#                    df_for_stratify_p01['Period'] + '_' + \\\n",
    "#                    df_for_stratify_p01['Corridor']\n",
    "\n",
    "# X_train_p01, X_test_p01, y_train_p01, y_test_p01 = train_test_split(\n",
    "#     X_p01, y_p01,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=stratify_key_p01 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p01(df, target_column='Ridership', test_size=0.2, random_state=42):\n",
    "    # Drop unnecessary columns\n",
    "    X = df.drop([target_column, 'Year', 'N_trains'], axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Create stratification key directly from df\n",
    "    df_for_stratify_p01 = Ridership_df.copy()\n",
    "    stratify_key_p01 = df_for_stratify_p01['Covid19'].astype(str) + '_' + \\\n",
    "                       df_for_stratify_p01['Workday'] + '_' + \\\n",
    "                       df_for_stratify_p01['Period']+ '_' + \\\n",
    "                       df_for_stratify_p01['Corridor']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_key_p01\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "X_train_p01, X_test_p01, y_train_p01, y_test_p01 = preprocess_and_split_data_p01(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 825.099\n",
      "RMSE: 825.10\n",
      "R²: 0.8129\n"
     ]
    }
   ],
   "source": [
    "# train_data = lgb.Dataset(X_train_p01, label=y_train_p01)\n",
    "# test_data = lgb.Dataset(X_test_p01, label=y_test_p01, reference=train_data)\n",
    "\n",
    "# # Define parameters\n",
    "# params = {\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'rmse',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'num_leaves': 31,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'verbose': -1\n",
    "# }\n",
    "\n",
    "# # Train the model\n",
    "# model_p01 = lgb.train(params,\n",
    "#                  train_data,\n",
    "#                  num_boost_round=1000,\n",
    "#                  valid_sets=[test_data],\n",
    "#                  callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model_p01.predict(X_test_p01)\n",
    "\n",
    "# # Evaluate\n",
    "# rmse_f_p01 = np.sqrt(mean_squared_error(y_test_p01, y_pred))\n",
    "# r2_f_p01= r2_score(y_test_p01, y_pred)\n",
    "\n",
    "# print(f\"RMSE: {rmse_f_p01:.2f}\")\n",
    "# print(f\"R²: {r2_f_p01:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p01(trial):\n",
    "    # Define parameters to be optimized by Optuna\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False # Disable feature pre-filtering\n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(X_train_p01, label=y_train_p01)\n",
    "    test_data = lgb.Dataset(X_test_p01, label=y_test_p01, reference=train_data)\n",
    "\n",
    "    # Train the model with early stopping on the validation set\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000, # Max boosting rounds\n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) # verbose=False to reduce output\n",
    "\n",
    "    # Make predictions on the validation set using the best iteration\n",
    "    y_pred = model.predict(X_test_p01, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Return RMSE as the objective value to minimize\n",
    "    return np.sqrt(mean_squared_error(y_test_p01, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 20:30:00,316] A new study created in memory with name: no-name-a1231877-b820-4676-ae49-8eec62c694df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c70faff138949a5bedb1c6598dabc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 20:30:03,232] Trial 0 finished with value: 858.3986297975716 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:08,173] Trial 1 finished with value: 965.171480859766 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:10,319] Trial 2 finished with value: 1000.1536696220307 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:12,515] Trial 3 finished with value: 894.0391972352643 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:15,082] Trial 4 finished with value: 948.3146519834861 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:19,858] Trial 5 finished with value: 866.4387208437403 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:21,977] Trial 6 finished with value: 949.6893791987322 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:23,913] Trial 7 finished with value: 1015.4673968533081 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:25,578] Trial 8 finished with value: 915.3457610239897 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:29,704] Trial 9 finished with value: 870.6259201748129 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-21 20:30:34,236] Trial 10 finished with value: 840.8127837075767 and parameters: {'num_leaves': 96, 'learning_rate': 0.20844875976291638, 'min_child_samples': 96, 'max_depth': 12, 'feature_fraction': 0.7606700059313507, 'bagging_fraction': 0.8451235367845726, 'bagging_freq': 0, 'lambda_l1': 6.233765186294655, 'lambda_l2': 5.705478648816834}. Best is trial 10 with value: 840.8127837075767.\n",
      "[I 2025-07-21 20:30:37,369] Trial 11 finished with value: 840.4630573552917 and parameters: {'num_leaves': 100, 'learning_rate': 0.21350493115709046, 'min_child_samples': 97, 'max_depth': 12, 'feature_fraction': 0.7804533509078434, 'bagging_fraction': 0.8513496163789993, 'bagging_freq': 0, 'lambda_l1': 5.732909776512292, 'lambda_l2': 5.916836359300596}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-21 20:30:40,717] Trial 12 finished with value: 865.350729411854 and parameters: {'num_leaves': 98, 'learning_rate': 0.1972983678039399, 'min_child_samples': 98, 'max_depth': 12, 'feature_fraction': 0.7630125055985993, 'bagging_fraction': 0.8588729908849949, 'bagging_freq': 1, 'lambda_l1': 5.4383196440103365, 'lambda_l2': 6.31247107794331}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-21 20:30:44,741] Trial 13 finished with value: 866.8463394407116 and parameters: {'num_leaves': 100, 'learning_rate': 0.19879458291976249, 'min_child_samples': 88, 'max_depth': 12, 'feature_fraction': 0.7878475603784051, 'bagging_fraction': 0.8585787245031458, 'bagging_freq': 2, 'lambda_l1': 5.948420184248468, 'lambda_l2': 3.919288077713245}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-21 20:30:48,231] Trial 14 finished with value: 829.5731708574829 and parameters: {'num_leaves': 86, 'learning_rate': 0.23235938995830105, 'min_child_samples': 85, 'max_depth': 10, 'feature_fraction': 0.9977408115016615, 'bagging_fraction': 0.9501945220447685, 'bagging_freq': 0, 'lambda_l1': 6.498463090024852, 'lambda_l2': 6.895871382854953}. Best is trial 14 with value: 829.5731708574829.\n",
      "[I 2025-07-21 20:30:50,951] Trial 15 finished with value: 823.2748751682116 and parameters: {'num_leaves': 85, 'learning_rate': 0.23812208281329955, 'min_child_samples': 32, 'max_depth': 10, 'feature_fraction': 0.977579072072423, 'bagging_fraction': 0.9913430783889023, 'bagging_freq': 2, 'lambda_l1': 3.744601193250797, 'lambda_l2': 7.085805321941195}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:30:52,563] Trial 16 finished with value: 829.8426953968805 and parameters: {'num_leaves': 85, 'learning_rate': 0.25005830524268685, 'min_child_samples': 34, 'max_depth': 10, 'feature_fraction': 0.98826210667186, 'bagging_fraction': 0.9839051683864238, 'bagging_freq': 2, 'lambda_l1': 3.8876919478638627, 'lambda_l2': 0.13179214380923554}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:30:55,651] Trial 17 finished with value: 837.0135234888076 and parameters: {'num_leaves': 86, 'learning_rate': 0.1367286480427689, 'min_child_samples': 33, 'max_depth': 10, 'feature_fraction': 0.9833898180659589, 'bagging_fraction': 0.9239821132404911, 'bagging_freq': 4, 'lambda_l1': 0.3630481323211834, 'lambda_l2': 9.948008035537754}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:30:58,779] Trial 18 finished with value: 865.6984858269009 and parameters: {'num_leaves': 86, 'learning_rate': 0.24080165094913625, 'min_child_samples': 41, 'max_depth': 6, 'feature_fraction': 0.9095336881172504, 'bagging_fraction': 0.9457995117435076, 'bagging_freq': 6, 'lambda_l1': 4.357469624538123, 'lambda_l2': 7.024197291755801}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:31:00,582] Trial 19 finished with value: 863.6451610827532 and parameters: {'num_leaves': 35, 'learning_rate': 0.16244265650172257, 'min_child_samples': 24, 'max_depth': 9, 'feature_fraction': 0.8440770194224896, 'bagging_fraction': 0.7869730869739291, 'bagging_freq': 3, 'lambda_l1': 7.1193695386383435, 'lambda_l2': 7.236364799111377}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:31:02,591] Trial 20 finished with value: 851.0168294442385 and parameters: {'num_leaves': 80, 'learning_rate': 0.29762483426517194, 'min_child_samples': 43, 'max_depth': 9, 'feature_fraction': 0.9476939712459647, 'bagging_fraction': 0.9192935333529579, 'bagging_freq': 1, 'lambda_l1': 2.416693120712215, 'lambda_l2': 3.974358253058724}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-21 20:31:04,920] Trial 21 finished with value: 820.0376579637274 and parameters: {'num_leaves': 90, 'learning_rate': 0.23681820581860302, 'min_child_samples': 26, 'max_depth': 10, 'feature_fraction': 0.9932206455418805, 'bagging_fraction': 0.9956917042908306, 'bagging_freq': 2, 'lambda_l1': 4.177306496037178, 'lambda_l2': 0.12550199367920242}. Best is trial 21 with value: 820.0376579637274.\n",
      "[I 2025-07-21 20:31:06,654] Trial 22 finished with value: 813.9634171612922 and parameters: {'num_leaves': 89, 'learning_rate': 0.22926627032742758, 'min_child_samples': 24, 'max_depth': 11, 'feature_fraction': 0.9925114051096695, 'bagging_fraction': 0.9969465653028303, 'bagging_freq': 1, 'lambda_l1': 4.3647828588546815, 'lambda_l2': 7.150604120240355}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:08,330] Trial 23 finished with value: 820.6660589447708 and parameters: {'num_leaves': 92, 'learning_rate': 0.26797136164517055, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.9400131173613442, 'bagging_fraction': 0.9994406932515424, 'bagging_freq': 3, 'lambda_l1': 4.5493952877479575, 'lambda_l2': 0.7592254223402448}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:09,798] Trial 24 finished with value: 832.2599836701345 and parameters: {'num_leaves': 91, 'learning_rate': 0.26108746705244795, 'min_child_samples': 19, 'max_depth': 11, 'feature_fraction': 0.9377518209778412, 'bagging_fraction': 0.9069576977760248, 'bagging_freq': 4, 'lambda_l1': 4.454771871746318, 'lambda_l2': 0.14579224689980322}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:11,415] Trial 25 finished with value: 827.4118145733287 and parameters: {'num_leaves': 92, 'learning_rate': 0.2681966255743236, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.8360490217951417, 'bagging_fraction': 0.9997631072285242, 'bagging_freq': 3, 'lambda_l1': 4.89141346540847, 'lambda_l2': 1.1366757726424068}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:14,226] Trial 26 finished with value: 853.9811376259078 and parameters: {'num_leaves': 65, 'learning_rate': 0.16699608602734356, 'min_child_samples': 42, 'max_depth': 11, 'feature_fraction': 0.855888008984883, 'bagging_fraction': 0.7787588257864038, 'bagging_freq': 1, 'lambda_l1': 1.698119125309197, 'lambda_l2': 1.3906554717810902}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:15,671] Trial 27 finished with value: 826.3079399006837 and parameters: {'num_leaves': 78, 'learning_rate': 0.22279186881297725, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.9363930934209518, 'bagging_fraction': 0.8976673683708202, 'bagging_freq': 5, 'lambda_l1': 3.727886430358488, 'lambda_l2': 3.2899951244808414}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:18,669] Trial 28 finished with value: 830.4241340852853 and parameters: {'num_leaves': 76, 'learning_rate': 0.13394655262891542, 'min_child_samples': 27, 'max_depth': 9, 'feature_fraction': 0.9586511086149871, 'bagging_fraction': 0.951176087760467, 'bagging_freq': 3, 'lambda_l1': 4.949132855010541, 'lambda_l2': 0.6784478531511889}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:20,654] Trial 29 finished with value: 1021.6276693190559 and parameters: {'num_leaves': 92, 'learning_rate': 0.2963883640360279, 'min_child_samples': 48, 'max_depth': 3, 'feature_fraction': 0.7172488564422614, 'bagging_fraction': 0.9614446966831018, 'bagging_freq': 1, 'lambda_l1': 3.2960388623897643, 'lambda_l2': 2.8431715544776233}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:22,361] Trial 30 finished with value: 853.2912849526887 and parameters: {'num_leaves': 92, 'learning_rate': 0.27653203948873, 'min_child_samples': 19, 'max_depth': 8, 'feature_fraction': 0.872117574190506, 'bagging_fraction': 0.8198854833066617, 'bagging_freq': 4, 'lambda_l1': 1.9800119770382478, 'lambda_l2': 1.0674765371015968}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:25,228] Trial 31 finished with value: 821.8519482550178 and parameters: {'num_leaves': 82, 'learning_rate': 0.2555777548022447, 'min_child_samples': 32, 'max_depth': 10, 'feature_fraction': 0.9657365469864623, 'bagging_fraction': 0.9991417930830018, 'bagging_freq': 2, 'lambda_l1': 3.866574849506398, 'lambda_l2': 7.65456750564721}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:27,806] Trial 32 finished with value: 819.1229574175021 and parameters: {'num_leaves': 81, 'learning_rate': 0.25919358911092033, 'min_child_samples': 29, 'max_depth': 11, 'feature_fraction': 0.9232104987886129, 'bagging_fraction': 0.9994902667235264, 'bagging_freq': 2, 'lambda_l1': 4.443275565042894, 'lambda_l2': 9.9688171199544}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:29,332] Trial 33 finished with value: 841.898801782214 and parameters: {'num_leaves': 95, 'learning_rate': 0.28199888076032403, 'min_child_samples': 17, 'max_depth': 11, 'feature_fraction': 0.9176856338607613, 'bagging_fraction': 0.8941193353020506, 'bagging_freq': 2, 'lambda_l1': 5.361849397419923, 'lambda_l2': 9.609280673436176}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:30,581] Trial 34 finished with value: 843.3467460830101 and parameters: {'num_leaves': 74, 'learning_rate': 0.22647538502975628, 'min_child_samples': 27, 'max_depth': 12, 'feature_fraction': 0.935470777808525, 'bagging_fraction': 0.9654261897650135, 'bagging_freq': 1, 'lambda_l1': 4.484117516383502, 'lambda_l2': 9.27389531609602}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:32,385] Trial 35 finished with value: 880.3243717689917 and parameters: {'num_leaves': 60, 'learning_rate': 0.17996038645895326, 'min_child_samples': 37, 'max_depth': 11, 'feature_fraction': 0.8239453932382725, 'bagging_fraction': 0.6405945324376946, 'bagging_freq': 5, 'lambda_l1': 3.1090116033739936, 'lambda_l2': 5.23722137934546}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:34,215] Trial 36 finished with value: 838.5793734085067 and parameters: {'num_leaves': 90, 'learning_rate': 0.2618863041528528, 'min_child_samples': 26, 'max_depth': 8, 'feature_fraction': 0.998434508044055, 'bagging_fraction': 0.929414802173654, 'bagging_freq': 3, 'lambda_l1': 6.717816393831111, 'lambda_l2': 1.89241715366098}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:35,908] Trial 37 finished with value: 867.7543930764988 and parameters: {'num_leaves': 81, 'learning_rate': 0.1952707684278006, 'min_child_samples': 15, 'max_depth': 9, 'feature_fraction': 0.7103435493235871, 'bagging_fraction': 0.7096763211890255, 'bagging_freq': 2, 'lambda_l1': 4.7228181538998815, 'lambda_l2': 8.296391937239637}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:38,559] Trial 38 finished with value: 858.700377028276 and parameters: {'num_leaves': 57, 'learning_rate': 0.21620507769553424, 'min_child_samples': 61, 'max_depth': 7, 'feature_fraction': 0.8877181903276369, 'bagging_fraction': 0.9688035405842793, 'bagging_freq': 1, 'lambda_l1': 2.5676452988080394, 'lambda_l2': 4.569968124217928}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:39,596] Trial 39 finished with value: 825.1262187365535 and parameters: {'num_leaves': 66, 'learning_rate': 0.28548936418147675, 'min_child_samples': 5, 'max_depth': 12, 'feature_fraction': 0.8091699477532056, 'bagging_fraction': 0.9347125554517861, 'bagging_freq': 3, 'lambda_l1': 3.4428315378357395, 'lambda_l2': 2.5438533654937885}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:42,944] Trial 40 finished with value: 843.827164840684 and parameters: {'num_leaves': 71, 'learning_rate': 0.06362065129104016, 'min_child_samples': 51, 'max_depth': 11, 'feature_fraction': 0.9177931201104805, 'bagging_fraction': 0.5887663591658137, 'bagging_freq': 0, 'lambda_l1': 5.329173035841281, 'lambda_l2': 0.5519654290902357}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:44,850] Trial 41 finished with value: 821.3183941768766 and parameters: {'num_leaves': 81, 'learning_rate': 0.2528348565646795, 'min_child_samples': 29, 'max_depth': 10, 'feature_fraction': 0.9575551669333756, 'bagging_fraction': 0.9975008705536783, 'bagging_freq': 2, 'lambda_l1': 4.145007331396462, 'lambda_l2': 7.647699416822267}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:46,221] Trial 42 finished with value: 820.67464463946 and parameters: {'num_leaves': 89, 'learning_rate': 0.2704594825582398, 'min_child_samples': 11, 'max_depth': 10, 'feature_fraction': 0.9591334877107154, 'bagging_fraction': 0.9735918884040877, 'bagging_freq': 2, 'lambda_l1': 4.252964142796664, 'lambda_l2': 8.757527019763153}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:47,311] Trial 43 finished with value: 848.4330446069383 and parameters: {'num_leaves': 89, 'learning_rate': 0.29866145765443847, 'min_child_samples': 13, 'max_depth': 9, 'feature_fraction': 0.8703583554194936, 'bagging_fraction': 0.8830839626320757, 'bagging_freq': 1, 'lambda_l1': 5.190319199558725, 'lambda_l2': 8.782486901800414}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:49,027] Trial 44 finished with value: 828.1874793042049 and parameters: {'num_leaves': 95, 'learning_rate': 0.2668534670527767, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.9743570523613105, 'bagging_fraction': 0.9738587621828848, 'bagging_freq': 9, 'lambda_l1': 3.082282997872249, 'lambda_l2': 9.15327167340185}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:50,321] Trial 45 finished with value: 825.7960945587848 and parameters: {'num_leaves': 97, 'learning_rate': 0.2740062551524419, 'min_child_samples': 9, 'max_depth': 10, 'feature_fraction': 0.8978189484089897, 'bagging_fraction': 0.9708402386038576, 'bagging_freq': 4, 'lambda_l1': 5.698171213693797, 'lambda_l2': 9.61906279577542}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:51,907] Trial 46 finished with value: 846.1303831600819 and parameters: {'num_leaves': 37, 'learning_rate': 0.23668600624280037, 'min_child_samples': 38, 'max_depth': 12, 'feature_fraction': 0.9278013691342434, 'bagging_fraction': 0.9304515385864465, 'bagging_freq': 6, 'lambda_l1': 4.113526549204541, 'lambda_l2': 6.526696063465382}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:53,454] Trial 47 finished with value: 819.8261701060943 and parameters: {'num_leaves': 88, 'learning_rate': 0.20650668957652968, 'min_child_samples': 20, 'max_depth': 11, 'feature_fraction': 0.9610278577340667, 'bagging_fraction': 0.974208788664251, 'bagging_freq': 0, 'lambda_l1': 8.359030379476582, 'lambda_l2': 8.300383269727488}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-21 20:31:55,154] Trial 48 finished with value: 810.4305674395371 and parameters: {'num_leaves': 76, 'learning_rate': 0.20551927855538374, 'min_child_samples': 20, 'max_depth': 12, 'feature_fraction': 0.9966022144448774, 'bagging_fraction': 0.9491919674871573, 'bagging_freq': 0, 'lambda_l1': 9.803954066886053, 'lambda_l2': 8.237537989929509}. Best is trial 48 with value: 810.4305674395371.\n",
      "[I 2025-07-21 20:31:57,024] Trial 49 finished with value: 829.339705124722 and parameters: {'num_leaves': 75, 'learning_rate': 0.20107457868868983, 'min_child_samples': 46, 'max_depth': 12, 'feature_fraction': 0.9960787598611138, 'bagging_fraction': 0.8803713749062628, 'bagging_freq': 0, 'lambda_l1': 9.819156057142715, 'lambda_l2': 8.116882637830772}. Best is trial 48 with value: 810.4305674395371.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 76, 'learning_rate': 0.20551927855538374, 'min_child_samples': 20, 'max_depth': 12, 'feature_fraction': 0.9966022144448774, 'bagging_fraction': 0.9491919674871573, 'bagging_freq': 0, 'lambda_l1': 9.803954066886053, 'lambda_l2': 8.237537989929509}\n",
      "Best RMSE on validation set during tuning (Optuna): 810.43\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize\n",
    "study_p01 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) # Add seed for reproducibility\n",
    "study_p01.optimize(objective_p01, n_trials=50, show_progress_bar=True) # show_progress_bar for better UX\n",
    "\n",
    "# Best parameters and best RMSE found by Optuna\n",
    "best_params_p01 = study_p01.best_params\n",
    "best_rmse_optuna_p01 = study_p01.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p01)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p01:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p02:\n",
      "RMSE: 818.90\n",
      "R²: 0.8157\n"
     ]
    }
   ],
   "source": [
    "final_model_p01 = lgb.train(best_params_p01,\n",
    "                            lgb.Dataset(X_train_p01, label=y_train_p01),\n",
    "                            num_boost_round=1000) # Use best iteration from Optuna's best trial\n",
    "\n",
    "# Make predictions on the truly unseen test set\n",
    "y_pred_final_p01 = final_model_p01.predict(X_test_p01)\n",
    "\n",
    "# Evaluate the final model's performance on the test set\n",
    "rmse_final_p01 = np.sqrt(mean_squared_error(y_test_p01, y_pred_final_p01))\n",
    "r2_final_p01 = r2_score(y_test_p01, y_pred_final_p01)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p01:\")\n",
    "print(f\"RMSE: {rmse_final_p01:.2f}\")\n",
    "print(f\"R²: {r2_final_p01:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_needed_trains(predicted_passengers_series: pd.Series,\n",
    "                            train_capacity: int = 600,\n",
    "                            safety_buffer_percentage: float = 0.05,\n",
    "                            minimum_trains_required: int = 1) -> pd.DataFrame:\n",
    "\n",
    "    predicted_passengers_int = predicted_passengers_series.astype(int)\n",
    "\n",
    "    # Create a DataFrame to hold the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Predicted_Passengers': predicted_passengers_int\n",
    "    })\n",
    "\n",
    "    # 1. Calculate the base number of trains needed (minimum required)\n",
    "    # np.ceil ensures that any fraction of a train needed results in a full additional train.\n",
    "    result_df['Base_Predicted_Trains'] = np.ceil(\n",
    "        result_df['Predicted_Passengers'] / train_capacity\n",
    "    ).astype(int)\n",
    "\n",
    "    # 2. Calculate trains with a safety/comfort buffer\n",
    "    # This adds a percentage buffer to the predicted passengers before dividing by capacity.\n",
    "    result_df['Buffered_Predicted_Trains'] = np.ceil(\n",
    "        result_df['Predicted_Passengers'] * (1 + safety_buffer_percentage) / train_capacity\n",
    "    ).astype(int)\n",
    "\n",
    "    # 3. Ensure a minimum number of trains\n",
    "    # This ensures that even for very low passenger counts, a base service level is maintained.\n",
    "    result_df['Final_Predicted_Trains'] = result_df['Buffered_Predicted_Trains'].apply(\n",
    "        lambda x: max(x, minimum_trains_required)\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Passengers</th>\n",
       "      <th>Base_Predicted_Trains</th>\n",
       "      <th>Buffered_Predicted_Trains</th>\n",
       "      <th>Final_Predicted_Trains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11777</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>2739</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11105</th>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>5202</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11604</th>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_Passengers  Base_Predicted_Trains  Buffered_Predicted_Trains  \\\n",
       "11777                    99                      1                          1   \n",
       "1539                   2739                      5                          5   \n",
       "4365                    565                      1                          1   \n",
       "1191                    576                      1                          2   \n",
       "11105                   191                      1                          1   \n",
       "51                      612                      2                          2   \n",
       "2275                   5202                      9                         10   \n",
       "5985                    204                      1                          1   \n",
       "6473                     17                      1                          1   \n",
       "11604                   125                      1                          1   \n",
       "\n",
       "       Final_Predicted_Trains  \n",
       "11777                       1  \n",
       "1539                        5  \n",
       "4365                        1  \n",
       "1191                        2  \n",
       "11105                       1  \n",
       "51                          2  \n",
       "2275                       10  \n",
       "5985                        1  \n",
       "6473                        1  \n",
       "11604                       1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_p01= calculate_needed_trains(y_pred_final_p01)\n",
    "y_pred_train_p01.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Two:\n",
    " Assume we need to forecast the number of passengers for different time periods in order to allocate the appropriate number of trains one week in advance. (In this case, we are allowed to use information from previous time periods, but using the year and number of trains columns is still not permitted.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p02(df, target_column='Ridership', train_size=0.8):\n",
    "    # Convert Year, Month_Num, and Day to a datetime object\n",
    "    df['Date'] = pd.to_datetime(\n",
    "        df['Year'].astype(str) + '-' +\n",
    "        df['Month_Num'].astype(str) + '-' +\n",
    "        df['Day'].astype(str),\n",
    "        errors='coerce'  # Handle potential invalid dates by setting them to NaT\n",
    "    )\n",
    "\n",
    "    # Drop rows with invalid dates\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    # Grouping columns for creating lagged features\n",
    "    grouping_cols = [\n",
    "        col for col in df.columns if col.startswith('Corridor_') or\n",
    "        col.startswith('Station_') or\n",
    "        col.startswith('Period_')\n",
    "    ]\n",
    "\n",
    "    # Create lagged features for 'Passengers'\n",
    "    # Lag 7 days (for same day of week, same period, etc., one week prior)\n",
    "    df['Ridership_Lag_7'] = df.groupby(grouping_cols)['Ridership'].shift(7)\n",
    "\n",
    "    # Lag 14 days (for same day of week, same period, two weeks prior)\n",
    "    df['Ridership_Lag_14'] = df.groupby(grouping_cols)['Ridership'].shift(14)\n",
    "\n",
    "    # Drop rows with NaN values in lagged features\n",
    "    df.dropna(subset=['Ridership_Lag_7', 'Ridership_Lag_14'], inplace=True)\n",
    "    \n",
    "    # Reset index after dropping NaNs\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Sort by Date\n",
    "    df.sort_values(by=['Date'], inplace=True)\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column, 'Year', 'N_trains', 'Date'])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Calculate split point\n",
    "    split_point = int(len(df) * train_size)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X.iloc[:split_point]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    \n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_test = y.iloc[split_point:]\n",
    "\n",
    "    # Print shapes of the resulting datasets\n",
    "    print(f\"\\nTrain set features (X_train) shape: {X_train.shape}\")\n",
    "    print(f\"Test set features (X_test) shape: {X_test.shape}\")\n",
    "    print(f\"Train set target (y_train) shape: {y_train.shape}\")\n",
    "    print(f\"Test set target (y_test) shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set features (X_train) shape: (49951, 82)\n",
      "Test set features (X_test) shape: (12488, 82)\n",
      "Train set target (y_train) shape: (49951,)\n",
      "Test set target (y_test) shape: (12488,)\n"
     ]
    }
   ],
   "source": [
    "X_train_p02, X_test_p02, y_train_p02, y_test_p02 = preprocess_and_split_data_p02(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p02(trial):\n",
    "    # Define parameters to be optimized by Optuna\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False # Disable feature pre-filtering\n",
    "    }\n",
    "\n",
    "    # Convert data to LightGBM Dataset format\n",
    "    # Use X_train_p02 for training, and X_test_p02 as the validation set\n",
    "    # This ensures that Optuna's reported best value is a good generalization estimate.\n",
    "    train_data = lgb.Dataset(X_train_p02, label=y_train_p02)\n",
    "    test_data = lgb.Dataset(X_test_p02, label=y_test_p02, reference=train_data)\n",
    "\n",
    "    # Train the model with early stopping on the validation set\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000, # Max boosting rounds\n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) # verbose=False to reduce output\n",
    "\n",
    "    # Make predictions on the validation set using the best iteration\n",
    "    y_pred = model.predict(X_test_p02, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Return RMSE as the objective value to minimize\n",
    "    return np.sqrt(mean_squared_error(y_test_p02, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 20:47:28,545] A new study created in memory with name: no-name-4e6b2d7e-fc20-49ea-a378-c16cce24d001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948078e52ccc4690a245f485f60c7bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 20:47:29,287] Trial 0 finished with value: 749.983216692356 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 749.983216692356.\n",
      "[I 2025-07-21 20:47:33,418] Trial 1 finished with value: 689.8169979283266 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 1 with value: 689.8169979283266.\n",
      "[I 2025-07-21 20:47:34,075] Trial 2 finished with value: 669.6805520970248 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-21 20:47:34,674] Trial 3 finished with value: 743.4659716391809 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-21 20:47:35,100] Trial 4 finished with value: 738.0206947253275 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-21 20:47:36,096] Trial 5 finished with value: 723.748016964836 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-21 20:47:36,639] Trial 6 finished with value: 687.8883464626696 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-21 20:47:37,270] Trial 7 finished with value: 656.3349160468297 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-21 20:47:37,715] Trial 8 finished with value: 659.0457370327476 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-21 20:47:38,280] Trial 9 finished with value: 659.7131205498853 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-21 20:47:39,110] Trial 10 finished with value: 656.6294958379173 and parameters: {'num_leaves': 96, 'learning_rate': 0.1874718576067958, 'min_child_samples': 34, 'max_depth': 3, 'feature_fraction': 0.9905354130446519, 'bagging_fraction': 0.8451235367845726, 'bagging_freq': 10, 'lambda_l1': 6.240835271723655, 'lambda_l2': 0.3979960607701478}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-21 20:47:39,781] Trial 11 finished with value: 655.1309264329091 and parameters: {'num_leaves': 100, 'learning_rate': 0.1773053455084359, 'min_child_samples': 32, 'max_depth': 3, 'feature_fraction': 0.995366008349641, 'bagging_fraction': 0.8513496163789993, 'bagging_freq': 10, 'lambda_l1': 6.16211739462904, 'lambda_l2': 0.04673570702773894}. Best is trial 11 with value: 655.1309264329091.\n",
      "[I 2025-07-21 20:47:40,473] Trial 12 finished with value: 643.3669432771432 and parameters: {'num_leaves': 34, 'learning_rate': 0.1452170025057517, 'min_child_samples': 35, 'max_depth': 5, 'feature_fraction': 0.8810709338789753, 'bagging_fraction': 0.8588729908849949, 'bagging_freq': 8, 'lambda_l1': 5.836177658376659, 'lambda_l2': 0.031071995147729885}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:41,236] Trial 13 finished with value: 649.1442460882886 and parameters: {'num_leaves': 29, 'learning_rate': 0.15912464772022475, 'min_child_samples': 35, 'max_depth': 6, 'feature_fraction': 0.8080673413914532, 'bagging_fraction': 0.8846915468913171, 'bagging_freq': 7, 'lambda_l1': 5.273501315332378, 'lambda_l2': 0.18292032726393373}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:41,761] Trial 14 finished with value: 663.1011574162833 and parameters: {'num_leaves': 28, 'learning_rate': 0.23079417685695425, 'min_child_samples': 40, 'max_depth': 6, 'feature_fraction': 0.7817421205832107, 'bagging_fraction': 0.9501945220447685, 'bagging_freq': 7, 'lambda_l1': 4.584302328362351, 'lambda_l2': 3.465514216694958}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:42,266] Trial 15 finished with value: 658.6184949954255 and parameters: {'num_leaves': 33, 'learning_rate': 0.15906076637112665, 'min_child_samples': 24, 'max_depth': 6, 'feature_fraction': 0.7788514614387833, 'bagging_fraction': 0.9117177726127699, 'bagging_freq': 8, 'lambda_l1': 4.373242307868379, 'lambda_l2': 1.1704182500408697}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:42,890] Trial 16 finished with value: 646.2363482380266 and parameters: {'num_leaves': 33, 'learning_rate': 0.135213347715731, 'min_child_samples': 46, 'max_depth': 5, 'feature_fraction': 0.8607349956827239, 'bagging_fraction': 0.788474586944839, 'bagging_freq': 6, 'lambda_l1': 6.439586532363955, 'lambda_l2': 3.58390284790542}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:43,702] Trial 17 finished with value: 647.6678545062273 and parameters: {'num_leaves': 39, 'learning_rate': 0.13649978960074022, 'min_child_samples': 46, 'max_depth': 5, 'feature_fraction': 0.8628799715054529, 'bagging_fraction': 0.7956399834425625, 'bagging_freq': 6, 'lambda_l1': 7.183830296409637, 'lambda_l2': 6.71236967350552}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:44,305] Trial 18 finished with value: 650.7089308400331 and parameters: {'num_leaves': 21, 'learning_rate': 0.056253492681493614, 'min_child_samples': 22, 'max_depth': 12, 'feature_fraction': 0.7077851292555184, 'bagging_fraction': 0.7607668789167329, 'bagging_freq': 5, 'lambda_l1': 3.42435982518749, 'lambda_l2': 3.9929464831880646}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:44,900] Trial 19 finished with value: 645.5612749537578 and parameters: {'num_leaves': 35, 'learning_rate': 0.1287000223369303, 'min_child_samples': 89, 'max_depth': 5, 'feature_fraction': 0.9218466062580651, 'bagging_fraction': 0.7975119753911437, 'bagging_freq': 8, 'lambda_l1': 6.427654544859113, 'lambda_l2': 3.1786691104821063}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:45,608] Trial 20 finished with value: 652.6728412329276 and parameters: {'num_leaves': 41, 'learning_rate': 0.20156011128754445, 'min_child_samples': 100, 'max_depth': 7, 'feature_fraction': 0.9491201445921722, 'bagging_fraction': 0.6988253157652793, 'bagging_freq': 9, 'lambda_l1': 0.11620961627552973, 'lambda_l2': 9.938427850497089}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:46,274] Trial 21 finished with value: 645.4092369709537 and parameters: {'num_leaves': 35, 'learning_rate': 0.13054114622046276, 'min_child_samples': 83, 'max_depth': 5, 'feature_fraction': 0.8339511894660561, 'bagging_fraction': 0.8114948890256886, 'bagging_freq': 8, 'lambda_l1': 6.445252637000118, 'lambda_l2': 3.248552738642576}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:47,148] Trial 22 finished with value: 645.9174062201375 and parameters: {'num_leaves': 37, 'learning_rate': 0.126029571589249, 'min_child_samples': 84, 'max_depth': 5, 'feature_fraction': 0.9314766787996078, 'bagging_fraction': 0.8152508113761574, 'bagging_freq': 8, 'lambda_l1': 5.219697599632305, 'lambda_l2': 2.2353485301100404}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:48,418] Trial 23 finished with value: 646.6302375000674 and parameters: {'num_leaves': 26, 'learning_rate': 0.0734408985579082, 'min_child_samples': 87, 'max_depth': 5, 'feature_fraction': 0.8322410276077967, 'bagging_fraction': 0.9241004407247386, 'bagging_freq': 9, 'lambda_l1': 7.046441690343867, 'lambda_l2': 1.166736901221074}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:48,956] Trial 24 finished with value: 683.4301451113315 and parameters: {'num_leaves': 57, 'learning_rate': 0.12699401178827283, 'min_child_samples': 89, 'max_depth': 3, 'feature_fraction': 0.7446195108134603, 'bagging_fraction': 0.7346296910830256, 'bagging_freq': 9, 'lambda_l1': 5.616746902209391, 'lambda_l2': 2.9348184817284393}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:49,677] Trial 25 finished with value: 648.3607652154126 and parameters: {'num_leaves': 45, 'learning_rate': 0.21471322298661788, 'min_child_samples': 79, 'max_depth': 4, 'feature_fraction': 0.9376122958679955, 'bagging_fraction': 0.8272029104292995, 'bagging_freq': 6, 'lambda_l1': 4.19559385057863, 'lambda_l2': 4.7338862979250775}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:50,234] Trial 26 finished with value: 646.3652488725002 and parameters: {'num_leaves': 33, 'learning_rate': 0.1476763664405195, 'min_child_samples': 63, 'max_depth': 7, 'feature_fraction': 0.8325873147129733, 'bagging_fraction': 0.8812829080304145, 'bagging_freq': 8, 'lambda_l1': 6.939278825456193, 'lambda_l2': 0.9912893999946736}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-21 20:47:51,252] Trial 27 finished with value: 642.2479870020248 and parameters: {'num_leaves': 25, 'learning_rate': 0.11602453150780333, 'min_child_samples': 93, 'max_depth': 5, 'feature_fraction': 0.9046221986498096, 'bagging_fraction': 0.783666961304615, 'bagging_freq': 7, 'lambda_l1': 8.331649083694579, 'lambda_l2': 6.094934702074951}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:52,404] Trial 28 finished with value: 655.8900070689391 and parameters: {'num_leaves': 25, 'learning_rate': 0.07222267390301056, 'min_child_samples': 97, 'max_depth': 6, 'feature_fraction': 0.7285545670206393, 'bagging_fraction': 0.637167495253871, 'bagging_freq': 7, 'lambda_l1': 8.159815924501153, 'lambda_l2': 6.412120024896554}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:53,392] Trial 29 finished with value: 653.4710277421298 and parameters: {'num_leaves': 50, 'learning_rate': 0.10779931122123985, 'min_child_samples': 79, 'max_depth': 9, 'feature_fraction': 0.8740759397384257, 'bagging_fraction': 0.7186498417448955, 'bagging_freq': 5, 'lambda_l1': 8.398384561816135, 'lambda_l2': 6.9059352240929925}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:53,942] Trial 30 finished with value: 644.6104056442806 and parameters: {'num_leaves': 62, 'learning_rate': 0.16991948970675974, 'min_child_samples': 92, 'max_depth': 4, 'feature_fraction': 0.9597977223447893, 'bagging_fraction': 0.7742516139395101, 'bagging_freq': 9, 'lambda_l1': 5.720014378176846, 'lambda_l2': 5.665862286994643}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:54,632] Trial 31 finished with value: 650.7884906810744 and parameters: {'num_leaves': 62, 'learning_rate': 0.16730151622855652, 'min_child_samples': 94, 'max_depth': 4, 'feature_fraction': 0.9713569478401963, 'bagging_fraction': 0.7779579149421749, 'bagging_freq': 9, 'lambda_l1': 7.387672491911572, 'lambda_l2': 5.508094470559812}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:55,348] Trial 32 finished with value: 657.35378318791 and parameters: {'num_leaves': 82, 'learning_rate': 0.20105904255735446, 'min_child_samples': 92, 'max_depth': 3, 'feature_fraction': 0.9166388107015678, 'bagging_fraction': 0.8340677464225512, 'bagging_freq': 9, 'lambda_l1': 5.742663202706927, 'lambda_l2': 7.511230180380133}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:56,445] Trial 33 finished with value: 650.5845307625218 and parameters: {'num_leaves': 85, 'learning_rate': 0.15060420742838432, 'min_child_samples': 82, 'max_depth': 4, 'feature_fraction': 0.9613125696656442, 'bagging_fraction': 0.7581103993016662, 'bagging_freq': 7, 'lambda_l1': 9.988200120500538, 'lambda_l2': 5.760841457862635}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:57,221] Trial 34 finished with value: 646.716763403262 and parameters: {'num_leaves': 64, 'learning_rate': 0.11535794516921064, 'min_child_samples': 76, 'max_depth': 5, 'feature_fraction': 0.8408240608642056, 'bagging_fraction': 0.7097699238053233, 'bagging_freq': 6, 'lambda_l1': 4.883985951949358, 'lambda_l2': 4.214139442352147}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:58,173] Trial 35 finished with value: 653.8084544486051 and parameters: {'num_leaves': 54, 'learning_rate': 0.07829563718932561, 'min_child_samples': 61, 'max_depth': 7, 'feature_fraction': 0.8015504856428303, 'bagging_fraction': 0.631101658030822, 'bagging_freq': 8, 'lambda_l1': 3.514586106014889, 'lambda_l2': 7.274377303429189}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:47:59,607] Trial 36 finished with value: 646.1213051747918 and parameters: {'num_leaves': 43, 'learning_rate': 0.03911376189489073, 'min_child_samples': 67, 'max_depth': 4, 'feature_fraction': 0.8983632649874882, 'bagging_fraction': 0.8912041625953747, 'bagging_freq': 0, 'lambda_l1': 7.809892640399617, 'lambda_l2': 6.045137292167471}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:48:00,189] Trial 37 finished with value: 648.1158827551692 and parameters: {'num_leaves': 55, 'learning_rate': 0.173190603159251, 'min_child_samples': 100, 'max_depth': 8, 'feature_fraction': 0.8528437814025002, 'bagging_fraction': 0.8150225814424858, 'bagging_freq': 1, 'lambda_l1': 2.4606828135220837, 'lambda_l2': 4.745808065727184}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-21 20:48:01,087] Trial 38 finished with value: 641.8393155044645 and parameters: {'num_leaves': 24, 'learning_rate': 0.14484235439461707, 'min_child_samples': 92, 'max_depth': 5, 'feature_fraction': 0.899527500582647, 'bagging_fraction': 0.7352118146218567, 'bagging_freq': 9, 'lambda_l1': 6.738496571577695, 'lambda_l2': 6.286830495685695}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:01,964] Trial 39 finished with value: 663.5941358756594 and parameters: {'num_leaves': 22, 'learning_rate': 0.0878973526453253, 'min_child_samples': 95, 'max_depth': 4, 'feature_fraction': 0.9757893595827343, 'bagging_fraction': 0.6508891267720402, 'bagging_freq': 10, 'lambda_l1': 8.569141839199698, 'lambda_l2': 5.255002319925984}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:02,615] Trial 40 finished with value: 662.1822075601177 and parameters: {'num_leaves': 75, 'learning_rate': 0.19252671683366168, 'min_child_samples': 49, 'max_depth': 9, 'feature_fraction': 0.9003608553973999, 'bagging_fraction': 0.5972212620328471, 'bagging_freq': 4, 'lambda_l1': 9.284885610341519, 'lambda_l2': 6.1594981286080515}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:03,362] Trial 41 finished with value: 648.1300135204136 and parameters: {'num_leaves': 31, 'learning_rate': 0.14188107626353286, 'min_child_samples': 85, 'max_depth': 5, 'feature_fraction': 0.8960162962838928, 'bagging_fraction': 0.6784705423497785, 'bagging_freq': 9, 'lambda_l1': 6.701103372944639, 'lambda_l2': 7.861380343192393}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:04,308] Trial 42 finished with value: 656.0932386643004 and parameters: {'num_leaves': 25, 'learning_rate': 0.11792288528147803, 'min_child_samples': 91, 'max_depth': 6, 'feature_fraction': 0.9537107495417143, 'bagging_fraction': 0.7374671494653139, 'bagging_freq': 8, 'lambda_l1': 5.624478986539984, 'lambda_l2': 5.204736785003092}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:04,873] Trial 43 finished with value: 648.121100000118 and parameters: {'num_leaves': 38, 'learning_rate': 0.1618940814165552, 'min_child_samples': 5, 'max_depth': 5, 'feature_fraction': 0.8775274413179482, 'bagging_fraction': 0.7720319789414302, 'bagging_freq': 9, 'lambda_l1': 7.563524305489988, 'lambda_l2': 4.102951228480186}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:05,857] Trial 44 finished with value: 654.8832877035479 and parameters: {'num_leaves': 47, 'learning_rate': 0.2771620089346378, 'min_child_samples': 74, 'max_depth': 3, 'feature_fraction': 0.8160823576525675, 'bagging_fraction': 0.8612368697757115, 'bagging_freq': 10, 'lambda_l1': 5.999318872336445, 'lambda_l2': 6.634177333066056}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:06,774] Trial 45 finished with value: 647.6971499047419 and parameters: {'num_leaves': 68, 'learning_rate': 0.09941591019858205, 'min_child_samples': 81, 'max_depth': 6, 'feature_fraction': 0.9190400811932736, 'bagging_fraction': 0.807661374617237, 'bagging_freq': 7, 'lambda_l1': 8.070893069398121, 'lambda_l2': 1.7669971521570182}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:07,455] Trial 46 finished with value: 645.4125271065061 and parameters: {'num_leaves': 29, 'learning_rate': 0.18005088355765794, 'min_child_samples': 96, 'max_depth': 4, 'feature_fraction': 0.9982409522597624, 'bagging_fraction': 0.7362857802752619, 'bagging_freq': 8, 'lambda_l1': 4.986414072301393, 'lambda_l2': 7.130250969885596}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:08,162] Trial 47 finished with value: 642.5412437117075 and parameters: {'num_leaves': 23, 'learning_rate': 0.15274350455168356, 'min_child_samples': 27, 'max_depth': 6, 'feature_fraction': 0.7856520657906572, 'bagging_fraction': 0.9956462991577971, 'bagging_freq': 10, 'lambda_l1': 6.818516872579354, 'lambda_l2': 5.943552499663844}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:08,680] Trial 48 finished with value: 652.982467034955 and parameters: {'num_leaves': 20, 'learning_rate': 0.15401140547780628, 'min_child_samples': 24, 'max_depth': 6, 'feature_fraction': 0.6818962697263993, 'bagging_fraction': 0.9613468179380777, 'bagging_freq': 10, 'lambda_l1': 6.712902860774687, 'lambda_l2': 5.888787075468496}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:09,229] Trial 49 finished with value: 649.1898157736196 and parameters: {'num_leaves': 24, 'learning_rate': 0.22078535454878528, 'min_child_samples': 15, 'max_depth': 7, 'feature_fraction': 0.7761025258482941, 'bagging_fraction': 0.9979341249501786, 'bagging_freq': 10, 'lambda_l1': 8.875949852599213, 'lambda_l2': 5.609581300355998}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:09,958] Trial 50 finished with value: 694.4880991065365 and parameters: {'num_leaves': 29, 'learning_rate': 0.16935842437868037, 'min_child_samples': 38, 'max_depth': 6, 'feature_fraction': 0.6406840792895764, 'bagging_fraction': 0.9463300214494845, 'bagging_freq': 9, 'lambda_l1': 4.042515303398181, 'lambda_l2': 6.302690399822815}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:10,559] Trial 51 finished with value: 655.0065638299592 and parameters: {'num_leaves': 50, 'learning_rate': 0.14075647137890385, 'min_child_samples': 30, 'max_depth': 5, 'feature_fraction': 0.7651907985175611, 'bagging_fraction': 0.7776726879304345, 'bagging_freq': 10, 'lambda_l1': 6.326118463904445, 'lambda_l2': 4.923089499769324}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:11,278] Trial 52 finished with value: 644.0045994736063 and parameters: {'num_leaves': 23, 'learning_rate': 0.1133662752705894, 'min_child_samples': 20, 'max_depth': 5, 'feature_fraction': 0.8093235334157599, 'bagging_fraction': 0.8467045355844418, 'bagging_freq': 9, 'lambda_l1': 6.045178309305462, 'lambda_l2': 4.369967279440312}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:12,111] Trial 53 finished with value: 648.3684268390116 and parameters: {'num_leaves': 23, 'learning_rate': 0.1160424164629642, 'min_child_samples': 18, 'max_depth': 4, 'feature_fraction': 0.7958655414908153, 'bagging_fraction': 0.8521534953007521, 'bagging_freq': 9, 'lambda_l1': 5.721225145832057, 'lambda_l2': 7.867199068560046}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:12,866] Trial 54 finished with value: 701.7508103569509 and parameters: {'num_leaves': 20, 'learning_rate': 0.19034334983349036, 'min_child_samples': 31, 'max_depth': 5, 'feature_fraction': 0.5341503889048508, 'bagging_fraction': 0.9051127578264078, 'bagging_freq': 10, 'lambda_l1': 7.331733748221638, 'lambda_l2': 8.803755569546428}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:13,974] Trial 55 finished with value: 649.0735813066904 and parameters: {'num_leaves': 27, 'learning_rate': 0.08528703629232853, 'min_child_samples': 27, 'max_depth': 4, 'feature_fraction': 0.8816321660419906, 'bagging_fraction': 0.930977071385424, 'bagging_freq': 9, 'lambda_l1': 5.969289644162204, 'lambda_l2': 5.439536878634853}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:14,673] Trial 56 finished with value: 644.9567174936017 and parameters: {'num_leaves': 31, 'learning_rate': 0.10563677426177673, 'min_child_samples': 20, 'max_depth': 6, 'feature_fraction': 0.7514080722582499, 'bagging_fraction': 0.6887425903565367, 'bagging_freq': 7, 'lambda_l1': 5.335017780694695, 'lambda_l2': 4.347691310288041}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:15,297] Trial 57 finished with value: 653.059723218389 and parameters: {'num_leaves': 59, 'learning_rate': 0.1468337580949696, 'min_child_samples': 38, 'max_depth': 5, 'feature_fraction': 0.850411889158109, 'bagging_fraction': 0.5070587568226921, 'bagging_freq': 8, 'lambda_l1': 6.803284186030429, 'lambda_l2': 9.544300677624099}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:16,322] Trial 58 finished with value: 666.4395644505322 and parameters: {'num_leaves': 23, 'learning_rate': 0.11880336391037055, 'min_child_samples': 55, 'max_depth': 3, 'feature_fraction': 0.8176054195945741, 'bagging_fraction': 0.9760673789164138, 'bagging_freq': 10, 'lambda_l1': 4.666292325286676, 'lambda_l2': 6.598042889571558}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-21 20:48:18,767] Trial 59 finished with value: 635.1092577146112 and parameters: {'num_leaves': 27, 'learning_rate': 0.013543841701209036, 'min_child_samples': 14, 'max_depth': 12, 'feature_fraction': 0.9430131088297382, 'bagging_fraction': 0.8342363451652917, 'bagging_freq': 9, 'lambda_l1': 5.292869960470173, 'lambda_l2': 7.376802833555514}. Best is trial 59 with value: 635.1092577146112.\n",
      "[I 2025-07-21 20:48:21,069] Trial 60 finished with value: 636.7948566050339 and parameters: {'num_leaves': 35, 'learning_rate': 0.011658337995168341, 'min_child_samples': 11, 'max_depth': 12, 'feature_fraction': 0.9376655622784418, 'bagging_fraction': 0.8754629919697009, 'bagging_freq': 6, 'lambda_l1': 5.150198752570424, 'lambda_l2': 8.27180990021555}. Best is trial 59 with value: 635.1092577146112.\n",
      "[I 2025-07-21 20:48:23,917] Trial 61 finished with value: 634.7214999200908 and parameters: {'num_leaves': 35, 'learning_rate': 0.0134290995004515, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9340245302057317, 'bagging_fraction': 0.8801065170857094, 'bagging_freq': 6, 'lambda_l1': 5.36583891949173, 'lambda_l2': 8.133502515855712}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-21 20:48:25,954] Trial 62 finished with value: 636.5880552660823 and parameters: {'num_leaves': 36, 'learning_rate': 0.013426581533714038, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9411061462129773, 'bagging_fraction': 0.8818474635893326, 'bagging_freq': 6, 'lambda_l1': 3.927102255697406, 'lambda_l2': 8.482680276233364}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-21 20:48:28,432] Trial 63 finished with value: 639.9629103663832 and parameters: {'num_leaves': 40, 'learning_rate': 0.012570736253928268, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9367254736229605, 'bagging_fraction': 0.8809041413307961, 'bagging_freq': 6, 'lambda_l1': 3.766837354833626, 'lambda_l2': 8.392114075364747}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-21 20:48:30,873] Trial 64 finished with value: 631.7720932403886 and parameters: {'num_leaves': 41, 'learning_rate': 0.013027420648364107, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9799179151705236, 'bagging_fraction': 0.8738286163424556, 'bagging_freq': 6, 'lambda_l1': 3.7443440139207125, 'lambda_l2': 8.311457587262433}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-21 20:48:33,167] Trial 65 finished with value: 634.9114428662369 and parameters: {'num_leaves': 41, 'learning_rate': 0.013358121959769863, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9435676126601654, 'bagging_fraction': 0.8823569255182764, 'bagging_freq': 6, 'lambda_l1': 2.4310383753172697, 'lambda_l2': 8.358104664930803}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-21 20:48:36,436] Trial 66 finished with value: 634.4634733108757 and parameters: {'num_leaves': 39, 'learning_rate': 0.012210055333014367, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9399492044160658, 'bagging_fraction': 0.8744450331838687, 'bagging_freq': 6, 'lambda_l1': 2.258970715723338, 'lambda_l2': 8.370493635092116}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-21 20:48:38,178] Trial 67 finished with value: 634.2985517853257 and parameters: {'num_leaves': 37, 'learning_rate': 0.02718182686268194, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.9829704371701842, 'bagging_fraction': 0.9048273028928185, 'bagging_freq': 5, 'lambda_l1': 1.73277082521835, 'lambda_l2': 9.184864532664047}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-21 20:48:39,870] Trial 68 finished with value: 631.9031278639253 and parameters: {'num_leaves': 42, 'learning_rate': 0.026168981351700336, 'min_child_samples': 6, 'max_depth': 11, 'feature_fraction': 0.9803176678953885, 'bagging_fraction': 0.9025553635783577, 'bagging_freq': 5, 'lambda_l1': 2.130172396804875, 'lambda_l2': 9.27515279737591}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-21 20:48:41,577] Trial 69 finished with value: 634.707272070923 and parameters: {'num_leaves': 42, 'learning_rate': 0.026464789886036406, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.982088801428082, 'bagging_fraction': 0.9070339906245926, 'bagging_freq': 4, 'lambda_l1': 2.0465989517309167, 'lambda_l2': 9.256491938837865}. Best is trial 64 with value: 631.7720932403886.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 41, 'learning_rate': 0.013027420648364107, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9799179151705236, 'bagging_fraction': 0.8738286163424556, 'bagging_freq': 6, 'lambda_l1': 3.7443440139207125, 'lambda_l2': 8.311457587262433}\n",
      "Best RMSE on validation set during tuning (Optuna): 631.77\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize\n",
    "study_p02 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) # Add seed for reproducibility\n",
    "study_p02.optimize(objective_p02, n_trials=70, show_progress_bar=True) # show_progress_bar for better UX\n",
    "\n",
    "# Best parameters and best RMSE found by Optuna\n",
    "best_params_p02 = study_p02.best_params\n",
    "best_rmse_optuna_p02 = study_p02.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p02)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p02:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p02:\n",
      "RMSE: 632.22\n",
      "R²: 0.8054\n"
     ]
    }
   ],
   "source": [
    "final_model_p02 = lgb.train(best_params_p02,\n",
    "                            lgb.Dataset(X_train_p02, label=y_train_p02),\n",
    "                            num_boost_round=1000) # Use best iteration from Optuna's best trial\n",
    "\n",
    "# Make predictions on the truly unseen test set\n",
    "y_pred_final_p02 = final_model_p02.predict(X_test_p02)\n",
    "\n",
    "# Evaluate the final model's performance on the test set\n",
    "rmse_final_p02 = np.sqrt(mean_squared_error(y_test_p02, y_pred_final_p02))\n",
    "r2_final_p02 = r2_score(y_test_p02, y_pred_final_p02)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p02:\")\n",
    "print(f\"RMSE: {rmse_final_p02:.2f}\")\n",
    "print(f\"R²: {r2_final_p02:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1627.96450871,  360.86406451,  581.99106058, ...,  171.21415554,\n",
       "       2836.89274428,  537.29573117])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final_p02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_allocation_p02= calculate_needed_trains(y_pred_final_p02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Passengers</th>\n",
       "      <th>Base_Predicted_Trains</th>\n",
       "      <th>Buffered_Predicted_Trains</th>\n",
       "      <th>Final_Predicted_Trains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>938</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587</th>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3404</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted_Passengers  Base_Predicted_Trains  Buffered_Predicted_Trains  \\\n",
       "2987                   488                      1                          1   \n",
       "2678                    62                      1                          1   \n",
       "8067                   938                      2                          2   \n",
       "9587                   318                      1                          1   \n",
       "1551                  3404                      6                          6   \n",
       "\n",
       "      Final_Predicted_Trains  \n",
       "2987                       1  \n",
       "2678                       1  \n",
       "8067                       2  \n",
       "9587                       1  \n",
       "1551                       6  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_allocation_p02.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Three:\n",
    " Assume we need to forecast the number of passengers for different time periods in order to allocate a more accurate number of trains for the next day. (In this case, we are allowed to use information from previous time periods, but using the year and number of trains columns is still not permitted.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p03(df, target_column='Ridership', cut_off_date: str = '2022-12-31', train_size=0.8):\n",
    "       \n",
    "    df['Date'] = pd.to_datetime(\n",
    "    df['Year'].astype(str) + '-' +\n",
    "    df['Month_Num'].astype(str) + '-' +\n",
    "    df['Day'].astype(str),\n",
    "    errors='coerce')\n",
    "\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "    df.sort_values(by=['Date'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Identify columns that define a unique time-series for lagging\n",
    "    # These are the columns that define \"which\" time series we are lagging.\n",
    "    grouping_cols = [\n",
    "      col for col in df.columns if \n",
    "      col.startswith('Corridor_') or\n",
    "      col.startswith('Station_') or\n",
    "      col.startswith('Period_')]\n",
    "    \n",
    "    if 'Workday_y' in df.columns:\n",
    "       grouping_cols.append('Workday_y')\n",
    " \n",
    "    if 'Workday_n' in df.columns:\n",
    "       grouping_cols.append('Workday_n')\n",
    "\n",
    "    if 'Covid19' in df.columns:\n",
    "       grouping_cols.append('Covid19')\n",
    "\n",
    "    # Create lagged features for 'Passengers'\n",
    "    # Lag 1 day (most important for next-day forecast)\n",
    "    df['Ridership_Lag_1'] = df.groupby(grouping_cols)['Ridership'].shift(1)\n",
    "    # Lag 2 days\n",
    "    df['Ridership_Lag_2'] = df.groupby(grouping_cols)['Ridership'].shift(2)\n",
    "    # Lag 7 days (for weekly seasonality, still important)\n",
    "    df['Ridership_Lag_7'] = df.groupby(grouping_cols)['Ridership'].shift(7)\n",
    "\n",
    "    # Rolling Average (e.g., 3-day rolling mean, shifted to avoid leakage)\n",
    "    # min_periods=1 allows calculation even if fewer than 3 periods are available at the start.\n",
    "    df['Rolling_Avg_Ridership_3'] = df.groupby(grouping_cols)['Ridership'].transform(\n",
    "       lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    "    \n",
    "    # Rolling Standard Deviation (e.g., 3-day rolling std, shifted)\n",
    "    df['Rolling_Std_Ridership_3'] = df.groupby(grouping_cols)['Ridership'].transform(\n",
    "         lambda x: x.rolling(window=3, min_periods=1).std().shift(1)).fillna(0)\n",
    "\n",
    "    df.dropna(subset=['Ridership_Lag_1','Ridership_Lag_2','Ridership_Lag_7','Rolling_Avg_Ridership_3'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column, 'Year', 'N_trains', 'Date'])\n",
    "    y = df[target_column]\n",
    "\n",
    "   #  cut_off_datetime = pd.to_datetime(cut_off_date)\n",
    "\n",
    "   #  train_mask = df['Date'] <= cut_off_datetime\n",
    "   #  X_train = X[train_mask]\n",
    "   #  y_train = y[train_mask]\n",
    "\n",
    "   #  test_mask = df['Date'] > cut_off_datetime\n",
    "   #  X_test = X[test_mask]\n",
    "   #  y_test = y[test_mask]\n",
    "\n",
    "    # Calculate split point\n",
    "    split_point = int(len(df) * train_size)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X.iloc[:split_point]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    \n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_test = y.iloc[split_point:]\n",
    "\n",
    "    # Print shapes of the resulting datasets\n",
    "    print(f\"\\nTrain set features (X_train) shape: {X_train.shape}\")\n",
    "    print(f\"Test set features (X_test) shape: {X_test.shape}\")\n",
    "    print(f\"Train set target (y_train) shape: {y_train.shape}\")\n",
    "    print(f\"Test set target (y_test) shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set features (X_train) shape: (47702, 85)\n",
      "Test set features (X_test) shape: (11926, 85)\n",
      "Train set target (y_train) shape: (47702,)\n",
      "Test set target (y_test) shape: (11926,)\n"
     ]
    }
   ],
   "source": [
    "X_train_p03, X_test_p03, y_train_p03, y_test_p03 = preprocess_and_split_data_p03(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p03(trial):\n",
    "    # Define parameters to be optimized by Optuna\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False # Disable feature pre-filtering\n",
    "    }\n",
    "\n",
    "    # Convert data to LightGBM Dataset format\n",
    "    # Use X_train_p02 for training, and X_test_p02 as the validation set\n",
    "    # This ensures that Optuna's reported best value is a good generalization estimate.\n",
    "    train_data = lgb.Dataset(X_train_p03, label=y_train_p03)\n",
    "    test_data = lgb.Dataset(X_test_p03, label=y_test_p03, reference=train_data)\n",
    "\n",
    "    # Train the model with early stopping on the validation set\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000, # Max boosting rounds\n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) # verbose=False to reduce output\n",
    "\n",
    "    # Make predictions on the validation set using the best iteration\n",
    "    y_pred = model.predict(X_test_p03, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Return RMSE as the objective value to minimize\n",
    "    return np.sqrt(mean_squared_error(y_test_p03, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 02:25:48,794] A new study created in memory with name: no-name-807a9491-b160-4e12-af4c-02e2b7a36e47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25be577eaa674a5b9c6680cd38f3d2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 02:25:49,086] Trial 0 finished with value: 616.4344150939429 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 616.4344150939429.\n",
      "[I 2025-07-22 02:25:50,645] Trial 1 finished with value: 610.784185327549 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 1 with value: 610.784185327549.\n",
      "[I 2025-07-22 02:25:51,528] Trial 2 finished with value: 592.9699728489815 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:51,968] Trial 3 finished with value: 611.535679630895 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:53,087] Trial 4 finished with value: 595.7282236212848 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:53,757] Trial 5 finished with value: 593.2519990748666 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:54,072] Trial 6 finished with value: 601.1753103683307 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:54,551] Trial 7 finished with value: 598.3152392442007 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:54,895] Trial 8 finished with value: 609.1673756263153 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:55,416] Trial 9 finished with value: 595.6222352165717 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:55,921] Trial 10 finished with value: 595.0618788437552 and parameters: {'num_leaves': 96, 'learning_rate': 0.17368350341485295, 'min_child_samples': 34, 'max_depth': 3, 'feature_fraction': 0.7512656088373982, 'bagging_fraction': 0.7606165441675251, 'bagging_freq': 6, 'lambda_l1': 6.240835271723655, 'lambda_l2': 0.3990753571948482}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:56,776] Trial 11 finished with value: 595.287701835365 and parameters: {'num_leaves': 88, 'learning_rate': 0.10471472793396032, 'min_child_samples': 43, 'max_depth': 6, 'feature_fraction': 0.7171781358782057, 'bagging_fraction': 0.9789880874538218, 'bagging_freq': 8, 'lambda_l1': 6.071842740332256, 'lambda_l2': 9.980995133299302}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:57,612] Trial 12 finished with value: 595.4479940515876 and parameters: {'num_leaves': 31, 'learning_rate': 0.06885769225676398, 'min_child_samples': 54, 'max_depth': 12, 'feature_fraction': 0.8033425041274396, 'bagging_fraction': 0.9603985157526262, 'bagging_freq': 5, 'lambda_l1': 6.660583056226428, 'lambda_l2': 3.309075206098962}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:58,384] Trial 13 finished with value: 596.4870874825008 and parameters: {'num_leaves': 85, 'learning_rate': 0.15912464772022475, 'min_child_samples': 94, 'max_depth': 6, 'feature_fraction': 0.6578156280449837, 'bagging_fraction': 0.8251130803737645, 'bagging_freq': 8, 'lambda_l1': 4.729749166323956, 'lambda_l2': 0.38970149536670395}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:59,029] Trial 14 finished with value: 594.3527786126879 and parameters: {'num_leaves': 58, 'learning_rate': 0.12615680263255413, 'min_child_samples': 32, 'max_depth': 8, 'feature_fraction': 0.6669061396282798, 'bagging_fraction': 0.6677349544985036, 'bagging_freq': 6, 'lambda_l1': 7.482700485615, 'lambda_l2': 7.049270826015106}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:25:59,465] Trial 15 finished with value: 607.3515014428503 and parameters: {'num_leaves': 38, 'learning_rate': 0.0629149829204078, 'min_child_samples': 81, 'max_depth': 5, 'feature_fraction': 0.5078844520790654, 'bagging_fraction': 0.8933912579489138, 'bagging_freq': 8, 'lambda_l1': 9.984074618849064, 'lambda_l2': 3.828053116697915}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:26:00,491] Trial 16 finished with value: 595.1858623837217 and parameters: {'num_leaves': 59, 'learning_rate': 0.13567326476767272, 'min_child_samples': 60, 'max_depth': 9, 'feature_fraction': 0.8146643330149077, 'bagging_fraction': 0.7014053992915784, 'bagging_freq': 4, 'lambda_l1': 7.900960486664598, 'lambda_l2': 1.7360290165166927}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:26:01,040] Trial 17 finished with value: 598.6491334934994 and parameters: {'num_leaves': 77, 'learning_rate': 0.1977487085394511, 'min_child_samples': 42, 'max_depth': 3, 'feature_fraction': 0.7218504918782025, 'bagging_fraction': 0.8008169599094145, 'bagging_freq': 2, 'lambda_l1': 3.770015782968793, 'lambda_l2': 9.795661442849326}. Best is trial 2 with value: 592.9699728489815.\n",
      "[I 2025-07-22 02:26:01,912] Trial 18 finished with value: 591.0037969246287 and parameters: {'num_leaves': 100, 'learning_rate': 0.06513361127988579, 'min_child_samples': 24, 'max_depth': 7, 'feature_fraction': 0.6316585144146266, 'bagging_fraction': 0.9134336554829188, 'bagging_freq': 9, 'lambda_l1': 5.06486575816506, 'lambda_l2': 6.369755517856774}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:03,780] Trial 19 finished with value: 599.5370992977817 and parameters: {'num_leaves': 100, 'learning_rate': 0.013554216160120008, 'min_child_samples': 22, 'max_depth': 5, 'feature_fraction': 0.6514278238756251, 'bagging_fraction': 0.8839208532144823, 'bagging_freq': 6, 'lambda_l1': 4.675195190109225, 'lambda_l2': 6.6580359670438085}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:04,777] Trial 20 finished with value: 599.2187860053676 and parameters: {'num_leaves': 86, 'learning_rate': 0.06401996044926572, 'min_child_samples': 27, 'max_depth': 7, 'feature_fraction': 0.9640514341164363, 'bagging_fraction': 0.9192935333529579, 'bagging_freq': 9, 'lambda_l1': 0.11620961627552973, 'lambda_l2': 4.463987628201712}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:06,012] Trial 21 finished with value: 592.6787239561627 and parameters: {'num_leaves': 71, 'learning_rate': 0.08312321042913394, 'min_child_samples': 45, 'max_depth': 9, 'feature_fraction': 0.6377735819216013, 'bagging_fraction': 0.9902467009891851, 'bagging_freq': 9, 'lambda_l1': 5.710410745995218, 'lambda_l2': 7.548697398205608}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:07,354] Trial 22 finished with value: 594.3289106413 and parameters: {'num_leaves': 54, 'learning_rate': 0.04448269346113263, 'min_child_samples': 42, 'max_depth': 10, 'feature_fraction': 0.6221365451590998, 'bagging_fraction': 0.9255066085194731, 'bagging_freq': 9, 'lambda_l1': 5.615330586309064, 'lambda_l2': 7.127952371390176}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:08,226] Trial 23 finished with value: 596.2001374915092 and parameters: {'num_leaves': 66, 'learning_rate': 0.08021849708077189, 'min_child_samples': 44, 'max_depth': 9, 'feature_fraction': 0.7051984933566552, 'bagging_fraction': 0.9994091601808105, 'bagging_freq': 7, 'lambda_l1': 5.394499801742677, 'lambda_l2': 6.340129925737216}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:09,327] Trial 24 finished with value: 600.3389376652564 and parameters: {'num_leaves': 92, 'learning_rate': 0.1300560004367835, 'min_child_samples': 65, 'max_depth': 10, 'feature_fraction': 0.7671580726937237, 'bagging_fraction': 0.83230655973243, 'bagging_freq': 5, 'lambda_l1': 7.151144675003307, 'lambda_l2': 5.270496965332079}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:09,933] Trial 25 finished with value: 603.8901714239432 and parameters: {'num_leaves': 39, 'learning_rate': 0.03854145299020535, 'min_child_samples': 20, 'max_depth': 5, 'feature_fraction': 0.5413581823950127, 'bagging_fraction': 0.9342985131709266, 'bagging_freq': 9, 'lambda_l1': 3.8489279005276344, 'lambda_l2': 7.875181618659658}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:10,963] Trial 26 finished with value: 595.248704408386 and parameters: {'num_leaves': 81, 'learning_rate': 0.12515651352686558, 'min_child_samples': 84, 'max_depth': 12, 'feature_fraction': 0.6304896561038393, 'bagging_fraction': 0.7131604453204495, 'bagging_freq': 7, 'lambda_l1': 4.226602908278908, 'lambda_l2': 5.705997065030042}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:11,428] Trial 27 finished with value: 602.0827642390846 and parameters: {'num_leaves': 65, 'learning_rate': 0.20820572201405724, 'min_child_samples': 48, 'max_depth': 7, 'feature_fraction': 0.6938787246271143, 'bagging_fraction': 0.622010497127612, 'bagging_freq': 10, 'lambda_l1': 8.331649083694579, 'lambda_l2': 1.3518283776138773}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:12,164] Trial 28 finished with value: 591.8501648608144 and parameters: {'num_leaves': 30, 'learning_rate': 0.04953639787389128, 'min_child_samples': 33, 'max_depth': 4, 'feature_fraction': 0.7845770798583175, 'bagging_fraction': 0.797671734909823, 'bagging_freq': 4, 'lambda_l1': 7.049211433340474, 'lambda_l2': 7.617124012987009}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:12,771] Trial 29 finished with value: 595.8494321885677 and parameters: {'num_leaves': 20, 'learning_rate': 0.042634225857358335, 'min_child_samples': 34, 'max_depth': 9, 'feature_fraction': 0.8241909080677586, 'bagging_fraction': 0.8566686224697246, 'bagging_freq': 0, 'lambda_l1': 5.419541615447548, 'lambda_l2': 7.3350205725626}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:13,703] Trial 30 finished with value: 596.9436922253926 and parameters: {'num_leaves': 32, 'learning_rate': 0.05536228935954046, 'min_child_samples': 18, 'max_depth': 11, 'feature_fraction': 0.7814834816112007, 'bagging_fraction': 0.7757969736292901, 'bagging_freq': 1, 'lambda_l1': 6.9923429362063265, 'lambda_l2': 9.154108887702842}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:14,472] Trial 31 finished with value: 592.3534598902042 and parameters: {'num_leaves': 53, 'learning_rate': 0.08442739558342358, 'min_child_samples': 37, 'max_depth': 4, 'feature_fraction': 0.7319405031420297, 'bagging_fraction': 0.7174319270069066, 'bagging_freq': 4, 'lambda_l1': 6.491124743946958, 'lambda_l2': 5.979054853217299}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:15,009] Trial 32 finished with value: 606.0812926035402 and parameters: {'num_leaves': 27, 'learning_rate': 0.025972038057702398, 'min_child_samples': 29, 'max_depth': 3, 'feature_fraction': 0.8486993979466384, 'bagging_fraction': 0.9550473150508323, 'bagging_freq': 3, 'lambda_l1': 6.442802083591877, 'lambda_l2': 6.008984236501816}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:15,701] Trial 33 finished with value: 596.7764428274747 and parameters: {'num_leaves': 47, 'learning_rate': 0.07849086098097685, 'min_child_samples': 37, 'max_depth': 4, 'feature_fraction': 0.7369131076174128, 'bagging_fraction': 0.7222930684878768, 'bagging_freq': 4, 'lambda_l1': 5.918144132748495, 'lambda_l2': 7.626791230997724}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:16,406] Trial 34 finished with value: 595.2998937615048 and parameters: {'num_leaves': 40, 'learning_rate': 0.08126526816527577, 'min_child_samples': 26, 'max_depth': 5, 'feature_fraction': 0.6081665647597971, 'bagging_fraction': 0.7845194789596304, 'bagging_freq': 3, 'lambda_l1': 2.326502163093811, 'lambda_l2': 6.6356374428844465}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:19,307] Trial 35 finished with value: 592.3970980729024 and parameters: {'num_leaves': 53, 'learning_rate': 0.024025260472824897, 'min_child_samples': 49, 'max_depth': 6, 'feature_fraction': 0.6978238225389176, 'bagging_fraction': 0.6405945324376946, 'bagging_freq': 2, 'lambda_l1': 5.0050543499013145, 'lambda_l2': 5.219967567075077}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:21,776] Trial 36 finished with value: 592.9633391907507 and parameters: {'num_leaves': 51, 'learning_rate': 0.02203858596458321, 'min_child_samples': 39, 'max_depth': 6, 'feature_fraction': 0.6903394916909418, 'bagging_fraction': 0.6359692915599621, 'bagging_freq': 2, 'lambda_l1': 3.4014598640292375, 'lambda_l2': 5.408119321458408}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:23,141] Trial 37 finished with value: 600.8710321388438 and parameters: {'num_leaves': 43, 'learning_rate': 0.011456333975848845, 'min_child_samples': 5, 'max_depth': 4, 'feature_fraction': 0.5642172125113807, 'bagging_fraction': 0.5770561968857882, 'bagging_freq': 1, 'lambda_l1': 4.869124993772448, 'lambda_l2': 4.2924696256447445}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:24,887] Trial 38 finished with value: 595.4347976058932 and parameters: {'num_leaves': 53, 'learning_rate': 0.04904596413058493, 'min_child_samples': 48, 'max_depth': 7, 'feature_fraction': 0.7719942858192701, 'bagging_fraction': 0.6162211866023891, 'bagging_freq': 4, 'lambda_l1': 6.751177374604297, 'lambda_l2': 6.000603695751016}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:25,617] Trial 39 finished with value: 608.7251898194257 and parameters: {'num_leaves': 63, 'learning_rate': 0.030956030528368324, 'min_child_samples': 16, 'max_depth': 4, 'feature_fraction': 0.8650795507693518, 'bagging_fraction': 0.7415997862563372, 'bagging_freq': 3, 'lambda_l1': 8.335354734916233, 'lambda_l2': 5.023242753862339}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:26,737] Trial 40 finished with value: 595.844563431991 and parameters: {'num_leaves': 34, 'learning_rate': 0.05365776332147251, 'min_child_samples': 51, 'max_depth': 5, 'feature_fraction': 0.7444170410155135, 'bagging_fraction': 0.5778610056515865, 'bagging_freq': 1, 'lambda_l1': 4.315111998482058, 'lambda_l2': 3.3644244669160894}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:27,448] Trial 41 finished with value: 598.4284066803968 and parameters: {'num_leaves': 73, 'learning_rate': 0.11241893124783292, 'min_child_samples': 25, 'max_depth': 8, 'feature_fraction': 0.589405730361548, 'bagging_fraction': 0.6805076253629212, 'bagging_freq': 5, 'lambda_l1': 5.581404186674193, 'lambda_l2': 6.628591644571452}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:28,350] Trial 42 finished with value: 592.109034009581 and parameters: {'num_leaves': 56, 'learning_rate': 0.09164840029551899, 'min_child_samples': 38, 'max_depth': 7, 'feature_fraction': 0.6831473826446817, 'bagging_fraction': 0.6560295879581012, 'bagging_freq': 10, 'lambda_l1': 5.287163426526651, 'lambda_l2': 8.41097569792693}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:29,215] Trial 43 finished with value: 596.4182405983125 and parameters: {'num_leaves': 56, 'learning_rate': 0.09338678916705714, 'min_child_samples': 36, 'max_depth': 6, 'feature_fraction': 0.680131899762436, 'bagging_fraction': 0.6406859264373027, 'bagging_freq': 10, 'lambda_l1': 4.957877341205848, 'lambda_l2': 8.2954990661012}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:30,952] Trial 44 finished with value: 592.8419752271797 and parameters: {'num_leaves': 45, 'learning_rate': 0.06725808861650022, 'min_child_samples': 30, 'max_depth': 7, 'feature_fraction': 0.7241339832728837, 'bagging_fraction': 0.696334211550028, 'bagging_freq': 2, 'lambda_l1': 7.287561416137178, 'lambda_l2': 9.014386866370684}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:31,473] Trial 45 finished with value: 595.8759388873417 and parameters: {'num_leaves': 50, 'learning_rate': 0.14852393891279528, 'min_child_samples': 38, 'max_depth': 6, 'feature_fraction': 0.7871896318073616, 'bagging_fraction': 0.7339643289218374, 'bagging_freq': 3, 'lambda_l1': 2.762913247921398, 'lambda_l2': 8.143783045398488}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:32,032] Trial 46 finished with value: 606.7907209163388 and parameters: {'num_leaves': 24, 'learning_rate': 0.03723370747487165, 'min_child_samples': 57, 'max_depth': 3, 'feature_fraction': 0.7577278609986703, 'bagging_fraction': 0.6565254859638775, 'bagging_freq': 10, 'lambda_l1': 6.392974836082367, 'lambda_l2': 8.59705821773621}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:32,685] Trial 47 finished with value: 598.352204040292 and parameters: {'num_leaves': 62, 'learning_rate': 0.11422738022954501, 'min_child_samples': 22, 'max_depth': 8, 'feature_fraction': 0.6832087157331453, 'bagging_fraction': 0.6071648663179525, 'bagging_freq': 4, 'lambda_l1': 5.21396193125755, 'lambda_l2': 5.703919152071082}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:33,393] Trial 48 finished with value: 598.0177721814701 and parameters: {'num_leaves': 57, 'learning_rate': 0.09774765107573766, 'min_child_samples': 13, 'max_depth': 7, 'feature_fraction': 0.7058073924013513, 'bagging_fraction': 0.8111639673541367, 'bagging_freq': 5, 'lambda_l1': 6.076105061239273, 'lambda_l2': 6.954469432828795}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:35,342] Trial 49 finished with value: 592.1852407541178 and parameters: {'num_leaves': 77, 'learning_rate': 0.027513451759346677, 'min_child_samples': 32, 'max_depth': 6, 'feature_fraction': 0.6125266976668771, 'bagging_fraction': 0.760430385296079, 'bagging_freq': 6, 'lambda_l1': 7.722495297044887, 'lambda_l2': 9.340890699095947}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:36,189] Trial 50 finished with value: 593.2055248183868 and parameters: {'num_leaves': 75, 'learning_rate': 0.07300192794155096, 'min_child_samples': 32, 'max_depth': 4, 'feature_fraction': 0.6186243316820106, 'bagging_fraction': 0.7575702820379993, 'bagging_freq': 6, 'lambda_l1': 9.107304722931907, 'lambda_l2': 9.455287381207686}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:36,957] Trial 51 finished with value: 607.618497291513 and parameters: {'num_leaves': 83, 'learning_rate': 0.024753599215665383, 'min_child_samples': 50, 'max_depth': 6, 'feature_fraction': 0.5779419175021803, 'bagging_fraction': 0.6758172967001526, 'bagging_freq': 8, 'lambda_l1': 7.811290528064728, 'lambda_l2': 9.448979972965198}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:38,174] Trial 52 finished with value: 592.9866282955084 and parameters: {'num_leaves': 92, 'learning_rate': 0.055313558056042246, 'min_child_samples': 39, 'max_depth': 5, 'feature_fraction': 0.6710985236041617, 'bagging_fraction': 0.7758390439520171, 'bagging_freq': 4, 'lambda_l1': 6.7615755997436136, 'lambda_l2': 8.544356261946998}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:38,792] Trial 53 finished with value: 608.449828158183 and parameters: {'num_leaves': 78, 'learning_rate': 0.28643681471731697, 'min_child_samples': 24, 'max_depth': 8, 'feature_fraction': 0.6458404303811767, 'bagging_fraction': 0.694637835563428, 'bagging_freq': 7, 'lambda_l1': 6.061114352962596, 'lambda_l2': 7.9198501328263236}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:40,245] Trial 54 finished with value: 595.5955088313755 and parameters: {'num_leaves': 100, 'learning_rate': 0.031963363215541794, 'min_child_samples': 31, 'max_depth': 7, 'feature_fraction': 0.6005026425035901, 'bagging_fraction': 0.6508850978440743, 'bagging_freq': 5, 'lambda_l1': 8.41053579702831, 'lambda_l2': 4.661312219125388}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:40,856] Trial 55 finished with value: 602.3629741394997 and parameters: {'num_leaves': 61, 'learning_rate': 0.2677701897463016, 'min_child_samples': 45, 'max_depth': 6, 'feature_fraction': 0.8000093724107983, 'bagging_fraction': 0.5583343165073961, 'bagging_freq': 9, 'lambda_l1': 4.408215039025749, 'lambda_l2': 7.655906818372502}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:41,591] Trial 56 finished with value: 592.1463341889563 and parameters: {'num_leaves': 69, 'learning_rate': 0.0886074925630367, 'min_child_samples': 34, 'max_depth': 5, 'feature_fraction': 0.7318792971956314, 'bagging_fraction': 0.7151293055910677, 'bagging_freq': 10, 'lambda_l1': 7.486314779149838, 'lambda_l2': 8.847592379503654}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:42,149] Trial 57 finished with value: 595.1199315454752 and parameters: {'num_leaves': 71, 'learning_rate': 0.087549664131732, 'min_child_samples': 28, 'max_depth': 5, 'feature_fraction': 0.7332797613907973, 'bagging_fraction': 0.5070587568226921, 'bagging_freq': 10, 'lambda_l1': 7.424885055077869, 'lambda_l2': 8.752696114581596}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:42,904] Trial 58 finished with value: 599.906109923025 and parameters: {'num_leaves': 68, 'learning_rate': 0.10703168855425335, 'min_child_samples': 34, 'max_depth': 4, 'feature_fraction': 0.8316135166830085, 'bagging_fraction': 0.7232456925244763, 'bagging_freq': 10, 'lambda_l1': 7.635564650399307, 'lambda_l2': 9.742323673668091}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:43,707] Trial 59 finished with value: 599.5356735479492 and parameters: {'num_leaves': 92, 'learning_rate': 0.06232450013329749, 'min_child_samples': 18, 'max_depth': 5, 'feature_fraction': 0.5411840996853042, 'bagging_fraction': 0.8378816518745298, 'bagging_freq': 9, 'lambda_l1': 8.068434978274096, 'lambda_l2': 9.098129528017777}. Best is trial 18 with value: 591.0037969246287.\n",
      "[I 2025-07-22 02:26:44,496] Trial 60 finished with value: 590.4522486813662 and parameters: {'num_leaves': 79, 'learning_rate': 0.07097577572472583, 'min_child_samples': 41, 'max_depth': 4, 'feature_fraction': 0.9992682327877374, 'bagging_fraction': 0.7919701925058237, 'bagging_freq': 9, 'lambda_l1': 8.878621643792004, 'lambda_l2': 8.346732649911745}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:45,485] Trial 61 finished with value: 590.9757734829685 and parameters: {'num_leaves': 81, 'learning_rate': 0.06976478526042994, 'min_child_samples': 40, 'max_depth': 4, 'feature_fraction': 0.9838997443642122, 'bagging_fraction': 0.7980713625223316, 'bagging_freq': 9, 'lambda_l1': 8.832715041674547, 'lambda_l2': 8.240614239890776}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:46,269] Trial 62 finished with value: 594.0809072940547 and parameters: {'num_leaves': 80, 'learning_rate': 0.07116270803547409, 'min_child_samples': 41, 'max_depth': 3, 'feature_fraction': 0.9991878267801637, 'bagging_fraction': 0.7924813433759298, 'bagging_freq': 9, 'lambda_l1': 9.508363879538031, 'lambda_l2': 8.486927713550974}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:47,168] Trial 63 finished with value: 591.7153734335652 and parameters: {'num_leaves': 87, 'learning_rate': 0.05922861645343565, 'min_child_samples': 34, 'max_depth': 3, 'feature_fraction': 0.9163354748928647, 'bagging_fraction': 0.8073232455139149, 'bagging_freq': 8, 'lambda_l1': 8.78406150387776, 'lambda_l2': 9.393079282033185}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:47,703] Trial 64 finished with value: 605.5058746754038 and parameters: {'num_leaves': 86, 'learning_rate': 0.061020025814685123, 'min_child_samples': 44, 'max_depth': 3, 'feature_fraction': 0.9230805426270339, 'bagging_fraction': 0.8134839471407477, 'bagging_freq': 8, 'lambda_l1': 9.896762229507361, 'lambda_l2': 8.141929844681458}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:48,347] Trial 65 finished with value: 595.2609817509016 and parameters: {'num_leaves': 95, 'learning_rate': 0.09704281264105402, 'min_child_samples': 35, 'max_depth': 3, 'feature_fraction': 0.9645581982278126, 'bagging_fraction': 0.8678713029232402, 'bagging_freq': 9, 'lambda_l1': 8.977070678715888, 'lambda_l2': 7.370051880561308}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:49,729] Trial 66 finished with value: 591.1912383612697 and parameters: {'num_leaves': 89, 'learning_rate': 0.04540031737655094, 'min_child_samples': 40, 'max_depth': 4, 'feature_fraction': 0.9278594522329278, 'bagging_fraction': 0.84875377582748, 'bagging_freq': 10, 'lambda_l1': 8.890224633795427, 'lambda_l2': 8.959562543722676}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:50,988] Trial 67 finished with value: 592.7931211304473 and parameters: {'num_leaves': 89, 'learning_rate': 0.03954851524221266, 'min_child_samples': 41, 'max_depth': 4, 'feature_fraction': 0.925679257133285, 'bagging_fraction': 0.9007911139975209, 'bagging_freq': 8, 'lambda_l1': 8.633790976470824, 'lambda_l2': 7.863684086523352}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:52,251] Trial 68 finished with value: 591.4564683770907 and parameters: {'num_leaves': 97, 'learning_rate': 0.07440157679657503, 'min_child_samples': 54, 'max_depth': 4, 'feature_fraction': 0.9803176678953885, 'bagging_fraction': 0.8457847404693627, 'bagging_freq': 9, 'lambda_l1': 9.227280060216193, 'lambda_l2': 9.586562667214341}. Best is trial 60 with value: 590.4522486813662.\n",
      "[I 2025-07-22 02:26:52,767] Trial 69 finished with value: 605.2302756711383 and parameters: {'num_leaves': 97, 'learning_rate': 0.047884108092670595, 'min_child_samples': 55, 'max_depth': 4, 'feature_fraction': 0.9993352173262476, 'bagging_fraction': 0.843241948983608, 'bagging_freq': 9, 'lambda_l1': 9.296029990225193, 'lambda_l2': 9.904821319386114}. Best is trial 60 with value: 590.4522486813662.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 79, 'learning_rate': 0.07097577572472583, 'min_child_samples': 41, 'max_depth': 4, 'feature_fraction': 0.9992682327877374, 'bagging_fraction': 0.7919701925058237, 'bagging_freq': 9, 'lambda_l1': 8.878621643792004, 'lambda_l2': 8.346732649911745}\n",
      "Best RMSE on validation set during tuning (Optuna): 590.45\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize\n",
    "study_p03 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) # Add seed for reproducibility\n",
    "study_p03.optimize(objective_p03, n_trials=70, show_progress_bar=True) # show_progress_bar for better UX\n",
    "\n",
    "# Best parameters and best RMSE found by Optuna\n",
    "best_params_p03 = study_p03.best_params\n",
    "best_rmse_optuna_p03 = study_p03.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p03)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p03:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p03:\n",
      "RMSE: 592.89\n",
      "R²: 0.8324\n"
     ]
    }
   ],
   "source": [
    "final_model_p03 = lgb.train(best_params_p03,\n",
    "                            lgb.Dataset(X_train_p03, label=y_train_p03),\n",
    "                            num_boost_round=1000) \n",
    "\n",
    "# Make predictions on the truly unseen test set\n",
    "y_pred_final_p03 = final_model_p03.predict(X_test_p03)\n",
    "\n",
    "# Evaluate the final model's performance on the test set\n",
    "rmse_final_p03 = np.sqrt(mean_squared_error(y_test_p03, y_pred_final_p03))\n",
    "r2_final_p03 = r2_score(y_test_p03, y_pred_final_p03)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p03:\")\n",
    "print(f\"RMSE: {rmse_final_p03:.2f}\")\n",
    "print(f\"R²: {r2_final_p03:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vg01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
