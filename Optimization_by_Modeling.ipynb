{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week Number</th>\n",
       "      <th>Corridor</th>\n",
       "      <th>Workday</th>\n",
       "      <th>Station</th>\n",
       "      <th>Period</th>\n",
       "      <th>Ridership</th>\n",
       "      <th>N_trains</th>\n",
       "      <th>Covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62858</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>Corridor_1</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_3</td>\n",
       "      <td>PM Peak</td>\n",
       "      <td>2516</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Corridor_1</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_2</td>\n",
       "      <td>PM Peak</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40936</th>\n",
       "      <td>2021</td>\n",
       "      <td>August</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>Corridor_3</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_3</td>\n",
       "      <td>PM Peak</td>\n",
       "      <td>1252</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Corridor_3</td>\n",
       "      <td>y</td>\n",
       "      <td>Station_4</td>\n",
       "      <td>Midday</td>\n",
       "      <td>3824</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2019</td>\n",
       "      <td>February</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>Corridor_1</td>\n",
       "      <td>n</td>\n",
       "      <td>Station_2</td>\n",
       "      <td>Weekend/Holiday</td>\n",
       "      <td>394</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year     Month  Day  Week Number    Corridor Workday    Station  \\\n",
       "62858  2022  November   30           48  Corridor_1       y  Station_3   \n",
       "8942   2019      July    3           27  Corridor_1       y  Station_2   \n",
       "40936  2021    August    9           32  Corridor_3       y  Station_3   \n",
       "1242   2019   January   23            4  Corridor_3       y  Station_4   \n",
       "2610   2019  February   17            7  Corridor_1       n  Station_2   \n",
       "\n",
       "                Period  Ridership  N_trains  Covid19  \n",
       "62858          PM Peak       2516         5        0  \n",
       "8942           PM Peak         61         1        0  \n",
       "40936          PM Peak       1252        12        1  \n",
       "1242            Midday       3824        12        0  \n",
       "2610   Weekend/Holiday        394        10        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridership_df= pd.read_csv('data/Ridership.csv')\n",
    "df= Ridership_df.copy()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64369 entries, 0 to 64368\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Year         64369 non-null  int64 \n",
      " 1   Month        64369 non-null  object\n",
      " 2   Day          64369 non-null  int64 \n",
      " 3   Week Number  64369 non-null  int64 \n",
      " 4   Corridor     64369 non-null  object\n",
      " 5   Workday      64369 non-null  object\n",
      " 6   Station      64369 non-null  object\n",
      " 7   Period       64369 non-null  object\n",
      " 8   Ridership    64369 non-null  int64 \n",
      " 9   N_trains     64369 non-null  int64 \n",
      " 10  Covid19      64369 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Month          0\n",
       "Day            0\n",
       "Week Number    0\n",
       "Corridor       0\n",
       "Workday        0\n",
       "Station        0\n",
       "Period         0\n",
       "Ridership      0\n",
       "N_trains       0\n",
       "Covid19        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines a function feature_engineering that encapsulates several crucial data transformation steps. These steps prepare the raw Ridership data into a format suitable for machine learning models, enhancing their ability to learn patterns from the metro service data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Month mapping\n",
    "    month_mapping = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "        'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    df['Month_Num'] = df['Month'].map(month_mapping)\n",
    "\n",
    "    # Cyclical Day conversion\n",
    "    def convert_day_to_circle(day):\n",
    "        angle = 2 * np.pi * (day - 1) / 31\n",
    "        x = np.cos(angle)\n",
    "        y = np.sin(angle)\n",
    "        return x, y\n",
    "\n",
    "    df['day_x'], df['day_y'] = zip(*df['Day'].map(convert_day_to_circle))\n",
    "\n",
    "    # Cyclical Week conversion\n",
    "    def convert_week_to_circle(week):\n",
    "        angle = 2 * np.pi * (week - 1) / 53\n",
    "        x = np.cos(angle)\n",
    "        y = np.sin(angle)\n",
    "        return x, y\n",
    "\n",
    "    df['week_x'], df['week_y'] = zip(*df['Week Number'].map(convert_week_to_circle))\n",
    "\n",
    "    # Categorical features for OneHotEncoder\n",
    "    categorical_features = ['Month', 'Corridor', 'Workday', 'Station', 'Period']\n",
    "\n",
    "    # Column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('', OneHotEncoder(), categorical_features),\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Fit and transform the DataFrame\n",
    "    df_transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Convert the encoded features to a dense matrix\n",
    "    df_transformed = df_transformed.toarray()\n",
    "\n",
    "    # Convert to DataFrame and get feature names\n",
    "    feature_names_out = list(preprocessor.get_feature_names_out())\n",
    "    \n",
    "    # Convert the dense matrix to a DataFrame\n",
    "    df_transformed = pd.DataFrame(df_transformed, columns=[item.split('__')[1] for item in feature_names_out])\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COVID_Workday'] = df['Covid19'] * df['Workday_y']\n",
    "\n",
    "columns_to_convert = [\n",
    "    'Month_April', 'Month_August', 'Month_December', 'Month_February', \n",
    "    'Month_January', 'Month_July', 'Month_June', 'Month_March', \n",
    "    'Month_May', 'Month_November', 'Month_October', 'Month_September',\n",
    "    'Corridor_Corridor_1', 'Corridor_Corridor_2', 'Corridor_Corridor_3', \n",
    "    'Corridor_Corridor_4', 'Corridor_Corridor_5', 'Corridor_Corridor_6', 'Corridor_Corridor_7',\n",
    "    'Station_Station_1', 'Station_Station_10', 'Station_Station_11', 'Station_Station_12', \n",
    "    'Station_Station_13', 'Station_Station_14', 'Station_Station_15', 'Station_Station_16', \n",
    "    'Station_Station_17', 'Station_Station_18', 'Station_Station_19', 'Station_Station_2', \n",
    "    'Station_Station_20', 'Station_Station_21', 'Station_Station_22', 'Station_Station_23', \n",
    "    'Station_Station_24', 'Station_Station_25', 'Station_Station_26', 'Station_Station_27', \n",
    "    'Station_Station_28', 'Station_Station_29', 'Station_Station_3', 'Station_Station_30', \n",
    "    'Station_Station_31', 'Station_Station_32', 'Station_Station_33', 'Station_Station_34', \n",
    "    'Station_Station_35', 'Station_Station_36', 'Station_Station_37', 'Station_Station_38', \n",
    "    'Station_Station_39', 'Station_Station_4', 'Station_Station_40', 'Station_Station_41', \n",
    "    'Station_Station_42', 'Station_Station_43', 'Station_Station_44', 'Station_Station_45', \n",
    "    'Station_Station_5', 'Station_Station_6', 'Station_Station_7', 'Station_Station_8', 'Station_Station_9',\n",
    "    'Period_AM Peak', 'Period_Evening', 'Period_Midday', 'Period_PM Peak', 'Period_Weekend/Holiday',\n",
    "    'Day',\n",
    "    'Week Number',\n",
    "    'Workday_n', 'Workday_y',\n",
    "    'Covid19','COVID_Workday',\n",
    "    'Month_Num']\n",
    "\n",
    "columns_to_convert_02=['Year', 'Ridership', 'N_trains']\n",
    "\n",
    "\n",
    "df[columns_to_convert] = df[columns_to_convert].astype('uint8')\n",
    "df[columns_to_convert_02] = df[columns_to_convert_02].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64369 entries, 0 to 64368\n",
      "Data columns (total 83 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Month_April             64369 non-null  uint8  \n",
      " 1   Month_August            64369 non-null  uint8  \n",
      " 2   Month_December          64369 non-null  uint8  \n",
      " 3   Month_February          64369 non-null  uint8  \n",
      " 4   Month_January           64369 non-null  uint8  \n",
      " 5   Month_July              64369 non-null  uint8  \n",
      " 6   Month_June              64369 non-null  uint8  \n",
      " 7   Month_March             64369 non-null  uint8  \n",
      " 8   Month_May               64369 non-null  uint8  \n",
      " 9   Month_November          64369 non-null  uint8  \n",
      " 10  Month_October           64369 non-null  uint8  \n",
      " 11  Month_September         64369 non-null  uint8  \n",
      " 12  Corridor_Corridor_1     64369 non-null  uint8  \n",
      " 13  Corridor_Corridor_2     64369 non-null  uint8  \n",
      " 14  Corridor_Corridor_3     64369 non-null  uint8  \n",
      " 15  Corridor_Corridor_4     64369 non-null  uint8  \n",
      " 16  Corridor_Corridor_5     64369 non-null  uint8  \n",
      " 17  Corridor_Corridor_6     64369 non-null  uint8  \n",
      " 18  Corridor_Corridor_7     64369 non-null  uint8  \n",
      " 19  Workday_n               64369 non-null  uint8  \n",
      " 20  Workday_y               64369 non-null  uint8  \n",
      " 21  Station_Station_1       64369 non-null  uint8  \n",
      " 22  Station_Station_10      64369 non-null  uint8  \n",
      " 23  Station_Station_11      64369 non-null  uint8  \n",
      " 24  Station_Station_12      64369 non-null  uint8  \n",
      " 25  Station_Station_13      64369 non-null  uint8  \n",
      " 26  Station_Station_14      64369 non-null  uint8  \n",
      " 27  Station_Station_15      64369 non-null  uint8  \n",
      " 28  Station_Station_16      64369 non-null  uint8  \n",
      " 29  Station_Station_17      64369 non-null  uint8  \n",
      " 30  Station_Station_18      64369 non-null  uint8  \n",
      " 31  Station_Station_19      64369 non-null  uint8  \n",
      " 32  Station_Station_2       64369 non-null  uint8  \n",
      " 33  Station_Station_20      64369 non-null  uint8  \n",
      " 34  Station_Station_21      64369 non-null  uint8  \n",
      " 35  Station_Station_22      64369 non-null  uint8  \n",
      " 36  Station_Station_23      64369 non-null  uint8  \n",
      " 37  Station_Station_24      64369 non-null  uint8  \n",
      " 38  Station_Station_25      64369 non-null  uint8  \n",
      " 39  Station_Station_26      64369 non-null  uint8  \n",
      " 40  Station_Station_27      64369 non-null  uint8  \n",
      " 41  Station_Station_28      64369 non-null  uint8  \n",
      " 42  Station_Station_29      64369 non-null  uint8  \n",
      " 43  Station_Station_3       64369 non-null  uint8  \n",
      " 44  Station_Station_30      64369 non-null  uint8  \n",
      " 45  Station_Station_31      64369 non-null  uint8  \n",
      " 46  Station_Station_32      64369 non-null  uint8  \n",
      " 47  Station_Station_33      64369 non-null  uint8  \n",
      " 48  Station_Station_34      64369 non-null  uint8  \n",
      " 49  Station_Station_35      64369 non-null  uint8  \n",
      " 50  Station_Station_36      64369 non-null  uint8  \n",
      " 51  Station_Station_37      64369 non-null  uint8  \n",
      " 52  Station_Station_38      64369 non-null  uint8  \n",
      " 53  Station_Station_39      64369 non-null  uint8  \n",
      " 54  Station_Station_4       64369 non-null  uint8  \n",
      " 55  Station_Station_40      64369 non-null  uint8  \n",
      " 56  Station_Station_41      64369 non-null  uint8  \n",
      " 57  Station_Station_42      64369 non-null  uint8  \n",
      " 58  Station_Station_43      64369 non-null  uint8  \n",
      " 59  Station_Station_44      64369 non-null  uint8  \n",
      " 60  Station_Station_45      64369 non-null  uint8  \n",
      " 61  Station_Station_5       64369 non-null  uint8  \n",
      " 62  Station_Station_6       64369 non-null  uint8  \n",
      " 63  Station_Station_7       64369 non-null  uint8  \n",
      " 64  Station_Station_8       64369 non-null  uint8  \n",
      " 65  Station_Station_9       64369 non-null  uint8  \n",
      " 66  Period_AM Peak          64369 non-null  uint8  \n",
      " 67  Period_Evening          64369 non-null  uint8  \n",
      " 68  Period_Midday           64369 non-null  uint8  \n",
      " 69  Period_PM Peak          64369 non-null  uint8  \n",
      " 70  Period_Weekend/Holiday  64369 non-null  uint8  \n",
      " 71  Year                    64369 non-null  uint16 \n",
      " 72  Day                     64369 non-null  uint8  \n",
      " 73  Week Number             64369 non-null  uint8  \n",
      " 74  Ridership               64369 non-null  uint16 \n",
      " 75  N_trains                64369 non-null  uint16 \n",
      " 76  Covid19                 64369 non-null  uint8  \n",
      " 77  Month_Num               64369 non-null  uint8  \n",
      " 78  day_x                   64369 non-null  float64\n",
      " 79  day_y                   64369 non-null  float64\n",
      " 80  week_x                  64369 non-null  float64\n",
      " 81  week_y                  64369 non-null  float64\n",
      " 82  COVID_Workday           64369 non-null  uint8  \n",
      "dtypes: float64(4), uint16(3), uint8(76)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem One: \n",
    "Assume we want to find a general model for the number of passengers without looking at the number of passengers on previous days and only using the recorded information in the table for the same time period (except for the year and number of trains) to predict the number of required trains based on the number of passengers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for problem One :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines the preprocess_and_split_data_p01 function, which is responsible for preparing the data and splitting it into training and testing sets specifically for Problem One: finding a general model for passenger prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p01(df, target_column='Ridership', test_size=0.2, random_state=42):\n",
    "    # Drop unnecessary columns\n",
    "    X = df.drop([target_column, 'Year', 'N_trains'], axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Create stratification key directly from df\n",
    "    df_for_stratify_p01 = Ridership_df.copy()\n",
    "    stratify_key_p01 = df_for_stratify_p01['Covid19'].astype(str) + '_' + \\\n",
    "                       df_for_stratify_p01['Workday'] + '_' + \\\n",
    "                       df_for_stratify_p01['Period']+ '_' + \\\n",
    "                       df_for_stratify_p01['Corridor']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_key_p01)\n",
    "    \n",
    "    print(f\"\\nTrain set features (X_train) shape: {X_train.shape}\")\n",
    "    print(f\"Test set features (X_test) shape: {X_test.shape}\")\n",
    "    print(f\"Train set target (y_train) shape: {y_train.shape}\")\n",
    "    print(f\"Test set target (y_test) shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set features (X_train) shape: (51495, 80)\n",
      "Test set features (X_test) shape: (12874, 80)\n",
      "Train set target (y_train) shape: (51495,)\n",
      "Test set target (y_test) shape: (12874,)\n"
     ]
    }
   ],
   "source": [
    "X_train_p01, X_test_p01, y_train_p01, y_test_p01 = preprocess_and_split_data_p01(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM model:\n",
    "\n",
    "This code defines the objective_p01 function, which serves as the core of the hyperparameter optimization process using the Optuna library for Problem One. Optuna calls this function repeatedly, each time suggesting a new set of hyperparameters for the LightGBM model, trains the model, and then evaluates its performance. Optuna then uses this feedback to intelligently propose better parameters in subsequent trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p01(trial):\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False \n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(X_train_p01, label=y_train_p01)\n",
    "    test_data = lgb.Dataset(X_test_p01, label=y_test_p01, reference=train_data)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000,\n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) \n",
    "\n",
    "    y_pred = model.predict(X_test_p01, num_iteration=model.best_iteration)\n",
    "    return np.sqrt(mean_squared_error(y_test_p01, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block initiates and executes the hyperparameter optimization process for Problem One using the Optuna library. It orchestrates the search for the best set of LightGBM hyperparameters that minimize the Root Mean Squared Error (RMSE) on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 03:27:06,335] A new study created in memory with name: no-name-2ba9b8cd-2c9a-4929-8e22-87d33e0a49f9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd74564e998446fb21dc82719edcd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 03:27:09,056] Trial 0 finished with value: 858.3986297975716 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:13,478] Trial 1 finished with value: 965.171480859766 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:15,510] Trial 2 finished with value: 1000.1536696220307 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:17,176] Trial 3 finished with value: 894.0391972352643 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:19,671] Trial 4 finished with value: 948.3146519834861 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:24,054] Trial 5 finished with value: 866.4387208437403 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:26,317] Trial 6 finished with value: 949.6893791987322 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:28,387] Trial 7 finished with value: 1015.4673968533081 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:30,521] Trial 8 finished with value: 915.3457610239897 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:33,942] Trial 9 finished with value: 870.6259201748129 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 0 with value: 858.3986297975716.\n",
      "[I 2025-07-22 03:27:38,067] Trial 10 finished with value: 840.8127837075767 and parameters: {'num_leaves': 96, 'learning_rate': 0.20844875976291638, 'min_child_samples': 96, 'max_depth': 12, 'feature_fraction': 0.7606700059313507, 'bagging_fraction': 0.8451235367845726, 'bagging_freq': 0, 'lambda_l1': 6.233765186294655, 'lambda_l2': 5.705478648816834}. Best is trial 10 with value: 840.8127837075767.\n",
      "[I 2025-07-22 03:27:41,009] Trial 11 finished with value: 840.4630573552917 and parameters: {'num_leaves': 100, 'learning_rate': 0.21350493115709046, 'min_child_samples': 97, 'max_depth': 12, 'feature_fraction': 0.7804533509078434, 'bagging_fraction': 0.8513496163789993, 'bagging_freq': 0, 'lambda_l1': 5.732909776512292, 'lambda_l2': 5.916836359300596}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-22 03:27:43,908] Trial 12 finished with value: 865.350729411854 and parameters: {'num_leaves': 98, 'learning_rate': 0.1972983678039399, 'min_child_samples': 98, 'max_depth': 12, 'feature_fraction': 0.7630125055985993, 'bagging_fraction': 0.8588729908849949, 'bagging_freq': 1, 'lambda_l1': 5.4383196440103365, 'lambda_l2': 6.31247107794331}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-22 03:27:47,226] Trial 13 finished with value: 866.8463394407116 and parameters: {'num_leaves': 100, 'learning_rate': 0.19879458291976249, 'min_child_samples': 88, 'max_depth': 12, 'feature_fraction': 0.7878475603784051, 'bagging_fraction': 0.8585787245031458, 'bagging_freq': 2, 'lambda_l1': 5.948420184248468, 'lambda_l2': 3.919288077713245}. Best is trial 11 with value: 840.4630573552917.\n",
      "[I 2025-07-22 03:27:49,996] Trial 14 finished with value: 829.5731708574829 and parameters: {'num_leaves': 86, 'learning_rate': 0.23235938995830105, 'min_child_samples': 85, 'max_depth': 10, 'feature_fraction': 0.9977408115016615, 'bagging_fraction': 0.9501945220447685, 'bagging_freq': 0, 'lambda_l1': 6.498463090024852, 'lambda_l2': 6.895871382854953}. Best is trial 14 with value: 829.5731708574829.\n",
      "[I 2025-07-22 03:27:51,977] Trial 15 finished with value: 823.2748751682116 and parameters: {'num_leaves': 85, 'learning_rate': 0.23812208281329955, 'min_child_samples': 32, 'max_depth': 10, 'feature_fraction': 0.977579072072423, 'bagging_fraction': 0.9913430783889023, 'bagging_freq': 2, 'lambda_l1': 3.744601193250797, 'lambda_l2': 7.085805321941195}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:27:53,520] Trial 16 finished with value: 829.8426953968805 and parameters: {'num_leaves': 85, 'learning_rate': 0.25005830524268685, 'min_child_samples': 34, 'max_depth': 10, 'feature_fraction': 0.98826210667186, 'bagging_fraction': 0.9839051683864238, 'bagging_freq': 2, 'lambda_l1': 3.8876919478638627, 'lambda_l2': 0.13179214380923554}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:27:56,545] Trial 17 finished with value: 837.0135234888076 and parameters: {'num_leaves': 86, 'learning_rate': 0.1367286480427689, 'min_child_samples': 33, 'max_depth': 10, 'feature_fraction': 0.9833898180659589, 'bagging_fraction': 0.9239821132404911, 'bagging_freq': 4, 'lambda_l1': 0.3630481323211834, 'lambda_l2': 9.948008035537754}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:27:59,432] Trial 18 finished with value: 865.6984858269009 and parameters: {'num_leaves': 86, 'learning_rate': 0.24080165094913625, 'min_child_samples': 41, 'max_depth': 6, 'feature_fraction': 0.9095336881172504, 'bagging_fraction': 0.9457995117435076, 'bagging_freq': 6, 'lambda_l1': 4.357469624538123, 'lambda_l2': 7.024197291755801}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:28:01,174] Trial 19 finished with value: 863.6451610827532 and parameters: {'num_leaves': 35, 'learning_rate': 0.16244265650172257, 'min_child_samples': 24, 'max_depth': 9, 'feature_fraction': 0.8440770194224896, 'bagging_fraction': 0.7869730869739291, 'bagging_freq': 3, 'lambda_l1': 7.1193695386383435, 'lambda_l2': 7.236364799111377}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:28:02,690] Trial 20 finished with value: 851.0168294442385 and parameters: {'num_leaves': 80, 'learning_rate': 0.29762483426517194, 'min_child_samples': 43, 'max_depth': 9, 'feature_fraction': 0.9476939712459647, 'bagging_fraction': 0.9192935333529579, 'bagging_freq': 1, 'lambda_l1': 2.416693120712215, 'lambda_l2': 3.974358253058724}. Best is trial 15 with value: 823.2748751682116.\n",
      "[I 2025-07-22 03:28:04,469] Trial 21 finished with value: 820.0376579637274 and parameters: {'num_leaves': 90, 'learning_rate': 0.23681820581860302, 'min_child_samples': 26, 'max_depth': 10, 'feature_fraction': 0.9932206455418805, 'bagging_fraction': 0.9956917042908306, 'bagging_freq': 2, 'lambda_l1': 4.177306496037178, 'lambda_l2': 0.12550199367920242}. Best is trial 21 with value: 820.0376579637274.\n",
      "[I 2025-07-22 03:28:06,071] Trial 22 finished with value: 813.9634171612922 and parameters: {'num_leaves': 89, 'learning_rate': 0.22926627032742758, 'min_child_samples': 24, 'max_depth': 11, 'feature_fraction': 0.9925114051096695, 'bagging_fraction': 0.9969465653028303, 'bagging_freq': 1, 'lambda_l1': 4.3647828588546815, 'lambda_l2': 7.150604120240355}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:07,757] Trial 23 finished with value: 820.6660589447708 and parameters: {'num_leaves': 92, 'learning_rate': 0.26797136164517055, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.9400131173613442, 'bagging_fraction': 0.9994406932515424, 'bagging_freq': 3, 'lambda_l1': 4.5493952877479575, 'lambda_l2': 0.7592254223402448}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:08,897] Trial 24 finished with value: 832.2599836701345 and parameters: {'num_leaves': 91, 'learning_rate': 0.26108746705244795, 'min_child_samples': 19, 'max_depth': 11, 'feature_fraction': 0.9377518209778412, 'bagging_fraction': 0.9069576977760248, 'bagging_freq': 4, 'lambda_l1': 4.454771871746318, 'lambda_l2': 0.14579224689980322}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:10,252] Trial 25 finished with value: 827.4118145733287 and parameters: {'num_leaves': 92, 'learning_rate': 0.2681966255743236, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.8360490217951417, 'bagging_fraction': 0.9997631072285242, 'bagging_freq': 3, 'lambda_l1': 4.89141346540847, 'lambda_l2': 1.1366757726424068}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:12,214] Trial 26 finished with value: 853.9811376259078 and parameters: {'num_leaves': 65, 'learning_rate': 0.16699608602734356, 'min_child_samples': 42, 'max_depth': 11, 'feature_fraction': 0.855888008984883, 'bagging_fraction': 0.7787588257864038, 'bagging_freq': 1, 'lambda_l1': 1.698119125309197, 'lambda_l2': 1.3906554717810902}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:13,353] Trial 27 finished with value: 826.3079399006837 and parameters: {'num_leaves': 78, 'learning_rate': 0.22279186881297725, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.9363930934209518, 'bagging_fraction': 0.8976673683708202, 'bagging_freq': 5, 'lambda_l1': 3.727886430358488, 'lambda_l2': 3.2899951244808414}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:15,591] Trial 28 finished with value: 830.4241340852853 and parameters: {'num_leaves': 76, 'learning_rate': 0.13394655262891542, 'min_child_samples': 27, 'max_depth': 9, 'feature_fraction': 0.9586511086149871, 'bagging_fraction': 0.951176087760467, 'bagging_freq': 3, 'lambda_l1': 4.949132855010541, 'lambda_l2': 0.6784478531511889}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:17,104] Trial 29 finished with value: 1021.6276693190559 and parameters: {'num_leaves': 92, 'learning_rate': 0.2963883640360279, 'min_child_samples': 48, 'max_depth': 3, 'feature_fraction': 0.7172488564422614, 'bagging_fraction': 0.9614446966831018, 'bagging_freq': 1, 'lambda_l1': 3.2960388623897643, 'lambda_l2': 2.8431715544776233}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:18,384] Trial 30 finished with value: 853.2912849526887 and parameters: {'num_leaves': 92, 'learning_rate': 0.27653203948873, 'min_child_samples': 19, 'max_depth': 8, 'feature_fraction': 0.872117574190506, 'bagging_fraction': 0.8198854833066617, 'bagging_freq': 4, 'lambda_l1': 1.9800119770382478, 'lambda_l2': 1.0674765371015968}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:20,463] Trial 31 finished with value: 821.8519482550178 and parameters: {'num_leaves': 82, 'learning_rate': 0.2555777548022447, 'min_child_samples': 32, 'max_depth': 10, 'feature_fraction': 0.9657365469864623, 'bagging_fraction': 0.9991417930830018, 'bagging_freq': 2, 'lambda_l1': 3.866574849506398, 'lambda_l2': 7.65456750564721}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:22,864] Trial 32 finished with value: 819.1229574175021 and parameters: {'num_leaves': 81, 'learning_rate': 0.25919358911092033, 'min_child_samples': 29, 'max_depth': 11, 'feature_fraction': 0.9232104987886129, 'bagging_fraction': 0.9994902667235264, 'bagging_freq': 2, 'lambda_l1': 4.443275565042894, 'lambda_l2': 9.9688171199544}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:23,937] Trial 33 finished with value: 841.898801782214 and parameters: {'num_leaves': 95, 'learning_rate': 0.28199888076032403, 'min_child_samples': 17, 'max_depth': 11, 'feature_fraction': 0.9176856338607613, 'bagging_fraction': 0.8941193353020506, 'bagging_freq': 2, 'lambda_l1': 5.361849397419923, 'lambda_l2': 9.609280673436176}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:24,843] Trial 34 finished with value: 843.3467460830101 and parameters: {'num_leaves': 74, 'learning_rate': 0.22647538502975628, 'min_child_samples': 27, 'max_depth': 12, 'feature_fraction': 0.935470777808525, 'bagging_fraction': 0.9654261897650135, 'bagging_freq': 1, 'lambda_l1': 4.484117516383502, 'lambda_l2': 9.27389531609602}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:26,383] Trial 35 finished with value: 880.3243717689917 and parameters: {'num_leaves': 60, 'learning_rate': 0.17996038645895326, 'min_child_samples': 37, 'max_depth': 11, 'feature_fraction': 0.8239453932382725, 'bagging_fraction': 0.6405945324376946, 'bagging_freq': 5, 'lambda_l1': 3.1090116033739936, 'lambda_l2': 5.23722137934546}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:28,151] Trial 36 finished with value: 838.5793734085067 and parameters: {'num_leaves': 90, 'learning_rate': 0.2618863041528528, 'min_child_samples': 26, 'max_depth': 8, 'feature_fraction': 0.998434508044055, 'bagging_fraction': 0.929414802173654, 'bagging_freq': 3, 'lambda_l1': 6.717816393831111, 'lambda_l2': 1.89241715366098}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:29,675] Trial 37 finished with value: 867.7543930764988 and parameters: {'num_leaves': 81, 'learning_rate': 0.1952707684278006, 'min_child_samples': 15, 'max_depth': 9, 'feature_fraction': 0.7103435493235871, 'bagging_fraction': 0.7096763211890255, 'bagging_freq': 2, 'lambda_l1': 4.7228181538998815, 'lambda_l2': 8.296391937239637}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:32,068] Trial 38 finished with value: 858.700377028276 and parameters: {'num_leaves': 57, 'learning_rate': 0.21620507769553424, 'min_child_samples': 61, 'max_depth': 7, 'feature_fraction': 0.8877181903276369, 'bagging_fraction': 0.9688035405842793, 'bagging_freq': 1, 'lambda_l1': 2.5676452988080394, 'lambda_l2': 4.569968124217928}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:33,072] Trial 39 finished with value: 825.1262187365535 and parameters: {'num_leaves': 66, 'learning_rate': 0.28548936418147675, 'min_child_samples': 5, 'max_depth': 12, 'feature_fraction': 0.8091699477532056, 'bagging_fraction': 0.9347125554517861, 'bagging_freq': 3, 'lambda_l1': 3.4428315378357395, 'lambda_l2': 2.5438533654937885}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:36,395] Trial 40 finished with value: 843.827164840684 and parameters: {'num_leaves': 71, 'learning_rate': 0.06362065129104016, 'min_child_samples': 51, 'max_depth': 11, 'feature_fraction': 0.9177931201104805, 'bagging_fraction': 0.5887663591658137, 'bagging_freq': 0, 'lambda_l1': 5.329173035841281, 'lambda_l2': 0.5519654290902357}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:38,150] Trial 41 finished with value: 821.3183941768766 and parameters: {'num_leaves': 81, 'learning_rate': 0.2528348565646795, 'min_child_samples': 29, 'max_depth': 10, 'feature_fraction': 0.9575551669333756, 'bagging_fraction': 0.9975008705536783, 'bagging_freq': 2, 'lambda_l1': 4.145007331396462, 'lambda_l2': 7.647699416822267}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:39,529] Trial 42 finished with value: 820.67464463946 and parameters: {'num_leaves': 89, 'learning_rate': 0.2704594825582398, 'min_child_samples': 11, 'max_depth': 10, 'feature_fraction': 0.9591334877107154, 'bagging_fraction': 0.9735918884040877, 'bagging_freq': 2, 'lambda_l1': 4.252964142796664, 'lambda_l2': 8.757527019763153}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:40,551] Trial 43 finished with value: 848.4330446069383 and parameters: {'num_leaves': 89, 'learning_rate': 0.29866145765443847, 'min_child_samples': 13, 'max_depth': 9, 'feature_fraction': 0.8703583554194936, 'bagging_fraction': 0.8830839626320757, 'bagging_freq': 1, 'lambda_l1': 5.190319199558725, 'lambda_l2': 8.782486901800414}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:42,277] Trial 44 finished with value: 828.1874793042049 and parameters: {'num_leaves': 95, 'learning_rate': 0.2668534670527767, 'min_child_samples': 22, 'max_depth': 11, 'feature_fraction': 0.9743570523613105, 'bagging_fraction': 0.9738587621828848, 'bagging_freq': 9, 'lambda_l1': 3.082282997872249, 'lambda_l2': 9.15327167340185}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:43,698] Trial 45 finished with value: 825.7960945587848 and parameters: {'num_leaves': 97, 'learning_rate': 0.2740062551524419, 'min_child_samples': 9, 'max_depth': 10, 'feature_fraction': 0.8978189484089897, 'bagging_fraction': 0.9708402386038576, 'bagging_freq': 4, 'lambda_l1': 5.698171213693797, 'lambda_l2': 9.61906279577542}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:45,287] Trial 46 finished with value: 846.1303831600819 and parameters: {'num_leaves': 37, 'learning_rate': 0.23668600624280037, 'min_child_samples': 38, 'max_depth': 12, 'feature_fraction': 0.9278013691342434, 'bagging_fraction': 0.9304515385864465, 'bagging_freq': 6, 'lambda_l1': 4.113526549204541, 'lambda_l2': 6.526696063465382}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:46,836] Trial 47 finished with value: 819.8261701060943 and parameters: {'num_leaves': 88, 'learning_rate': 0.20650668957652968, 'min_child_samples': 20, 'max_depth': 11, 'feature_fraction': 0.9610278577340667, 'bagging_fraction': 0.974208788664251, 'bagging_freq': 0, 'lambda_l1': 8.359030379476582, 'lambda_l2': 8.300383269727488}. Best is trial 22 with value: 813.9634171612922.\n",
      "[I 2025-07-22 03:28:48,611] Trial 48 finished with value: 810.4305674395371 and parameters: {'num_leaves': 76, 'learning_rate': 0.20551927855538374, 'min_child_samples': 20, 'max_depth': 12, 'feature_fraction': 0.9966022144448774, 'bagging_fraction': 0.9491919674871573, 'bagging_freq': 0, 'lambda_l1': 9.803954066886053, 'lambda_l2': 8.237537989929509}. Best is trial 48 with value: 810.4305674395371.\n",
      "[I 2025-07-22 03:28:50,433] Trial 49 finished with value: 829.339705124722 and parameters: {'num_leaves': 75, 'learning_rate': 0.20107457868868983, 'min_child_samples': 46, 'max_depth': 12, 'feature_fraction': 0.9960787598611138, 'bagging_fraction': 0.8803713749062628, 'bagging_freq': 0, 'lambda_l1': 9.819156057142715, 'lambda_l2': 8.116882637830772}. Best is trial 48 with value: 810.4305674395371.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 76, 'learning_rate': 0.20551927855538374, 'min_child_samples': 20, 'max_depth': 12, 'feature_fraction': 0.9966022144448774, 'bagging_fraction': 0.9491919674871573, 'bagging_freq': 0, 'lambda_l1': 9.803954066886053, 'lambda_l2': 8.237537989929509}\n",
      "Best RMSE on validation set during tuning (Optuna): 810.43\n"
     ]
    }
   ],
   "source": [
    "study_p01 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) \n",
    "study_p01.optimize(objective_p01, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "best_params_p01 = study_p01.best_params\n",
    "best_rmse_optuna_p01 = study_p01.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p01)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p01:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output provides the Best parameters found by Optuna and the Best RMSE on validation set during tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block focuses on training the final LightGBM model for Problem One (general passenger prediction) using the optimal hyperparameters found by Optuna, and then evaluating its performance on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p01:\n",
      "RMSE: 818.90\n",
      "R²: 0.8157\n"
     ]
    }
   ],
   "source": [
    "final_model_p01 = lgb.train(best_params_p01,\n",
    "                            lgb.Dataset(X_train_p01, label=y_train_p01),\n",
    "                            num_boost_round=1000) \n",
    "\n",
    "y_pred_final_p01 = final_model_p01.predict(X_test_p01)\n",
    "\n",
    "rmse_final_p01 = np.sqrt(mean_squared_error(y_test_p01, y_pred_final_p01))\n",
    "r2_final_p01 = r2_score(y_test_p01, y_pred_final_p01)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p01:\")\n",
    "print(f\"RMSE: {rmse_final_p01:.2f}\")\n",
    "print(f\"R²: {r2_final_p01:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``RMSE: 818.90``\n",
    "This means, on average, this model predictions for passenger numbers are off by approximately 819 passengers.\n",
    "\n",
    "#### ``R²: 0.8157 ``\n",
    "This indicates that approximately ``81.57%`` of the variance in passenger numbers in the test set can be explained by this model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines the calculate_needed_trains function, a crucial component for translating predicted passenger numbers into actionable operational decisions: the number of trains required. \n",
    "The primary goal of this function is to determine the optimal number of trains needed to accommodate a given number of predicted passengers, taking into account the train's capacity and optional buffering for comfort or safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_needed_trains(predicted_passengers_series: pd.Series,\n",
    "                            train_capacity: int = 600,\n",
    "                            safety_buffer_percentage: float = 0.05,\n",
    "                            minimum_trains_required: int = 1) -> pd.DataFrame:\n",
    "\n",
    "    predicted_passengers_int = predicted_passengers_series.astype(int)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Predicted_Passengers': predicted_passengers_int})\n",
    "\n",
    "    # 1. Calculate the base number of trains needed (minimum required)\n",
    "    # np.ceil ensures that any fraction of a train needed results in a full additional train.\n",
    "    result_df['Base_Predicted_Trains'] = np.ceil(\n",
    "        result_df['Predicted_Passengers'] / train_capacity\n",
    "    ).astype(int)\n",
    "\n",
    "    # 2. Calculate trains with a safety/comfort buffer\n",
    "    # This adds a percentage buffer to the predicted passengers before dividing by capacity.\n",
    "    result_df['Buffered_Predicted_Trains'] = np.ceil(\n",
    "        result_df['Predicted_Passengers'] * (1 + safety_buffer_percentage) / train_capacity\n",
    "    ).astype(int)\n",
    "\n",
    "    # 3. Ensure a minimum number of trains\n",
    "    # This ensures that even for very low passenger counts, a base service level is maintained.\n",
    "    result_df['Final_Predicted_Trains'] = result_df['Buffered_Predicted_Trains'].apply(\n",
    "        lambda x: max(x, minimum_trains_required)\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Passengers</th>\n",
       "      <th>Base_Predicted_Trains</th>\n",
       "      <th>Buffered_Predicted_Trains</th>\n",
       "      <th>Final_Predicted_Trains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>8576</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12709</th>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12204</th>\n",
       "      <td>2134</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>1159</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>4072</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_Passengers  Base_Predicted_Trains  Buffered_Predicted_Trains  \\\n",
       "1253                   8576                     15                         16   \n",
       "7091                    129                      1                          1   \n",
       "7473                    484                      1                          1   \n",
       "6851                    193                      1                          1   \n",
       "12709                   390                      1                          1   \n",
       "4285                    519                      1                          1   \n",
       "12204                  2134                      4                          4   \n",
       "8419                   1159                      2                          3   \n",
       "3503                    447                      1                          1   \n",
       "11769                  4072                      7                          8   \n",
       "\n",
       "       Final_Predicted_Trains  \n",
       "1253                       16  \n",
       "7091                        1  \n",
       "7473                        1  \n",
       "6851                        1  \n",
       "12709                       1  \n",
       "4285                        1  \n",
       "12204                       4  \n",
       "8419                        3  \n",
       "3503                        1  \n",
       "11769                       8  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_p01= calculate_needed_trains(y_pred_final_p01)\n",
    "y_pred_train_p01.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Two:\n",
    " Assume we need to forecast the number of passengers for different time periods in order to allocate the appropriate number of trains one week in advance. (In this case, we are allowed to use information from previous time periods, but using the year and number of trains columns is still not permitted.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for problem two :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM model:\n",
    "\n",
    "This code defines the preprocess_and_split_data_p02 function, which handles the data preparation and chronological splitting specifically for Problem Two: forecasting passenger numbers one week in advance. This problem requires a time-series approach, making the order of data crucial.\n",
    "The function takes your processed DataFrame, creates time-series specific features (lags), and then splits the data into training and testing sets based on time, ensuring that the model only learns from past information to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p02(df, target_column='Ridership', train_size=0.8):\n",
    "\n",
    "    df['Date'] = pd.to_datetime(\n",
    "        df['Year'].astype(str) + '-' +\n",
    "        df['Month_Num'].astype(str) + '-' +\n",
    "        df['Day'].astype(str),\n",
    "        errors='coerce')\n",
    "\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    # Grouping columns for creating lagged features\n",
    "    grouping_cols = [\n",
    "        col for col in df.columns if col.startswith('Corridor_') or\n",
    "        col.startswith('Station_') or\n",
    "        col.startswith('Period_')\n",
    "    ]\n",
    "\n",
    "    # Create lagged features for 'Passengers'\n",
    "    # Lag 7 days (for same day of week, same period, etc., one week prior)\n",
    "    df['Ridership_Lag_7'] = df.groupby(grouping_cols)['Ridership'].shift(7)\n",
    "\n",
    "    # Lag 14 days (for same day of week, same period, two weeks prior)\n",
    "    df['Ridership_Lag_14'] = df.groupby(grouping_cols)['Ridership'].shift(14)\n",
    "\n",
    "    df.dropna(subset=['Ridership_Lag_7', 'Ridership_Lag_14'], inplace=True)    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.sort_values(by=['Date'], inplace=True)\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column, 'Year', 'N_trains', 'Date'])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Calculate split point\n",
    "    split_point = int(len(df) * train_size)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X.iloc[:split_point]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    \n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_test = y.iloc[split_point:]\n",
    "\n",
    "    print(f\"\\nTrain set features (X_train) shape: {X_train.shape}\")\n",
    "    print(f\"Test set features (X_test) shape: {X_test.shape}\")\n",
    "    print(f\"Train set target (y_train) shape: {y_train.shape}\")\n",
    "    print(f\"Test set target (y_test) shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set features (X_train) shape: (49951, 82)\n",
      "Test set features (X_test) shape: (12488, 82)\n",
      "Train set target (y_train) shape: (49951,)\n",
      "Test set target (y_test) shape: (12488,)\n"
     ]
    }
   ],
   "source": [
    "X_train_p02, X_test_p02, y_train_p02, y_test_p02 = preprocess_and_split_data_p02(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines the objective_p02 function, which serves as the core of the hyperparameter optimization process using the Optuna library for Problem Two: forecasting passenger numbers one week in advance. Optuna repeatedly calls this function, suggesting new sets of hyperparameters for the LightGBM model, trains the model, and evaluates its performance on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p02(trial):\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False \n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(X_train_p02, label=y_train_p02)\n",
    "    test_data = lgb.Dataset(X_test_p02, label=y_test_p02, reference=train_data)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000, \n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) \n",
    "\n",
    "    y_pred = model.predict(X_test_p02, num_iteration=model.best_iteration)\n",
    "\n",
    "    return np.sqrt(mean_squared_error(y_test_p02, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block initiates and executes the hyperparameter optimization process for Problem Two (forecasting one week in advance) using the Optuna library. It orchestrates the search for the best set of LightGBM hyperparameters that minimize the Root Mean Squared Error (RMSE) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 04:14:05,514] A new study created in memory with name: no-name-67be581c-db7d-470f-b31b-ab010da4f090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67412c902d744c3a4fa685f01e7c1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 04:14:06,219] Trial 0 finished with value: 749.983216692356 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 749.983216692356.\n",
      "[I 2025-07-22 04:14:10,177] Trial 1 finished with value: 689.8169979283266 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 1 with value: 689.8169979283266.\n",
      "[I 2025-07-22 04:14:10,910] Trial 2 finished with value: 669.6805520970248 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-22 04:14:11,554] Trial 3 finished with value: 743.4659716391809 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-22 04:14:12,014] Trial 4 finished with value: 738.0206947253275 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-22 04:14:13,015] Trial 5 finished with value: 723.748016964836 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-22 04:14:13,531] Trial 6 finished with value: 687.8883464626696 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 2 with value: 669.6805520970248.\n",
      "[I 2025-07-22 04:14:14,178] Trial 7 finished with value: 656.3349160468297 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-22 04:14:14,619] Trial 8 finished with value: 659.0457370327476 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-22 04:14:15,169] Trial 9 finished with value: 659.7131205498853 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-22 04:14:15,960] Trial 10 finished with value: 656.6294958379173 and parameters: {'num_leaves': 96, 'learning_rate': 0.1874718576067958, 'min_child_samples': 34, 'max_depth': 3, 'feature_fraction': 0.9905354130446519, 'bagging_fraction': 0.8451235367845726, 'bagging_freq': 10, 'lambda_l1': 6.240835271723655, 'lambda_l2': 0.3979960607701478}. Best is trial 7 with value: 656.3349160468297.\n",
      "[I 2025-07-22 04:14:16,654] Trial 11 finished with value: 655.1309264329091 and parameters: {'num_leaves': 100, 'learning_rate': 0.1773053455084359, 'min_child_samples': 32, 'max_depth': 3, 'feature_fraction': 0.995366008349641, 'bagging_fraction': 0.8513496163789993, 'bagging_freq': 10, 'lambda_l1': 6.16211739462904, 'lambda_l2': 0.04673570702773894}. Best is trial 11 with value: 655.1309264329091.\n",
      "[I 2025-07-22 04:14:17,421] Trial 12 finished with value: 643.3669432771432 and parameters: {'num_leaves': 34, 'learning_rate': 0.1452170025057517, 'min_child_samples': 35, 'max_depth': 5, 'feature_fraction': 0.8810709338789753, 'bagging_fraction': 0.8588729908849949, 'bagging_freq': 8, 'lambda_l1': 5.836177658376659, 'lambda_l2': 0.031071995147729885}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:18,289] Trial 13 finished with value: 649.1442460882886 and parameters: {'num_leaves': 29, 'learning_rate': 0.15912464772022475, 'min_child_samples': 35, 'max_depth': 6, 'feature_fraction': 0.8080673413914532, 'bagging_fraction': 0.8846915468913171, 'bagging_freq': 7, 'lambda_l1': 5.273501315332378, 'lambda_l2': 0.18292032726393373}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:18,867] Trial 14 finished with value: 663.1011574162833 and parameters: {'num_leaves': 28, 'learning_rate': 0.23079417685695425, 'min_child_samples': 40, 'max_depth': 6, 'feature_fraction': 0.7817421205832107, 'bagging_fraction': 0.9501945220447685, 'bagging_freq': 7, 'lambda_l1': 4.584302328362351, 'lambda_l2': 3.465514216694958}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:19,413] Trial 15 finished with value: 658.6184949954255 and parameters: {'num_leaves': 33, 'learning_rate': 0.15906076637112665, 'min_child_samples': 24, 'max_depth': 6, 'feature_fraction': 0.7788514614387833, 'bagging_fraction': 0.9117177726127699, 'bagging_freq': 8, 'lambda_l1': 4.373242307868379, 'lambda_l2': 1.1704182500408697}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:20,083] Trial 16 finished with value: 646.2363482380266 and parameters: {'num_leaves': 33, 'learning_rate': 0.135213347715731, 'min_child_samples': 46, 'max_depth': 5, 'feature_fraction': 0.8607349956827239, 'bagging_fraction': 0.788474586944839, 'bagging_freq': 6, 'lambda_l1': 6.439586532363955, 'lambda_l2': 3.58390284790542}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:20,932] Trial 17 finished with value: 647.6678545062273 and parameters: {'num_leaves': 39, 'learning_rate': 0.13649978960074022, 'min_child_samples': 46, 'max_depth': 5, 'feature_fraction': 0.8628799715054529, 'bagging_fraction': 0.7956399834425625, 'bagging_freq': 6, 'lambda_l1': 7.183830296409637, 'lambda_l2': 6.71236967350552}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:21,517] Trial 18 finished with value: 650.7089308400331 and parameters: {'num_leaves': 21, 'learning_rate': 0.056253492681493614, 'min_child_samples': 22, 'max_depth': 12, 'feature_fraction': 0.7077851292555184, 'bagging_fraction': 0.7607668789167329, 'bagging_freq': 5, 'lambda_l1': 3.42435982518749, 'lambda_l2': 3.9929464831880646}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:22,118] Trial 19 finished with value: 645.5612749537578 and parameters: {'num_leaves': 35, 'learning_rate': 0.1287000223369303, 'min_child_samples': 89, 'max_depth': 5, 'feature_fraction': 0.9218466062580651, 'bagging_fraction': 0.7975119753911437, 'bagging_freq': 8, 'lambda_l1': 6.427654544859113, 'lambda_l2': 3.1786691104821063}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:23,187] Trial 20 finished with value: 652.6728412329276 and parameters: {'num_leaves': 41, 'learning_rate': 0.20156011128754445, 'min_child_samples': 100, 'max_depth': 7, 'feature_fraction': 0.9491201445921722, 'bagging_fraction': 0.6988253157652793, 'bagging_freq': 9, 'lambda_l1': 0.11620961627552973, 'lambda_l2': 9.938427850497089}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:23,989] Trial 21 finished with value: 645.4092369709537 and parameters: {'num_leaves': 35, 'learning_rate': 0.13054114622046276, 'min_child_samples': 83, 'max_depth': 5, 'feature_fraction': 0.8339511894660561, 'bagging_fraction': 0.8114948890256886, 'bagging_freq': 8, 'lambda_l1': 6.445252637000118, 'lambda_l2': 3.248552738642576}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:24,873] Trial 22 finished with value: 645.9174062201375 and parameters: {'num_leaves': 37, 'learning_rate': 0.126029571589249, 'min_child_samples': 84, 'max_depth': 5, 'feature_fraction': 0.9314766787996078, 'bagging_fraction': 0.8152508113761574, 'bagging_freq': 8, 'lambda_l1': 5.219697599632305, 'lambda_l2': 2.2353485301100404}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:26,138] Trial 23 finished with value: 646.6302375000674 and parameters: {'num_leaves': 26, 'learning_rate': 0.0734408985579082, 'min_child_samples': 87, 'max_depth': 5, 'feature_fraction': 0.8322410276077967, 'bagging_fraction': 0.9241004407247386, 'bagging_freq': 9, 'lambda_l1': 7.046441690343867, 'lambda_l2': 1.166736901221074}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:26,649] Trial 24 finished with value: 683.4301451113315 and parameters: {'num_leaves': 57, 'learning_rate': 0.12699401178827283, 'min_child_samples': 89, 'max_depth': 3, 'feature_fraction': 0.7446195108134603, 'bagging_fraction': 0.7346296910830256, 'bagging_freq': 9, 'lambda_l1': 5.616746902209391, 'lambda_l2': 2.9348184817284393}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:27,396] Trial 25 finished with value: 648.3607652154126 and parameters: {'num_leaves': 45, 'learning_rate': 0.21471322298661788, 'min_child_samples': 79, 'max_depth': 4, 'feature_fraction': 0.9376122958679955, 'bagging_fraction': 0.8272029104292995, 'bagging_freq': 6, 'lambda_l1': 4.19559385057863, 'lambda_l2': 4.7338862979250775}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:28,000] Trial 26 finished with value: 646.3652488725002 and parameters: {'num_leaves': 33, 'learning_rate': 0.1476763664405195, 'min_child_samples': 63, 'max_depth': 7, 'feature_fraction': 0.8325873147129733, 'bagging_fraction': 0.8812829080304145, 'bagging_freq': 8, 'lambda_l1': 6.939278825456193, 'lambda_l2': 0.9912893999946736}. Best is trial 12 with value: 643.3669432771432.\n",
      "[I 2025-07-22 04:14:29,101] Trial 27 finished with value: 642.2479870020248 and parameters: {'num_leaves': 25, 'learning_rate': 0.11602453150780333, 'min_child_samples': 93, 'max_depth': 5, 'feature_fraction': 0.9046221986498096, 'bagging_fraction': 0.783666961304615, 'bagging_freq': 7, 'lambda_l1': 8.331649083694579, 'lambda_l2': 6.094934702074951}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:30,713] Trial 28 finished with value: 655.8900070689391 and parameters: {'num_leaves': 25, 'learning_rate': 0.07222267390301056, 'min_child_samples': 97, 'max_depth': 6, 'feature_fraction': 0.7285545670206393, 'bagging_fraction': 0.637167495253871, 'bagging_freq': 7, 'lambda_l1': 8.159815924501153, 'lambda_l2': 6.412120024896554}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:31,825] Trial 29 finished with value: 653.4710277421298 and parameters: {'num_leaves': 50, 'learning_rate': 0.10779931122123985, 'min_child_samples': 79, 'max_depth': 9, 'feature_fraction': 0.8740759397384257, 'bagging_fraction': 0.7186498417448955, 'bagging_freq': 5, 'lambda_l1': 8.398384561816135, 'lambda_l2': 6.9059352240929925}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:32,492] Trial 30 finished with value: 644.6104056442806 and parameters: {'num_leaves': 62, 'learning_rate': 0.16991948970675974, 'min_child_samples': 92, 'max_depth': 4, 'feature_fraction': 0.9597977223447893, 'bagging_fraction': 0.7742516139395101, 'bagging_freq': 9, 'lambda_l1': 5.720014378176846, 'lambda_l2': 5.665862286994643}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:33,559] Trial 31 finished with value: 650.7884906810744 and parameters: {'num_leaves': 62, 'learning_rate': 0.16730151622855652, 'min_child_samples': 94, 'max_depth': 4, 'feature_fraction': 0.9713569478401963, 'bagging_fraction': 0.7779579149421749, 'bagging_freq': 9, 'lambda_l1': 7.387672491911572, 'lambda_l2': 5.508094470559812}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:34,499] Trial 32 finished with value: 657.35378318791 and parameters: {'num_leaves': 82, 'learning_rate': 0.20105904255735446, 'min_child_samples': 92, 'max_depth': 3, 'feature_fraction': 0.9166388107015678, 'bagging_fraction': 0.8340677464225512, 'bagging_freq': 9, 'lambda_l1': 5.742663202706927, 'lambda_l2': 7.511230180380133}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:36,084] Trial 33 finished with value: 650.5845307625218 and parameters: {'num_leaves': 85, 'learning_rate': 0.15060420742838432, 'min_child_samples': 82, 'max_depth': 4, 'feature_fraction': 0.9613125696656442, 'bagging_fraction': 0.7581103993016662, 'bagging_freq': 7, 'lambda_l1': 9.988200120500538, 'lambda_l2': 5.760841457862635}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:36,995] Trial 34 finished with value: 646.716763403262 and parameters: {'num_leaves': 64, 'learning_rate': 0.11535794516921064, 'min_child_samples': 76, 'max_depth': 5, 'feature_fraction': 0.8408240608642056, 'bagging_fraction': 0.7097699238053233, 'bagging_freq': 6, 'lambda_l1': 4.883985951949358, 'lambda_l2': 4.214139442352147}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:38,371] Trial 35 finished with value: 653.8084544486051 and parameters: {'num_leaves': 54, 'learning_rate': 0.07829563718932561, 'min_child_samples': 61, 'max_depth': 7, 'feature_fraction': 0.8015504856428303, 'bagging_fraction': 0.631101658030822, 'bagging_freq': 8, 'lambda_l1': 3.514586106014889, 'lambda_l2': 7.274377303429189}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:39,936] Trial 36 finished with value: 646.1213051747918 and parameters: {'num_leaves': 43, 'learning_rate': 0.03911376189489073, 'min_child_samples': 67, 'max_depth': 4, 'feature_fraction': 0.8983632649874882, 'bagging_fraction': 0.8912041625953747, 'bagging_freq': 0, 'lambda_l1': 7.809892640399617, 'lambda_l2': 6.045137292167471}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:40,557] Trial 37 finished with value: 648.1158827551692 and parameters: {'num_leaves': 55, 'learning_rate': 0.173190603159251, 'min_child_samples': 100, 'max_depth': 8, 'feature_fraction': 0.8528437814025002, 'bagging_fraction': 0.8150225814424858, 'bagging_freq': 1, 'lambda_l1': 2.4606828135220837, 'lambda_l2': 4.745808065727184}. Best is trial 27 with value: 642.2479870020248.\n",
      "[I 2025-07-22 04:14:41,525] Trial 38 finished with value: 641.8393155044645 and parameters: {'num_leaves': 24, 'learning_rate': 0.14484235439461707, 'min_child_samples': 92, 'max_depth': 5, 'feature_fraction': 0.899527500582647, 'bagging_fraction': 0.7352118146218567, 'bagging_freq': 9, 'lambda_l1': 6.738496571577695, 'lambda_l2': 6.286830495685695}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:42,659] Trial 39 finished with value: 663.5941358756594 and parameters: {'num_leaves': 22, 'learning_rate': 0.0878973526453253, 'min_child_samples': 95, 'max_depth': 4, 'feature_fraction': 0.9757893595827343, 'bagging_fraction': 0.6508891267720402, 'bagging_freq': 10, 'lambda_l1': 8.569141839199698, 'lambda_l2': 5.255002319925984}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:43,363] Trial 40 finished with value: 662.1822075601177 and parameters: {'num_leaves': 75, 'learning_rate': 0.19252671683366168, 'min_child_samples': 49, 'max_depth': 9, 'feature_fraction': 0.9003608553973999, 'bagging_fraction': 0.5972212620328471, 'bagging_freq': 4, 'lambda_l1': 9.284885610341519, 'lambda_l2': 6.1594981286080515}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:44,140] Trial 41 finished with value: 648.1300135204136 and parameters: {'num_leaves': 31, 'learning_rate': 0.14188107626353286, 'min_child_samples': 85, 'max_depth': 5, 'feature_fraction': 0.8960162962838928, 'bagging_fraction': 0.6784705423497785, 'bagging_freq': 9, 'lambda_l1': 6.701103372944639, 'lambda_l2': 7.861380343192393}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:45,161] Trial 42 finished with value: 656.0932386643004 and parameters: {'num_leaves': 25, 'learning_rate': 0.11792288528147803, 'min_child_samples': 91, 'max_depth': 6, 'feature_fraction': 0.9537107495417143, 'bagging_fraction': 0.7374671494653139, 'bagging_freq': 8, 'lambda_l1': 5.624478986539984, 'lambda_l2': 5.204736785003092}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:45,771] Trial 43 finished with value: 648.121100000118 and parameters: {'num_leaves': 38, 'learning_rate': 0.1618940814165552, 'min_child_samples': 5, 'max_depth': 5, 'feature_fraction': 0.8775274413179482, 'bagging_fraction': 0.7720319789414302, 'bagging_freq': 9, 'lambda_l1': 7.563524305489988, 'lambda_l2': 4.102951228480186}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:46,772] Trial 44 finished with value: 654.8832877035479 and parameters: {'num_leaves': 47, 'learning_rate': 0.2771620089346378, 'min_child_samples': 74, 'max_depth': 3, 'feature_fraction': 0.8160823576525675, 'bagging_fraction': 0.8612368697757115, 'bagging_freq': 10, 'lambda_l1': 5.999318872336445, 'lambda_l2': 6.634177333066056}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:47,701] Trial 45 finished with value: 647.6971499047419 and parameters: {'num_leaves': 68, 'learning_rate': 0.09941591019858205, 'min_child_samples': 81, 'max_depth': 6, 'feature_fraction': 0.9190400811932736, 'bagging_fraction': 0.807661374617237, 'bagging_freq': 7, 'lambda_l1': 8.070893069398121, 'lambda_l2': 1.7669971521570182}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:48,371] Trial 46 finished with value: 645.4125271065061 and parameters: {'num_leaves': 29, 'learning_rate': 0.18005088355765794, 'min_child_samples': 96, 'max_depth': 4, 'feature_fraction': 0.9982409522597624, 'bagging_fraction': 0.7362857802752619, 'bagging_freq': 8, 'lambda_l1': 4.986414072301393, 'lambda_l2': 7.130250969885596}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:49,087] Trial 47 finished with value: 642.5412437117075 and parameters: {'num_leaves': 23, 'learning_rate': 0.15274350455168356, 'min_child_samples': 27, 'max_depth': 6, 'feature_fraction': 0.7856520657906572, 'bagging_fraction': 0.9956462991577971, 'bagging_freq': 10, 'lambda_l1': 6.818516872579354, 'lambda_l2': 5.943552499663844}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:49,617] Trial 48 finished with value: 652.982467034955 and parameters: {'num_leaves': 20, 'learning_rate': 0.15401140547780628, 'min_child_samples': 24, 'max_depth': 6, 'feature_fraction': 0.6818962697263993, 'bagging_fraction': 0.9613468179380777, 'bagging_freq': 10, 'lambda_l1': 6.712902860774687, 'lambda_l2': 5.888787075468496}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:50,237] Trial 49 finished with value: 649.1898157736196 and parameters: {'num_leaves': 24, 'learning_rate': 0.22078535454878528, 'min_child_samples': 15, 'max_depth': 7, 'feature_fraction': 0.7761025258482941, 'bagging_fraction': 0.9979341249501786, 'bagging_freq': 10, 'lambda_l1': 8.875949852599213, 'lambda_l2': 5.609581300355998}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:50,881] Trial 50 finished with value: 694.4880991065365 and parameters: {'num_leaves': 29, 'learning_rate': 0.16935842437868037, 'min_child_samples': 38, 'max_depth': 6, 'feature_fraction': 0.6406840792895764, 'bagging_fraction': 0.9463300214494845, 'bagging_freq': 9, 'lambda_l1': 4.042515303398181, 'lambda_l2': 6.302690399822815}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:51,486] Trial 51 finished with value: 655.0065638299592 and parameters: {'num_leaves': 50, 'learning_rate': 0.14075647137890385, 'min_child_samples': 30, 'max_depth': 5, 'feature_fraction': 0.7651907985175611, 'bagging_fraction': 0.7776726879304345, 'bagging_freq': 10, 'lambda_l1': 6.326118463904445, 'lambda_l2': 4.923089499769324}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:52,237] Trial 52 finished with value: 644.0045994736063 and parameters: {'num_leaves': 23, 'learning_rate': 0.1133662752705894, 'min_child_samples': 20, 'max_depth': 5, 'feature_fraction': 0.8093235334157599, 'bagging_fraction': 0.8467045355844418, 'bagging_freq': 9, 'lambda_l1': 6.045178309305462, 'lambda_l2': 4.369967279440312}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:52,959] Trial 53 finished with value: 648.3684268390116 and parameters: {'num_leaves': 23, 'learning_rate': 0.1160424164629642, 'min_child_samples': 18, 'max_depth': 4, 'feature_fraction': 0.7958655414908153, 'bagging_fraction': 0.8521534953007521, 'bagging_freq': 9, 'lambda_l1': 5.721225145832057, 'lambda_l2': 7.867199068560046}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:53,639] Trial 54 finished with value: 701.7508103569509 and parameters: {'num_leaves': 20, 'learning_rate': 0.19034334983349036, 'min_child_samples': 31, 'max_depth': 5, 'feature_fraction': 0.5341503889048508, 'bagging_fraction': 0.9051127578264078, 'bagging_freq': 10, 'lambda_l1': 7.331733748221638, 'lambda_l2': 8.803755569546428}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:54,767] Trial 55 finished with value: 649.0735813066904 and parameters: {'num_leaves': 27, 'learning_rate': 0.08528703629232853, 'min_child_samples': 27, 'max_depth': 4, 'feature_fraction': 0.8816321660419906, 'bagging_fraction': 0.930977071385424, 'bagging_freq': 9, 'lambda_l1': 5.969289644162204, 'lambda_l2': 5.439536878634853}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:55,471] Trial 56 finished with value: 644.9567174936017 and parameters: {'num_leaves': 31, 'learning_rate': 0.10563677426177673, 'min_child_samples': 20, 'max_depth': 6, 'feature_fraction': 0.7514080722582499, 'bagging_fraction': 0.6887425903565367, 'bagging_freq': 7, 'lambda_l1': 5.335017780694695, 'lambda_l2': 4.347691310288041}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:56,069] Trial 57 finished with value: 653.059723218389 and parameters: {'num_leaves': 59, 'learning_rate': 0.1468337580949696, 'min_child_samples': 38, 'max_depth': 5, 'feature_fraction': 0.850411889158109, 'bagging_fraction': 0.5070587568226921, 'bagging_freq': 8, 'lambda_l1': 6.803284186030429, 'lambda_l2': 9.544300677624099}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:57,032] Trial 58 finished with value: 666.4395644505322 and parameters: {'num_leaves': 23, 'learning_rate': 0.11880336391037055, 'min_child_samples': 55, 'max_depth': 3, 'feature_fraction': 0.8176054195945741, 'bagging_fraction': 0.9760673789164138, 'bagging_freq': 10, 'lambda_l1': 4.666292325286676, 'lambda_l2': 6.598042889571558}. Best is trial 38 with value: 641.8393155044645.\n",
      "[I 2025-07-22 04:14:59,673] Trial 59 finished with value: 635.1092577146112 and parameters: {'num_leaves': 27, 'learning_rate': 0.013543841701209036, 'min_child_samples': 14, 'max_depth': 12, 'feature_fraction': 0.9430131088297382, 'bagging_fraction': 0.8342363451652917, 'bagging_freq': 9, 'lambda_l1': 5.292869960470173, 'lambda_l2': 7.376802833555514}. Best is trial 59 with value: 635.1092577146112.\n",
      "[I 2025-07-22 04:15:02,151] Trial 60 finished with value: 636.7948566050339 and parameters: {'num_leaves': 35, 'learning_rate': 0.011658337995168341, 'min_child_samples': 11, 'max_depth': 12, 'feature_fraction': 0.9376655622784418, 'bagging_fraction': 0.8754629919697009, 'bagging_freq': 6, 'lambda_l1': 5.150198752570424, 'lambda_l2': 8.27180990021555}. Best is trial 59 with value: 635.1092577146112.\n",
      "[I 2025-07-22 04:15:05,254] Trial 61 finished with value: 634.7214999200908 and parameters: {'num_leaves': 35, 'learning_rate': 0.0134290995004515, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9340245302057317, 'bagging_fraction': 0.8801065170857094, 'bagging_freq': 6, 'lambda_l1': 5.36583891949173, 'lambda_l2': 8.133502515855712}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-22 04:15:07,410] Trial 62 finished with value: 636.5880552660823 and parameters: {'num_leaves': 36, 'learning_rate': 0.013426581533714038, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9411061462129773, 'bagging_fraction': 0.8818474635893326, 'bagging_freq': 6, 'lambda_l1': 3.927102255697406, 'lambda_l2': 8.482680276233364}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-22 04:15:10,001] Trial 63 finished with value: 639.9629103663832 and parameters: {'num_leaves': 40, 'learning_rate': 0.012570736253928268, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9367254736229605, 'bagging_fraction': 0.8809041413307961, 'bagging_freq': 6, 'lambda_l1': 3.766837354833626, 'lambda_l2': 8.392114075364747}. Best is trial 61 with value: 634.7214999200908.\n",
      "[I 2025-07-22 04:15:12,851] Trial 64 finished with value: 631.7720932403886 and parameters: {'num_leaves': 41, 'learning_rate': 0.013027420648364107, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9799179151705236, 'bagging_fraction': 0.8738286163424556, 'bagging_freq': 6, 'lambda_l1': 3.7443440139207125, 'lambda_l2': 8.311457587262433}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-22 04:15:15,153] Trial 65 finished with value: 634.9114428662369 and parameters: {'num_leaves': 41, 'learning_rate': 0.013358121959769863, 'min_child_samples': 9, 'max_depth': 12, 'feature_fraction': 0.9435676126601654, 'bagging_fraction': 0.8823569255182764, 'bagging_freq': 6, 'lambda_l1': 2.4310383753172697, 'lambda_l2': 8.358104664930803}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-22 04:15:18,437] Trial 66 finished with value: 634.4634733108757 and parameters: {'num_leaves': 39, 'learning_rate': 0.012210055333014367, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9399492044160658, 'bagging_fraction': 0.8744450331838687, 'bagging_freq': 6, 'lambda_l1': 2.258970715723338, 'lambda_l2': 8.370493635092116}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-22 04:15:20,228] Trial 67 finished with value: 634.2985517853257 and parameters: {'num_leaves': 37, 'learning_rate': 0.02718182686268194, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.9829704371701842, 'bagging_fraction': 0.9048273028928185, 'bagging_freq': 5, 'lambda_l1': 1.73277082521835, 'lambda_l2': 9.184864532664047}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-22 04:15:22,136] Trial 68 finished with value: 631.9031278639253 and parameters: {'num_leaves': 42, 'learning_rate': 0.026168981351700336, 'min_child_samples': 6, 'max_depth': 11, 'feature_fraction': 0.9803176678953885, 'bagging_fraction': 0.9025553635783577, 'bagging_freq': 5, 'lambda_l1': 2.130172396804875, 'lambda_l2': 9.27515279737591}. Best is trial 64 with value: 631.7720932403886.\n",
      "[I 2025-07-22 04:15:23,774] Trial 69 finished with value: 634.707272070923 and parameters: {'num_leaves': 42, 'learning_rate': 0.026464789886036406, 'min_child_samples': 5, 'max_depth': 11, 'feature_fraction': 0.982088801428082, 'bagging_fraction': 0.9070339906245926, 'bagging_freq': 4, 'lambda_l1': 2.0465989517309167, 'lambda_l2': 9.256491938837865}. Best is trial 64 with value: 631.7720932403886.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 41, 'learning_rate': 0.013027420648364107, 'min_child_samples': 8, 'max_depth': 12, 'feature_fraction': 0.9799179151705236, 'bagging_fraction': 0.8738286163424556, 'bagging_freq': 6, 'lambda_l1': 3.7443440139207125, 'lambda_l2': 8.311457587262433}\n",
      "Best RMSE on validation set during tuning (Optuna): 631.77\n"
     ]
    }
   ],
   "source": [
    "study_p02 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) \n",
    "study_p02.optimize(objective_p02, n_trials=70, show_progress_bar=True) \n",
    "\n",
    "\n",
    "best_params_p02 = study_p02.best_params\n",
    "best_rmse_optuna_p02 = study_p02.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p02)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p02:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is dedicated to training the final LightGBM model for Problem Two (forecasting passenger numbers one week in advance) using the optimal hyperparameters identified by Optuna, and then rigorously evaluating its performance on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p02:\n",
      "RMSE: 632.22\n",
      "R²: 0.8054\n"
     ]
    }
   ],
   "source": [
    "final_model_p02 = lgb.train(best_params_p02,\n",
    "                            lgb.Dataset(X_train_p02, label=y_train_p02),\n",
    "                            num_boost_round=1000) \n",
    "\n",
    "y_pred_final_p02 = final_model_p02.predict(X_test_p02)\n",
    "\n",
    "\n",
    "rmse_final_p02 = np.sqrt(mean_squared_error(y_test_p02, y_pred_final_p02))\n",
    "r2_final_p02 = r2_score(y_test_p02, y_pred_final_p02)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p02:\")\n",
    "print(f\"RMSE: {rmse_final_p02:.2f}\")\n",
    "print(f\"R²: {r2_final_p02:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``RMSE: 632.22`` \n",
    "On average, this model weekly passenger forecasts are off by approximately 632 passengers.\n",
    "\n",
    "#### ``R²: 0.8054 ``\n",
    "This indicates that about ``80.54% ``of the variability in weekly passenger numbers can be explained by this model features and its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Passengers</th>\n",
       "      <th>Base_Predicted_Trains</th>\n",
       "      <th>Buffered_Predicted_Trains</th>\n",
       "      <th>Final_Predicted_Trains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5054</th>\n",
       "      <td>1650</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>941</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>4422</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted_Passengers  Base_Predicted_Trains  Buffered_Predicted_Trains  \\\n",
       "5054                  1650                      3                          3   \n",
       "9269                   342                      1                          1   \n",
       "2293                   941                      2                          2   \n",
       "2764                   121                      1                          1   \n",
       "4798                  4422                      8                          8   \n",
       "\n",
       "      Final_Predicted_Trains  \n",
       "5054                       3  \n",
       "9269                       1  \n",
       "2293                       2  \n",
       "2764                       1  \n",
       "4798                       8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_allocation_p02= calculate_needed_trains(y_pred_final_p02)\n",
    "train_allocation_p02.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Three:\n",
    " Assume we need to forecast the number of passengers for different time periods in order to allocate a more accurate number of trains for the next day. (In this case, we are allowed to use information from previous time periods, but using the year and number of trains columns is still not permitted.)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for problem three :\n",
    "\n",
    "This code defines the preprocess_and_split_data_p03 function, which is designed to prepare your data for Problem Three: forecasting passenger numbers for the next day. This problem emphasizes short-term accuracy and relies heavily on recent historical data, making time-series specific feature engineering and a chronological split essential.\n",
    "The function takes your DataFrame, performs necessary time-series feature engineering (creating lags and rolling statistics), and then splits the data into training and testing sets based on chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data_p03(df, target_column='Ridership', train_size=0.8):\n",
    "       \n",
    "    df['Date'] = pd.to_datetime(\n",
    "    df['Year'].astype(str) + '-' +\n",
    "    df['Month_Num'].astype(str) + '-' +\n",
    "    df['Day'].astype(str),\n",
    "    errors='coerce')\n",
    "\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "    df.sort_values(by=['Date'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Identify columns that define a unique time-series for lagging\n",
    "    # These are the columns that define \"which\" time series we are lagging.\n",
    "    grouping_cols = [\n",
    "      col for col in df.columns if \n",
    "      col.startswith('Corridor_') or\n",
    "      col.startswith('Station_') or\n",
    "      col.startswith('Period_')]\n",
    "    \n",
    "    if 'Workday_y' in df.columns:\n",
    "       grouping_cols.append('Workday_y')\n",
    " \n",
    "    if 'Workday_n' in df.columns:\n",
    "       grouping_cols.append('Workday_n')\n",
    "\n",
    "    if 'Covid19' in df.columns:\n",
    "       grouping_cols.append('Covid19')\n",
    "\n",
    "    # Create lagged features for 'Passengers'\n",
    "    # Lag 1 day (most important for next-day forecast)\n",
    "    df['Ridership_Lag_1'] = df.groupby(grouping_cols)['Ridership'].shift(1)\n",
    "    # Lag 2 days\n",
    "    df['Ridership_Lag_2'] = df.groupby(grouping_cols)['Ridership'].shift(2)\n",
    "    # Lag 7 days (for weekly seasonality, still important)\n",
    "    df['Ridership_Lag_7'] = df.groupby(grouping_cols)['Ridership'].shift(7)\n",
    "\n",
    "    # Rolling Average (e.g., 3-day rolling mean, shifted to avoid leakage)\n",
    "    # min_periods=1 allows calculation even if fewer than 3 periods are available at the start.\n",
    "    df['Rolling_Avg_Ridership_3'] = df.groupby(grouping_cols)['Ridership'].transform(\n",
    "       lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    "    \n",
    "    # Rolling Standard Deviation (e.g., 3-day rolling std, shifted)\n",
    "    df['Rolling_Std_Ridership_3'] = df.groupby(grouping_cols)['Ridership'].transform(\n",
    "         lambda x: x.rolling(window=3, min_periods=1).std().shift(1)).fillna(0)\n",
    "\n",
    "    df.dropna(subset=['Ridership_Lag_1','Ridership_Lag_2','Ridership_Lag_7','Rolling_Avg_Ridership_3'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column, 'Year', 'N_trains', 'Date'])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Calculate split point\n",
    "    split_point = int(len(df) * train_size)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X.iloc[:split_point]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    \n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_test = y.iloc[split_point:]\n",
    "\n",
    "    print(f\"\\nTrain set features (X_train) shape: {X_train.shape}\")\n",
    "    print(f\"Test set features (X_test) shape: {X_test.shape}\")\n",
    "    print(f\"Train set target (y_train) shape: {y_train.shape}\")\n",
    "    print(f\"Test set target (y_test) shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set features (X_train) shape: (48742, 86)\n",
      "Test set features (X_test) shape: (12186, 86)\n",
      "Train set target (y_train) shape: (48742,)\n",
      "Test set target (y_test) shape: (12186,)\n"
     ]
    }
   ],
   "source": [
    "X_train_p03, X_test_p03, y_train_p03, y_test_p03 = preprocess_and_split_data_p03(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM model:\n",
    "\n",
    "This code defines the objective_p03 function, which serves as the core of the hyperparameter optimization process using the Optuna library for Problem Three: forecasting passenger numbers for the next day. This function is designed to be called repeatedly by Optuna, with each call evaluating a different set of hyperparameters for the LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p03(trial):\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False \n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(X_train_p03, label=y_train_p03)\n",
    "    test_data = lgb.Dataset(X_test_p03, label=y_test_p03, reference=train_data)\n",
    "\n",
    " \n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=1000, \n",
    "                      valid_sets=[test_data],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) \n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test_p03, num_iteration=model.best_iteration)\n",
    "\n",
    "    return np.sqrt(mean_squared_error(y_test_p03, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block initiates and executes the hyperparameter optimization process for Problem Three (forecasting passenger numbers for the next day) using the Optuna library. It orchestrates an intelligent search for the best set of LightGBM hyperparameters that minimize the Root Mean Squared Error (RMSE) on the validation set, aiming for the most accurate next-day forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 04:27:13,088] A new study created in memory with name: no-name-2004b13f-27c2-4790-b331-49293e179ab7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830284177f8d4152860ba8138f94b632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 04:27:13,769] Trial 0 finished with value: 564.5341626443118 and parameters: {'num_leaves': 50, 'learning_rate': 0.28570714885887566, 'min_child_samples': 75, 'max_depth': 8, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 0, 'lambda_l1': 8.661761457749352, 'lambda_l2': 6.011150117432088}. Best is trial 0 with value: 564.5341626443118.\n",
      "[I 2025-07-22 04:27:18,189] Trial 1 finished with value: 566.8601726273216 and parameters: {'num_leaves': 77, 'learning_rate': 0.01596950334578271, 'min_child_samples': 98, 'max_depth': 11, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 3.0424224295953772, 'lambda_l2': 5.247564316322379}. Best is trial 0 with value: 564.5341626443118.\n",
      "[I 2025-07-22 04:27:18,963] Trial 2 finished with value: 559.2096247150855 and parameters: {'num_leaves': 54, 'learning_rate': 0.09445645065743215, 'min_child_samples': 63, 'max_depth': 4, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 5, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:19,403] Trial 3 finished with value: 565.6670796716269 and parameters: {'num_leaves': 61, 'learning_rate': 0.18180022496999232, 'min_child_samples': 9, 'max_depth': 9, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 10, 'lambda_l1': 9.656320330745594, 'lambda_l2': 8.08397348116461}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:21,075] Trial 4 finished with value: 562.285967745201 and parameters: {'num_leaves': 44, 'learning_rate': 0.03832491306185132, 'min_child_samples': 70, 'max_depth': 7, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 0, 'lambda_l1': 9.093204020787821, 'lambda_l2': 2.587799816000169}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:22,345] Trial 5 finished with value: 562.7881902857598 and parameters: {'num_leaves': 73, 'learning_rate': 0.10039621206592916, 'min_child_samples': 54, 'max_depth': 8, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 8, 'lambda_l1': 9.394989415641891, 'lambda_l2': 8.948273504276488}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:22,747] Trial 6 finished with value: 575.3027755989731 and parameters: {'num_leaves': 68, 'learning_rate': 0.2773435281567039, 'min_child_samples': 13, 'max_depth': 4, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 4, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:23,164] Trial 7 finished with value: 564.3936006912336 and parameters: {'num_leaves': 48, 'learning_rate': 0.09147100780934041, 'min_child_samples': 57, 'max_depth': 4, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 10, 'lambda_l1': 7.722447692966574, 'lambda_l2': 1.987156815341724}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:23,648] Trial 8 finished with value: 570.041485860406 and parameters: {'num_leaves': 20, 'learning_rate': 0.2464838142519019, 'min_child_samples': 72, 'max_depth': 10, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1586905952512971, 'lambda_l2': 8.631034258755935}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:24,170] Trial 9 finished with value: 567.9310143065799 and parameters: {'num_leaves': 70, 'learning_rate': 0.10596042720726825, 'min_child_samples': 11, 'max_depth': 6, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 7, 'lambda_l1': 8.872127425763265, 'lambda_l2': 4.722149251619493}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:24,600] Trial 10 finished with value: 569.9391841954183 and parameters: {'num_leaves': 96, 'learning_rate': 0.17368350341485295, 'min_child_samples': 34, 'max_depth': 3, 'feature_fraction': 0.7512656088373982, 'bagging_fraction': 0.7606165441675251, 'bagging_freq': 6, 'lambda_l1': 6.240835271723655, 'lambda_l2': 0.3990753571948482}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:27,331] Trial 11 finished with value: 564.4746390474776 and parameters: {'num_leaves': 33, 'learning_rate': 0.013342005185465269, 'min_child_samples': 79, 'max_depth': 6, 'feature_fraction': 0.7171781358782057, 'bagging_fraction': 0.7409481648316649, 'bagging_freq': 0, 'lambda_l1': 6.071842740332256, 'lambda_l2': 2.739245103851502}. Best is trial 2 with value: 559.2096247150855.\n",
      "[I 2025-07-22 04:27:28,574] Trial 12 finished with value: 557.0150386147878 and parameters: {'num_leaves': 43, 'learning_rate': 0.05178646763926213, 'min_child_samples': 37, 'max_depth': 6, 'feature_fraction': 0.8033425041274396, 'bagging_fraction': 0.7421073602513316, 'bagging_freq': 5, 'lambda_l1': 7.299436732862953, 'lambda_l2': 2.9784455040856885}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:29,660] Trial 13 finished with value: 563.4448675614052 and parameters: {'num_leaves': 34, 'learning_rate': 0.06438446311567651, 'min_child_samples': 37, 'max_depth': 5, 'feature_fraction': 0.806943907248636, 'bagging_fraction': 0.6714129799598364, 'bagging_freq': 5, 'lambda_l1': 6.958447287283494, 'lambda_l2': 0.37303177594075376}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:31,000] Trial 14 finished with value: 566.6384815414765 and parameters: {'num_leaves': 87, 'learning_rate': 0.12615680263255413, 'min_child_samples': 43, 'max_depth': 3, 'feature_fraction': 0.9983491531386127, 'bagging_fraction': 0.833403143155805, 'bagging_freq': 5, 'lambda_l1': 4.8377410774800005, 'lambda_l2': 3.8541884744298303}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:32,108] Trial 15 finished with value: 563.7485051692693 and parameters: {'num_leaves': 57, 'learning_rate': 0.0629149829204078, 'min_child_samples': 26, 'max_depth': 5, 'feature_fraction': 0.8195913792189864, 'bagging_fraction': 0.6614141294398876, 'bagging_freq': 8, 'lambda_l1': 5.03553535027425, 'lambda_l2': 1.7799649353551308}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:33,486] Trial 16 finished with value: 561.8840550624312 and parameters: {'num_leaves': 36, 'learning_rate': 0.14773759810005263, 'min_child_samples': 60, 'max_depth': 12, 'feature_fraction': 0.6639926607342312, 'bagging_fraction': 0.8348357285067618, 'bagging_freq': 3, 'lambda_l1': 7.919046579773576, 'lambda_l2': 3.6966322148534507}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:35,250] Trial 17 finished with value: 560.6274870063498 and parameters: {'num_leaves': 22, 'learning_rate': 0.06335382638228174, 'min_child_samples': 94, 'max_depth': 6, 'feature_fraction': 0.7458414327410122, 'bagging_fraction': 0.9095019130282986, 'bagging_freq': 6, 'lambda_l1': 4.2907232907365405, 'lambda_l2': 6.71236967350552}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:35,753] Trial 18 finished with value: 571.0307822427015 and parameters: {'num_leaves': 59, 'learning_rate': 0.20365981037938688, 'min_child_samples': 24, 'max_depth': 4, 'feature_fraction': 0.6716810389363811, 'bagging_fraction': 0.704506393603957, 'bagging_freq': 2, 'lambda_l1': 6.739745678476541, 'lambda_l2': 1.3267349903190364}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:36,592] Trial 19 finished with value: 558.5944564769621 and parameters: {'num_leaves': 41, 'learning_rate': 0.13441809139151736, 'min_child_samples': 47, 'max_depth': 7, 'feature_fraction': 0.813878444618394, 'bagging_fraction': 0.615169236239334, 'bagging_freq': 4, 'lambda_l1': 7.718448973154885, 'lambda_l2': 3.3668451792504683}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:37,359] Trial 20 finished with value: 560.4287463791983 and parameters: {'num_leaves': 42, 'learning_rate': 0.2144489993810001, 'min_child_samples': 44, 'max_depth': 7, 'feature_fraction': 0.8488995529150473, 'bagging_fraction': 0.6119033716305957, 'bagging_freq': 2, 'lambda_l1': 0.11620961627552973, 'lambda_l2': 9.938427850497089}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:38,158] Trial 21 finished with value: 561.1362262951247 and parameters: {'num_leaves': 29, 'learning_rate': 0.13590023404711632, 'min_child_samples': 47, 'max_depth': 5, 'feature_fraction': 0.9264630750139052, 'bagging_fraction': 0.6332395074528492, 'bagging_freq': 4, 'lambda_l1': 7.841477937509251, 'lambda_l2': 3.6658469952805817}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:39,335] Trial 22 finished with value: 562.7959236559344 and parameters: {'num_leaves': 53, 'learning_rate': 0.08113741911018058, 'min_child_samples': 61, 'max_depth': 9, 'feature_fraction': 0.7819341998068986, 'bagging_fraction': 0.7865722310756497, 'bagging_freq': 5, 'lambda_l1': 7.284191629393661, 'lambda_l2': 2.910858870170244}. Best is trial 12 with value: 557.0150386147878.\n",
      "[I 2025-07-22 04:27:40,333] Trial 23 finished with value: 556.9398696599536 and parameters: {'num_leaves': 42, 'learning_rate': 0.12180910853713132, 'min_child_samples': 84, 'max_depth': 7, 'feature_fraction': 0.7060765755742385, 'bagging_fraction': 0.7084231924512825, 'bagging_freq': 6, 'lambda_l1': 5.474361035502866, 'lambda_l2': 1.1388465300054271}. Best is trial 23 with value: 556.9398696599536.\n",
      "[I 2025-07-22 04:27:41,531] Trial 24 finished with value: 561.603833442438 and parameters: {'num_leaves': 41, 'learning_rate': 0.1206259384924455, 'min_child_samples': 84, 'max_depth': 7, 'feature_fraction': 0.7173977827786409, 'bagging_fraction': 0.719908046946871, 'bagging_freq': 7, 'lambda_l1': 5.4812016079875825, 'lambda_l2': 1.0200212888100284}. Best is trial 23 with value: 556.9398696599536.\n",
      "[I 2025-07-22 04:27:42,093] Trial 25 finished with value: 572.0831210824309 and parameters: {'num_leaves': 26, 'learning_rate': 0.16243658692033264, 'min_child_samples': 26, 'max_depth': 9, 'feature_fraction': 0.8407905849536597, 'bagging_fraction': 0.5006061040379494, 'bagging_freq': 6, 'lambda_l1': 3.7466454186623004, 'lambda_l2': 4.426943188579218}. Best is trial 23 with value: 556.9398696599536.\n",
      "[I 2025-07-22 04:27:42,857] Trial 26 finished with value: 574.1205809925995 and parameters: {'num_leaves': 39, 'learning_rate': 0.1933734578609974, 'min_child_samples': 35, 'max_depth': 8, 'feature_fraction': 0.775877496965112, 'bagging_fraction': 0.7836665627187115, 'bagging_freq': 4, 'lambda_l1': 5.898963314462399, 'lambda_l2': 3.235948400769368}. Best is trial 23 with value: 556.9398696599536.\n",
      "[I 2025-07-22 04:27:44,168] Trial 27 finished with value: 561.9104694099684 and parameters: {'num_leaves': 48, 'learning_rate': 0.03720132063335333, 'min_child_samples': 87, 'max_depth': 6, 'feature_fraction': 0.7160705121771777, 'bagging_fraction': 0.6330419923883435, 'bagging_freq': 7, 'lambda_l1': 6.7842664787030476, 'lambda_l2': 5.530198325721288}. Best is trial 23 with value: 556.9398696599536.\n",
      "[I 2025-07-22 04:27:45,020] Trial 28 finished with value: 556.4079749940266 and parameters: {'num_leaves': 64, 'learning_rate': 0.1153055431763099, 'min_child_samples': 49, 'max_depth': 7, 'feature_fraction': 0.8718989420825612, 'bagging_fraction': 0.7090548006508024, 'bagging_freq': 3, 'lambda_l1': 8.4298093731787, 'lambda_l2': 0.9027761493408102}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:46,420] Trial 29 finished with value: 561.2287173531004 and parameters: {'num_leaves': 64, 'learning_rate': 0.03938887510932905, 'min_child_samples': 67, 'max_depth': 8, 'feature_fraction': 0.9930658074902059, 'bagging_fraction': 0.7970963726474016, 'bagging_freq': 1, 'lambda_l1': 8.538116981236033, 'lambda_l2': 0.05578061053233618}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:46,978] Trial 30 finished with value: 568.7276243979638 and parameters: {'num_leaves': 47, 'learning_rate': 0.11210517750779513, 'min_child_samples': 19, 'max_depth': 6, 'feature_fraction': 0.9558460102215041, 'bagging_fraction': 0.7171870304402891, 'bagging_freq': 8, 'lambda_l1': 8.51247335487599, 'lambda_l2': 1.188535769091197}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:47,647] Trial 31 finished with value: 560.9672980099041 and parameters: {'num_leaves': 29, 'learning_rate': 0.14750949966082266, 'min_child_samples': 48, 'max_depth': 7, 'feature_fraction': 0.8814300089010964, 'bagging_fraction': 0.5940631403433928, 'bagging_freq': 3, 'lambda_l1': 7.2796134940491655, 'lambda_l2': 2.3316126288989736}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:48,511] Trial 32 finished with value: 561.1671897137564 and parameters: {'num_leaves': 84, 'learning_rate': 0.07642178738212843, 'min_child_samples': 40, 'max_depth': 7, 'feature_fraction': 0.8523030724899716, 'bagging_fraction': 0.6984539682355769, 'bagging_freq': 4, 'lambda_l1': 8.410654391605009, 'lambda_l2': 0.86169525448187}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:49,171] Trial 33 finished with value: 559.4088649583044 and parameters: {'num_leaves': 52, 'learning_rate': 0.14140369070000733, 'min_child_samples': 51, 'max_depth': 9, 'feature_fraction': 0.7952981890364875, 'bagging_fraction': 0.6367575325738621, 'bagging_freq': 3, 'lambda_l1': 9.819076660873037, 'lambda_l2': 6.256988315210917}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:49,973] Trial 34 finished with value: 563.0909560825488 and parameters: {'num_leaves': 65, 'learning_rate': 0.16404334663135428, 'min_child_samples': 31, 'max_depth': 8, 'feature_fraction': 0.8224134835597027, 'bagging_fraction': 0.5661643425206676, 'bagging_freq': 5, 'lambda_l1': 6.267422110802715, 'lambda_l2': 1.5391695547077262}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:50,699] Trial 35 finished with value: 561.4674409264462 and parameters: {'num_leaves': 57, 'learning_rate': 0.12569760187755394, 'min_child_samples': 52, 'max_depth': 10, 'feature_fraction': 0.6214932394478824, 'bagging_fraction': 0.7345560816002078, 'bagging_freq': 6, 'lambda_l1': 5.325989793124685, 'lambda_l2': 2.247170025211875}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:52,025] Trial 36 finished with value: 558.3357696218127 and parameters: {'num_leaves': 45, 'learning_rate': 0.050024380823752775, 'min_child_samples': 99, 'max_depth': 5, 'feature_fraction': 0.747003326954369, 'bagging_fraction': 0.6862166461470511, 'bagging_freq': 4, 'lambda_l1': 7.977054176699918, 'lambda_l2': 4.171141624274357}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:53,764] Trial 37 finished with value: 562.4509820011519 and parameters: {'num_leaves': 79, 'learning_rate': 0.029865909197443752, 'min_child_samples': 100, 'max_depth': 5, 'feature_fraction': 0.7468724162196149, 'bagging_fraction': 0.6804944632875493, 'bagging_freq': 1, 'lambda_l1': 3.1589183390434563, 'lambda_l2': 4.382802534205804}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:54,879] Trial 38 finished with value: 562.3259169724815 and parameters: {'num_leaves': 62, 'learning_rate': 0.04908704750012919, 'min_child_samples': 90, 'max_depth': 5, 'feature_fraction': 0.7622822044395262, 'bagging_fraction': 0.7560770217868588, 'bagging_freq': 9, 'lambda_l1': 9.880111612218021, 'lambda_l2': 7.261315570653675}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:55,975] Trial 39 finished with value: 561.7113602392114 and parameters: {'num_leaves': 45, 'learning_rate': 0.0888906722435499, 'min_child_samples': 77, 'max_depth': 6, 'feature_fraction': 0.6883639107345911, 'bagging_fraction': 0.8194449343168201, 'bagging_freq': 5, 'lambda_l1': 9.190710255829362, 'lambda_l2': 5.557471959467853}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:58,012] Trial 40 finished with value: 566.8112783039907 and parameters: {'num_leaves': 50, 'learning_rate': 0.023656618287310693, 'min_child_samples': 97, 'max_depth': 4, 'feature_fraction': 0.559057300200795, 'bagging_fraction': 0.9042940834597448, 'bagging_freq': 3, 'lambda_l1': 8.041671831232877, 'lambda_l2': 0.6893740549224537}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:58,948] Trial 41 finished with value: 558.3028390321172 and parameters: {'num_leaves': 38, 'learning_rate': 0.1046164931793575, 'min_child_samples': 56, 'max_depth': 7, 'feature_fraction': 0.8656868863705365, 'bagging_fraction': 0.6497419073620467, 'bagging_freq': 4, 'lambda_l1': 7.499211505573879, 'lambda_l2': 3.477737663552765}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:27:59,970] Trial 42 finished with value: 558.8883648636144 and parameters: {'num_leaves': 36, 'learning_rate': 0.10269630501971093, 'min_child_samples': 66, 'max_depth': 7, 'feature_fraction': 0.9315533057940893, 'bagging_fraction': 0.6889072080715603, 'bagging_freq': 4, 'lambda_l1': 7.285549711427053, 'lambda_l2': 4.992293164726332}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:28:00,931] Trial 43 finished with value: 559.7763245906057 and parameters: {'num_leaves': 38, 'learning_rate': 0.052080654685917306, 'min_child_samples': 5, 'max_depth': 6, 'feature_fraction': 0.8722787592152699, 'bagging_fraction': 0.6514577351666362, 'bagging_freq': 6, 'lambda_l1': 9.066139956658406, 'lambda_l2': 4.033367517174515}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:28:01,934] Trial 44 finished with value: 563.5232996811968 and parameters: {'num_leaves': 32, 'learning_rate': 0.07504409073787038, 'min_child_samples': 56, 'max_depth': 8, 'feature_fraction': 0.9104007377606137, 'bagging_fraction': 0.7627378337279127, 'bagging_freq': 2, 'lambda_l1': 6.498800892242756, 'lambda_l2': 2.9507645065039783}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:28:02,943] Trial 45 finished with value: 559.0801356055496 and parameters: {'num_leaves': 74, 'learning_rate': 0.09401720749078808, 'min_child_samples': 81, 'max_depth': 6, 'feature_fraction': 0.7008216989154508, 'bagging_fraction': 0.7230376982754697, 'bagging_freq': 1, 'lambda_l1': 5.743156976351653, 'lambda_l2': 1.8511281943263216}. Best is trial 28 with value: 556.4079749940266.\n",
      "[I 2025-07-22 04:28:04,081] Trial 46 finished with value: 552.7821063891009 and parameters: {'num_leaves': 46, 'learning_rate': 0.11178999016846031, 'min_child_samples': 91, 'max_depth': 5, 'feature_fraction': 0.83061889772184, 'bagging_fraction': 0.6656375058550822, 'bagging_freq': 4, 'lambda_l1': 1.9488216899277764, 'lambda_l2': 4.334997106167453}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:05,095] Trial 47 finished with value: 564.2080931348032 and parameters: {'num_leaves': 55, 'learning_rate': 0.11422738022954501, 'min_child_samples': 73, 'max_depth': 7, 'feature_fraction': 0.838175301438244, 'bagging_fraction': 0.5900739273599871, 'bagging_freq': 5, 'lambda_l1': 2.317654429707663, 'lambda_l2': 2.488699457382436}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:06,499] Trial 48 finished with value: 559.5592215536612 and parameters: {'num_leaves': 70, 'learning_rate': 0.10476833459959126, 'min_child_samples': 94, 'max_depth': 8, 'feature_fraction': 0.8655649275034535, 'bagging_fraction': 0.6614917632671611, 'bagging_freq': 3, 'lambda_l1': 1.5457619032104644, 'lambda_l2': 4.818068513025208}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:07,554] Trial 49 finished with value: 559.9263098813784 and parameters: {'num_leaves': 50, 'learning_rate': 0.08482966781535316, 'min_child_samples': 40, 'max_depth': 10, 'feature_fraction': 0.9006660582937552, 'bagging_fraction': 0.7698215131678094, 'bagging_freq': 7, 'lambda_l1': 3.829190246972335, 'lambda_l2': 3.244072675057752}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:08,291] Trial 50 finished with value: 560.1229545829927 and parameters: {'num_leaves': 24, 'learning_rate': 0.17956398988626823, 'min_child_samples': 30, 'max_depth': 3, 'feature_fraction': 0.7930828870290962, 'bagging_fraction': 0.5571047430979033, 'bagging_freq': 5, 'lambda_l1': 4.9348082233341515, 'lambda_l2': 0.2274032615848287}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:09,890] Trial 51 finished with value: 562.2589143249505 and parameters: {'num_leaves': 44, 'learning_rate': 0.052897759204036714, 'min_child_samples': 89, 'max_depth': 5, 'feature_fraction': 0.7323027628931588, 'bagging_fraction': 0.7031145629555727, 'bagging_freq': 4, 'lambda_l1': 8.173858195425927, 'lambda_l2': 4.222785903492906}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:11,077] Trial 52 finished with value: 556.3138804431213 and parameters: {'num_leaves': 46, 'learning_rate': 0.0735639326660168, 'min_child_samples': 84, 'max_depth': 4, 'feature_fraction': 0.829433004134102, 'bagging_fraction': 0.6813129229814883, 'bagging_freq': 4, 'lambda_l1': 7.619898231934176, 'lambda_l2': 3.6211752507725214}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:12,302] Trial 53 finished with value: 555.1316591442436 and parameters: {'num_leaves': 38, 'learning_rate': 0.06673026358964902, 'min_child_samples': 83, 'max_depth': 4, 'feature_fraction': 0.829175284358569, 'bagging_fraction': 0.6465187781912252, 'bagging_freq': 3, 'lambda_l1': 7.514149150525317, 'lambda_l2': 3.5665493942430797}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:13,206] Trial 54 finished with value: 564.0995559699365 and parameters: {'num_leaves': 31, 'learning_rate': 0.065483830461305, 'min_child_samples': 82, 'max_depth': 4, 'feature_fraction': 0.8261002344606758, 'bagging_fraction': 0.7345630830635426, 'bagging_freq': 2, 'lambda_l1': 0.1379561710888897, 'lambda_l2': 5.25415104001982}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:13,849] Trial 55 finished with value: 573.3503274848608 and parameters: {'num_leaves': 59, 'learning_rate': 0.07445202826348106, 'min_child_samples': 85, 'max_depth': 3, 'feature_fraction': 0.7697868419634245, 'bagging_fraction': 0.6742752750610185, 'bagging_freq': 3, 'lambda_l1': 6.906834441400404, 'lambda_l2': 2.8189433909073247}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:14,492] Trial 56 finished with value: 561.294297391471 and parameters: {'num_leaves': 35, 'learning_rate': 0.11871544605190901, 'min_child_samples': 92, 'max_depth': 4, 'feature_fraction': 0.7997276615046491, 'bagging_fraction': 0.6197940437473114, 'bagging_freq': 3, 'lambda_l1': 4.41472385989905, 'lambda_l2': 1.8552701885799763}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:15,611] Trial 57 finished with value: 555.095280631515 and parameters: {'num_leaves': 42, 'learning_rate': 0.09592180313956104, 'min_child_samples': 77, 'max_depth': 4, 'feature_fraction': 0.892267481765475, 'bagging_fraction': 0.7086854939938013, 'bagging_freq': 5, 'lambda_l1': 8.782456660239225, 'lambda_l2': 3.802479109412386}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:16,316] Trial 58 finished with value: 556.0771257082988 and parameters: {'num_leaves': 41, 'learning_rate': 0.2768150793788384, 'min_child_samples': 77, 'max_depth': 3, 'feature_fraction': 0.8958939519185398, 'bagging_fraction': 0.7054698562423259, 'bagging_freq': 6, 'lambda_l1': 8.79518671252957, 'lambda_l2': 4.663367565850496}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:16,952] Trial 59 finished with value: 554.4202630834128 and parameters: {'num_leaves': 55, 'learning_rate': 0.2911549303669436, 'min_child_samples': 74, 'max_depth': 3, 'feature_fraction': 0.9440504505900219, 'bagging_fraction': 0.6501160491413392, 'bagging_freq': 2, 'lambda_l1': 9.529480853678427, 'lambda_l2': 4.519502370321749}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:17,435] Trial 60 finished with value: 563.483118371343 and parameters: {'num_leaves': 47, 'learning_rate': 0.2979283112464063, 'min_child_samples': 76, 'max_depth': 3, 'feature_fraction': 0.9487700205456864, 'bagging_fraction': 0.5950163143464243, 'bagging_freq': 0, 'lambda_l1': 8.852257349031612, 'lambda_l2': 4.610014708793819}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:17,962] Trial 61 finished with value: 567.4181128002198 and parameters: {'num_leaves': 54, 'learning_rate': 0.278383488562074, 'min_child_samples': 72, 'max_depth': 4, 'feature_fraction': 0.8988282359065377, 'bagging_fraction': 0.648759020285905, 'bagging_freq': 2, 'lambda_l1': 9.3183602831404, 'lambda_l2': 5.990785475186032}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:18,583] Trial 62 finished with value: 560.9146199148267 and parameters: {'num_leaves': 40, 'learning_rate': 0.25572764822767624, 'min_child_samples': 79, 'max_depth': 3, 'feature_fraction': 0.9652522520247843, 'bagging_fraction': 0.691161260974798, 'bagging_freq': 1, 'lambda_l1': 9.474802286756969, 'lambda_l2': 3.7387283948547516}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:19,103] Trial 63 finished with value: 558.5791184991688 and parameters: {'num_leaves': 51, 'learning_rate': 0.24521417283911362, 'min_child_samples': 71, 'max_depth': 4, 'feature_fraction': 0.9779448929298332, 'bagging_fraction': 0.6198739819548846, 'bagging_freq': 2, 'lambda_l1': 8.727352573130657, 'lambda_l2': 5.25213648699096}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:19,715] Trial 64 finished with value: 565.5606094011658 and parameters: {'num_leaves': 100, 'learning_rate': 0.2979033137302401, 'min_child_samples': 68, 'max_depth': 3, 'feature_fraction': 0.9250020582154669, 'bagging_fraction': 0.6724708936698826, 'bagging_freq': 3, 'lambda_l1': 9.550034055808926, 'lambda_l2': 3.9663822809867835}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:20,192] Trial 65 finished with value: 563.217788098961 and parameters: {'num_leaves': 48, 'learning_rate': 0.2640959324501002, 'min_child_samples': 64, 'max_depth': 3, 'feature_fraction': 0.9436002763056569, 'bagging_fraction': 0.7103937612285833, 'bagging_freq': 4, 'lambda_l1': 8.414487685285906, 'lambda_l2': 4.604728187581352}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:20,930] Trial 66 finished with value: 559.0078446699387 and parameters: {'num_leaves': 56, 'learning_rate': 0.2308564135768672, 'min_child_samples': 87, 'max_depth': 4, 'feature_fraction': 0.8894637597769551, 'bagging_fraction': 0.6654321125288101, 'bagging_freq': 5, 'lambda_l1': 8.761059515663497, 'lambda_l2': 5.65932089348777}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:21,467] Trial 67 finished with value: 565.7899691108764 and parameters: {'num_leaves': 67, 'learning_rate': 0.28663763176522444, 'min_child_samples': 79, 'max_depth': 4, 'feature_fraction': 0.9133388492219316, 'bagging_fraction': 0.6365151461682069, 'bagging_freq': 4, 'lambda_l1': 8.220675930866694, 'lambda_l2': 4.898392663427519}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:22,167] Trial 68 finished with value: 563.2827417308628 and parameters: {'num_leaves': 60, 'learning_rate': 0.13264579853529654, 'min_child_samples': 75, 'max_depth': 3, 'feature_fraction': 0.8516648177327014, 'bagging_fraction': 0.7298065045164674, 'bagging_freq': 6, 'lambda_l1': 9.003571481460668, 'lambda_l2': 3.6014932639674173}. Best is trial 46 with value: 552.7821063891009.\n",
      "[I 2025-07-22 04:28:23,309] Trial 69 finished with value: 558.0500151177727 and parameters: {'num_leaves': 44, 'learning_rate': 0.09158865079185737, 'min_child_samples': 96, 'max_depth': 5, 'feature_fraction': 0.87894944694824, 'bagging_fraction': 0.7475043540125321, 'bagging_freq': 2, 'lambda_l1': 7.71312351856921, 'lambda_l2': 3.180497665275837}. Best is trial 46 with value: 552.7821063891009.\n",
      "\n",
      "Best parameters found by Optuna: {'num_leaves': 46, 'learning_rate': 0.11178999016846031, 'min_child_samples': 91, 'max_depth': 5, 'feature_fraction': 0.83061889772184, 'bagging_fraction': 0.6656375058550822, 'bagging_freq': 4, 'lambda_l1': 1.9488216899277764, 'lambda_l2': 4.334997106167453}\n",
      "Best RMSE on validation set during tuning (Optuna): 552.78\n"
     ]
    }
   ],
   "source": [
    "study_p03 = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42)) \n",
    "study_p03.optimize(objective_p03, n_trials=70, show_progress_bar=True) \n",
    "\n",
    "best_params_p03 = study_p03.best_params\n",
    "best_rmse_optuna_p03 = study_p03.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\", best_params_p03)\n",
    "print(f\"Best RMSE on validation set during tuning (Optuna): {best_rmse_optuna_p03:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is dedicated to training the final LightGBM model for Problem Three (forecasting passenger numbers for the next day) using the optimal hyperparameters identified by Optuna, and then rigorously evaluating its performance on the held-out test set. This evaluation provides the most realistic assessment of how well the model will perform on truly unseen future data for next-day forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on X_test_p03:\n",
      "RMSE: 565.81\n",
      "R²: 0.8455\n"
     ]
    }
   ],
   "source": [
    "final_model_p03 = lgb.train(best_params_p03,\n",
    "                            lgb.Dataset(X_train_p03, label=y_train_p03),\n",
    "                            num_boost_round=1000) \n",
    "\n",
    "y_pred_final_p03 = final_model_p03.predict(X_test_p03)\n",
    "\n",
    "rmse_final_p03 = np.sqrt(mean_squared_error(y_test_p03, y_pred_final_p03))\n",
    "r2_final_p03 = r2_score(y_test_p03, y_pred_final_p03)\n",
    "\n",
    "print(f\"\\nFinal Model Performance on X_test_p03:\")\n",
    "print(f\"RMSE: {rmse_final_p03:.2f}\")\n",
    "print(f\"R²: {r2_final_p03:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``RMSE:592.89`` \n",
    "On average, this model next-day passenger forecasts are off by approximately 593 passengers.\n",
    "\n",
    "### ``R²:0.8324`` \n",
    "This indicates that about 83.24% of the variability in next-day passenger numbers can be explained by this model features and its predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Passengers</th>\n",
       "      <th>Base_Predicted_Trains</th>\n",
       "      <th>Buffered_Predicted_Trains</th>\n",
       "      <th>Final_Predicted_Trains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>748</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9026</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10485</th>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_Passengers  Base_Predicted_Trains  Buffered_Predicted_Trains  \\\n",
       "6217                    748                      2                          2   \n",
       "9026                     99                      1                          1   \n",
       "10485                   585                      1                          2   \n",
       "1155                    183                      1                          1   \n",
       "2979                    231                      1                          1   \n",
       "\n",
       "       Final_Predicted_Trains  \n",
       "6217                        2  \n",
       "9026                        1  \n",
       "10485                       2  \n",
       "1155                        1  \n",
       "2979                        1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_allocation_p03= calculate_needed_trains(y_pred_final_p03)\n",
    "train_allocation_p03.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vg01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
